{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sklearn.metrics as metrics\n",
    "# from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\n",
    "# from torchinfo import summary\n",
    "import parameters\n",
    "import random\n",
    "from data_formatting import split_sequence_overlap, split_sequence_nooverlap, split_sequence, split_train_test, normalize_data, set_targets\n",
    "parameters.initialize_parameters()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, seq_length=1000, num_heads=10):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        positions = seq_length + 1 \n",
    "        # Positional Encoding\n",
    "        self.position_enc = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(positions, d_hid=100, T=1000), freeze=True) # frozen weight \n",
    "        self.mha = []\n",
    "        self.fc_input_size = 100 * seq_length\n",
    "        self.relu = nn.ReLU()\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # LayerNorm \n",
    "        self.layernorm = nn.LayerNorm((1000, 100))\n",
    "        \n",
    "        for _ in range(self.num_layers):\n",
    "            # Multi-head self-attention Layer\n",
    "            self.mha.append(nn.MultiheadAttention(100, num_heads, batch_first=True)) # (batch, seq, feature)\n",
    "            # Feed-Forward Network\n",
    "            # self.encoder.append(nn.Linear(self.fc_input_size, self.fc_input_size))\n",
    "            \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 2)\n",
    "        # self.fc1 = nn.Linear(self.fc_input_size, 4096)\n",
    "        # self.fc2 = nn.Linear(4096, self.hidden_size)\n",
    "        # self.fc3 = nn.Linear(self.hidden_size, 2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        src_pos = torch.arange(0, self.seq_length, dtype=torch.long).expand(x.shape[0], self.seq_length) # (batch_size, seq_length)\n",
    "        x = x + self.position_enc(src_pos) # (16, 1000, 100)\n",
    "        for i in range(self.num_layers):\n",
    "            x2 = self.mha[i](x, x, x)[0] # (query, key, value)\n",
    "            # residual connection\n",
    "            x = self.layernorm(x + x2)\n",
    "            \n",
    "            #x = x.view(-1, self.fc_input_size) \n",
    "            #x = self.relu(self.encoder[2](x))\n",
    "            #x = self.dropout(x)\n",
    "            #x = x.view(self.input_size, self.seq_length, 100) \n",
    "            \n",
    "        # x = self.relu(self.fc1(x))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        x = x.view(-1, self.fc_input_size) \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Positional Encoding\n",
    "def get_sinusoid_encoding_table(positions, d_hid, T=1000, cuda=False):\n",
    "    ''' Sinusoid position encoding table\n",
    "    positions: int or list of integer, if int range(positions)'''\n",
    "\n",
    "    if isinstance(positions, int):\n",
    "        positions = list(range(positions))\n",
    "\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(T, 2 * (hid_idx // 2) / d_hid)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_hid)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in positions])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    return torch.FloatTensor(sinusoid_table)\n",
    "\n",
    "    # if cuda:\n",
    "    #     return torch.FloatTensor(sinusoid_table).to('cuda')\n",
    "    # else:\n",
    "    #     return torch.FloatTensor(sinusoid_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Transformer(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers=1, seq_length=1000, num_heads=10):\n",
    "#         super(Transformer, self).__init__()\n",
    "#         self.num_layers = num_layers #number of layers\n",
    "#         self.input_size = input_size #input size\n",
    "#         self.hidden_size = hidden_size #hidden state\n",
    "#         self.seq_length = seq_length #sequence length\n",
    "\n",
    "#         positions = seq_length + 1 \n",
    "#         # Positional Encoding\n",
    "#         self.position_enc = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(positions, d_hid=100, T=1000), freeze=True) # frozen weight \n",
    "#         # Multi-head self-attention Layer\n",
    "#         self.mha = []\n",
    "#         for _ in range(self.num_layers):\n",
    "#           self.mha.append(nn.MultiheadAttention(100, num_heads, batch_first=True)) # (batch, seq, feature)\n",
    "#         # Layer normalization\n",
    "#         self.layernorm = nn.LayerNorm((1000, 100))\n",
    "        \n",
    "#         # Feed-Forward Network\n",
    "#         self.fc_input_size = 100 * seq_length\n",
    "#         #self.fc = nn.Linear(self.fc_input_size, 2)\n",
    "#         self.fc1 = nn.Linear(self.fc_input_size, hidden_size)\n",
    "#         self.fc2 = nn.Linear(hidden_size, 2)\n",
    "#         self.relu = nn.ReLU()\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         src_pos = torch.arange(0, self.seq_length, dtype=torch.long).expand(x.shape[0], self.seq_length) # (batch_size, seq_length) = (16, 100)\n",
    "#         x = x + self.position_enc(src_pos) # (16, 1000, 100)\n",
    "#         x2 = x\n",
    "#         for i in range(self.num_layers):\n",
    "#           x2, _ = self.mha[i](x2, x2, x2) # (query, key, value)\n",
    "#         # residual connection\n",
    "#         x = self.layernorm(x + x2)\n",
    "#         # reshape\n",
    "#         x = x.view(-1, self.fc_input_size) \n",
    "#         #x = self.fc(x)\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Positional Encoding\n",
    "# def get_sinusoid_encoding_table(positions, d_hid, T=1000, cuda=False):\n",
    "#     ''' Sinusoid position encoding table\n",
    "#     positions: int or list of integer, if int range(positions)'''\n",
    "\n",
    "#     if isinstance(positions, int):\n",
    "#         positions = list(range(positions))\n",
    "\n",
    "#     def cal_angle(position, hid_idx):\n",
    "#         return position / np.power(T, 2 * (hid_idx // 2) / d_hid)\n",
    "\n",
    "#     def get_posi_angle_vec(position):\n",
    "#         return [cal_angle(position, hid_j) for hid_j in range(d_hid)]\n",
    "\n",
    "#     sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in positions])\n",
    "\n",
    "#     sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "#     sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "#     if cuda:\n",
    "#         return torch.FloatTensor(sinusoid_table).cuda()\n",
    "#     else:\n",
    "#         return torch.FloatTensor(sinusoid_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list):\n",
    "    all_val_predicted = []\n",
    "    all_val_labels = []\n",
    "    all_val_outputs = np.empty((0, nclasses), dtype='float')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate through validation dataset\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = Variable(features.view(-1, parameters.seq_dim, input_dim)).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(features)\n",
    "            val_loss = error(outputs, labels)\n",
    "\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            predicted = predicted.to('cpu')\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cpu()).sum()\n",
    "            all_val_predicted.extend(list(predicted.detach().numpy()))\n",
    "            all_val_labels.extend(list(labels.cpu().detach().numpy()))\n",
    "            all_val_outputs = np.concatenate((all_val_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "    al_np = np.array(all_val_labels)   \n",
    "    ao_np = np.array(all_val_outputs)  \n",
    "    accuracy = correct / float(total)\n",
    "\n",
    "    # store loss and iteration\n",
    "    loss_list.append(loss.data)\n",
    "    val_loss_list.append(val_loss.data)\n",
    "    epoch_list.append(epoch)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Subject: {}/{}  Epoch: {:>3}  Loss: {:.6}/{:.6}  Validation accuracy: {:.2f}'.format(test_subj, xv, epoch, loss, val_loss, accuracy))\n",
    "    return accuracy\n",
    "    \n",
    "def cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    prev_label = -1\n",
    "    class_hist = np.zeros(nclasses, dtype='int')\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "    # Iterate through test dataset\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if parameters.test_with_subsequences:\n",
    "            for features, labels in test_loader:\n",
    "                features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "                labels = Variable(labels).to('cpu')\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(features)\n",
    "                test_loss = error_cpu(outputs.to('cpu'), labels)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                predicted = predicted.to('cpu')\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_predicted.extend(list(predicted.detach().numpy()))\n",
    "                all_labels.extend(list(labels.detach().numpy()))\n",
    "                all_outputs = np.concatenate((all_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "        \n",
    "        else:\n",
    "            count=0\n",
    "            for features in features_test:\n",
    "                features = torch.tensor(features)\n",
    "                features = torch.unsqueeze(features, 0).to(device)\n",
    "                labels = torch.unsqueeze(torch.tensor(targets_test[count]), 0)\n",
    "                features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(features)\n",
    "\n",
    "                test_loss = error(outputs.to('cpu'), labels)\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                predicted = predicted.to('cpu')\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                count += 1\n",
    "\n",
    "        al_np = np.array(all_labels)   \n",
    "        ao_np = np.array(all_outputs)  \n",
    "\n",
    "        accuracy = correct / float(total)\n",
    "\n",
    "        print(f\"Test accuracy for run {test_subj}/{xv}: {accuracy}\")\n",
    "\n",
    "    avg_test_acc += accuracy\n",
    "    test_acc_list.append(accuracy)\n",
    "\n",
    "\n",
    "def train_model(list_labels, list_targets, epochs, learning_rate, weight_decay, device, num_validation_subjects, train_df):\n",
    "    \n",
    "    target_1 = list_targets[0]\n",
    "    target_2 = list_targets[1]\n",
    "\n",
    "    print(f\"Training transformer model for {target_1} and {target_2}...\")\n",
    "    # Select only the classes we want to predict\n",
    "    train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "    # Convert the subject names (strings) into numbers\n",
    "    subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "    # Normalise the features\n",
    "    features_numpy = normalize_data(train_df, False) #parameters.normalise_individual_subjects\n",
    "    input_dim = features_numpy.shape[1]\n",
    "    #print(f\"Number of features: {input_dim}\")\n",
    "    print(f\"Shape of dataset: {features_numpy.shape}\")\n",
    "    \n",
    "    del train_df\n",
    "    \n",
    "    # Variable we will use throughout the training and testing\n",
    "    test_accuracies = []\n",
    "    calibrated_test_accuracies = []\n",
    "    all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "    # Validation accuracy\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    epoch_list = []\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Get distinct subjects\n",
    "    subj = np.unique(subjects)\n",
    "\n",
    "    # Loop over all subjects\n",
    "    for test_subj in subj:\n",
    "        xv_max_val = 0\n",
    "        avg_test_acc = 0\n",
    "        val_acc_val_loss_list = []\n",
    "        test_acc_list = []\n",
    "        best_accuracy = 0\n",
    "\n",
    "        file_name = f'../model_transformer/best_model_checkpoint_{target_1}_{target_2}_{test_subj}.pth'\n",
    "\n",
    "        # Cross validation\n",
    "        for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "            # Set up the train, validation and test sets\n",
    "            test_idx = np.array([test_subj])\n",
    "\n",
    "            # Take out test subject from trainval (Crooss validation)\n",
    "            trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "            val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "            val_idx = val_idx%len(subj)\n",
    "\n",
    "            # Remove test & validation subjects from trainval\n",
    "            train_idx = np.setxor1d(subj, test_idx)\n",
    "            train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "            #print(\"Generating train/val/test split...\")\n",
    "            features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "            #print(\"Generating sequences...\")\n",
    "            features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "            features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "            \n",
    "            # Overlap or no\n",
    "            if parameters.test_with_subsequences:\n",
    "                features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "            else:\n",
    "                features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "            #print(f\"Number of training examples: {len(targets_train)}\")\n",
    "            #print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "            #print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "            # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "            featuresTrain = torch.from_numpy(features_train)\n",
    "            targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "            featuresVal = torch.from_numpy(features_val)\n",
    "            targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "            # Pytorch train and validation sets\n",
    "            train = TensorDataset(featuresTrain, targetsTrain)\n",
    "            val = TensorDataset(featuresVal, targetsVal)\n",
    "            \n",
    "            \n",
    "            # Data loader\n",
    "            train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "            \n",
    "\n",
    "            # Create feature and targets tensor for test set\n",
    "            if parameters.test_with_subsequences:\n",
    "                featuresTest = torch.from_numpy(features_test)\n",
    "                targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "                test = TensorDataset(featuresTest, targetsTest)\n",
    "                test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "            \n",
    "            # Model\n",
    "            model = Transformer(parameters.batch_size, parameters.hidden_dim).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            error = nn.CrossEntropyLoss()\n",
    "            error_cpu = nn.CrossEntropyLoss().to(device) # 'cpu'\n",
    "\n",
    "            # Early Stopping\n",
    "            \n",
    "            patience = epochs -1\n",
    "            #patience = 4\n",
    "            current_patience = 0\n",
    "\n",
    "            # Train the model\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                running_loss = 0\n",
    "                for data, target in train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    # print(data.shape)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(data)\n",
    "                    loss = error(outputs, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation accuracy\n",
    "                accuracy = validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\n",
    "\n",
    "                ### Early stopping\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    torch.save(model.state_dict(), file_name)\n",
    "                    current_patience = 0  # Reset patience counter\n",
    "                else:\n",
    "                    current_patience += 1  # No improvement, increase patience counter\n",
    "                \n",
    "                if current_patience >= patience:\n",
    "                    # Early stopping condition met\n",
    "                    #print(f'Early stopping at epoch {epoch} due to lack of improvement.')\n",
    "                    break\n",
    "\n",
    "            # Restore the best model checkpoint\n",
    "            model.load_state_dict(torch.load(file_name))\n",
    "        \n",
    "            # Cross validation accuracy\n",
    "            cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj)\n",
    "\n",
    "        avg_test_acc = np.mean(test_acc_list)\n",
    "        test_accuracies.append(avg_test_acc)\n",
    "    \n",
    "    print(\"Test accuracies:\")\n",
    "    print(test_accuracies)\n",
    "    mean_accuracy = np.mean(test_accuracies)\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    return mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_specific_test_subj(list_labels, list_targets, epochs, learning_rate, weight_decay, device, num_validation_subjects, train_df, test_subj):\n",
    "    \n",
    "    target_1 = list_targets[0]\n",
    "    target_2 = list_targets[1]\n",
    "\n",
    "    print(f\"Training transformer model for {target_1} and {target_2}...\")\n",
    "    # Select only the classes we want to predict\n",
    "    train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "    # Convert the subject names (strings) into numbers\n",
    "    subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "    # Normalise the features\n",
    "    features_numpy = normalize_data(train_df, False) #parameters.normalise_individual_subjects\n",
    "    input_dim = features_numpy.shape[1]\n",
    "    #print(f\"Number of features: {input_dim}\")\n",
    "    print(f\"Shape of dataset: {features_numpy.shape}\")\n",
    "    \n",
    "    del train_df\n",
    "    \n",
    "    # Variable we will use throughout the training and testing\n",
    "    test_accuracies = []\n",
    "    calibrated_test_accuracies = []\n",
    "    all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "    # Validation accuracy\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    epoch_list = []\n",
    "    accuracy_list = []\n",
    "\n",
    "    file_name = f'../model_transformer/best_model_checkpoint_{target_1}_{target_2}_{test_subj}.pth'\n",
    "\n",
    "    # Get distinct subjects\n",
    "    subj = np.unique(subjects)\n",
    "\n",
    "    xv_max_val = 0\n",
    "    avg_test_acc = 0\n",
    "    val_acc_val_loss_list = []\n",
    "    test_acc_list = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "\n",
    "    # Cross validation\n",
    "    for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "        # Set up the train, validation and test sets\n",
    "        test_idx = np.array([test_subj])\n",
    "\n",
    "        # Take out test subject from trainval (Crooss validation)\n",
    "        trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "        val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "        val_idx = val_idx%len(subj)\n",
    "\n",
    "        # Remove test & validation subjects from trainval\n",
    "        train_idx = np.setxor1d(subj, test_idx)\n",
    "        train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "        #print(\"Generating train/val/test split...\")\n",
    "        features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "        #print(\"Generating sequences...\")\n",
    "        features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "        features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "        \n",
    "        # Overlap or no\n",
    "        if parameters.test_with_subsequences:\n",
    "            features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "        else:\n",
    "            features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "        #print(f\"Number of training examples: {len(targets_train)}\")\n",
    "        #print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "        #print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "        # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "        featuresTrain = torch.from_numpy(features_train)\n",
    "        targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        featuresVal = torch.from_numpy(features_val)\n",
    "        targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        # Pytorch train and validation sets\n",
    "        train = TensorDataset(featuresTrain, targetsTrain)\n",
    "        val = TensorDataset(featuresVal, targetsVal)\n",
    "        \n",
    "        \n",
    "        # Data loader\n",
    "        train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "        \n",
    "\n",
    "        # Create feature and targets tensor for test set\n",
    "        if parameters.test_with_subsequences:\n",
    "            featuresTest = torch.from_numpy(features_test)\n",
    "            targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "            test = TensorDataset(featuresTest, targetsTest)\n",
    "            test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "        \n",
    "        # Model\n",
    "        model = Transformer(parameters.batch_size, parameters.hidden_dim).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        error = nn.CrossEntropyLoss()\n",
    "        error_cpu = nn.CrossEntropyLoss().to(device) # 'cpu'\n",
    "\n",
    "        # Early Stopping\n",
    "        \n",
    "        patience = epochs -1\n",
    "        #patience = 4\n",
    "        current_patience = 0\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # print(data.shape)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = error(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Validation accuracy\n",
    "            accuracy = validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\n",
    "\n",
    "            ### Early stopping\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(model.state_dict(), file_name)\n",
    "                current_patience = 0  # Reset patience counter\n",
    "            else:\n",
    "                current_patience += 1  # No improvement, increase patience counter\n",
    "            \n",
    "            if current_patience >= patience:\n",
    "                # Early stopping condition met\n",
    "                #print(f'Early stopping at epoch {epoch} due to lack of improvement.')\n",
    "                break\n",
    "\n",
    "        # Restore the best model checkpoint\n",
    "        model.load_state_dict(torch.load(file_name))\n",
    "    \n",
    "        # Cross validation accuracy\n",
    "        cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj)\n",
    "\n",
    "    avg_test_acc = np.mean(test_acc_list)\n",
    "    test_accuracies.append(avg_test_acc)\n",
    "    \n",
    "    print(\"Test accuracies:\")\n",
    "    print(test_accuracies)\n",
    "    mean_accuracy = np.mean(test_accuracies)\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    return mean_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "# Classes we want to predict (0 et 3) and binary outputs\n",
    "list_targets = [0, 3]\n",
    "list_labels = [0, 1]\n",
    "\n",
    "# number of subjects used for validation\n",
    "num_validation_subjects = 1\n",
    "\n",
    "learning_rate = 0.0007\n",
    "weight_decay = 10e-4\n",
    "epochs = 3\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "csvfile = \"../../data/video/All_Subs_Diff_Modules_nofilter_withoutAUc.csv\"\n",
    "train_df = pd.read_csv(csvfile,  delimiter=\",\")  # 101 features (only AU_r)\n",
    "\n",
    "# Create folder to save models\n",
    "if not os.path.exists(\"../model_transformer/\"):\n",
    "    os.makedirs(\"../model_transformer/\")\n",
    "\n",
    "\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transformer model for 0 and 1...\n",
      "Shape of dataset: (221004, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.376898/0.0673712  Validation accuracy: 0.56\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.399972/4.95734  Validation accuracy: 0.51\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.301656/0.754184  Validation accuracy: 0.67\n",
      "Test accuracy for run 2/0: 0.6109422492401215\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.989251/4.07151  Validation accuracy: 0.42\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.282568/4.24717  Validation accuracy: 0.45\n",
      "Test accuracy for run 2/1: 0.6398176291793313\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.364745/0.0348898  Validation accuracy: 1.00\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.41369/0.0380064  Validation accuracy: 0.99\n",
      "Subject: 2/2  Epoch:   2  Loss: 0.00415179/0.000505541  Validation accuracy: 0.96\n",
      "Test accuracy for run 2/2: 0.5729483282674772\n",
      "Test accuracies:\n",
      "[0.60790273556231]\n",
      "Mean accuracy: 0.60790273556231\n",
      "Training transformer model for 0 and 2...\n",
      "Shape of dataset: (220827, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.0745365/1.89008  Validation accuracy: 0.34\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.560335/0.508287  Validation accuracy: 0.54\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.296476/0.301551  Validation accuracy: 0.76\n",
      "Test accuracy for run 2/0: 0.7211895910780669\n",
      "Subject: 2/1  Epoch:   0  Loss: 5.86501/0.0  Validation accuracy: 0.52\n",
      "Subject: 2/1  Epoch:   1  Loss: 1.09585/0.206782  Validation accuracy: 0.80\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.00846572/0.234098  Validation accuracy: 0.77\n",
      "Test accuracy for run 2/1: 0.7286245353159851\n",
      "Subject: 2/2  Epoch:   0  Loss: 1.73483/2.69018  Validation accuracy: 0.39\n",
      "Subject: 2/2  Epoch:   1  Loss: 1.24654/1.3181  Validation accuracy: 0.43\n",
      "Test accuracy for run 2/2: 0.7509293680297398\n",
      "Test accuracies:\n",
      "[0.7335811648079306]\n",
      "Mean accuracy: 0.7335811648079306\n",
      "Training transformer model for 0 and 3...\n",
      "Shape of dataset: (221075, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 1.43223/0.000369361  Validation accuracy: 0.71\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.0676222/2.2382  Validation accuracy: 0.89\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.30703/0.0502388  Validation accuracy: 0.79\n",
      "Test accuracy for run 2/0: 0.6081871345029239\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.0374424/3.75508e-06  Validation accuracy: 0.63\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.0629007/0.010184  Validation accuracy: 0.96\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.00452474/3.3214e-05  Validation accuracy: 0.88\n",
      "Test accuracy for run 2/1: 0.6052631578947368\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.931793/1.92276  Validation accuracy: 0.69\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.638027/1.52352  Validation accuracy: 0.74\n",
      "Test accuracy for run 2/2: 0.6052631578947368\n",
      "Test accuracies:\n",
      "[0.6062378167641325]\n",
      "Mean accuracy: 0.6062378167641325\n",
      "Training transformer model for 0 and 4...\n",
      "Shape of dataset: (221248, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.035945/0.854736  Validation accuracy: 0.69\n",
      "Subject: 2/0  Epoch:   1  Loss: 5.96046e-07/0.954344  Validation accuracy: 0.75\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.000360781/1.1417  Validation accuracy: 0.60\n",
      "Test accuracy for run 2/0: 0.5693950177935944\n",
      "Subject: 2/1  Epoch:   0  Loss: 1.24284/0.159919  Validation accuracy: 0.94\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.00164959/0.734556  Validation accuracy: 0.82\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.175829/0.00570492  Validation accuracy: 0.93\n",
      "Test accuracy for run 2/1: 0.697508896797153\n",
      "Subject: 2/2  Epoch:   0  Loss: 6.7524/18.3548  Validation accuracy: 0.68\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.000837154/11.3356  Validation accuracy: 0.68\n",
      "Test accuracy for run 2/2: 0.8220640569395018\n",
      "Test accuracies:\n",
      "[0.6963226571767497]\n",
      "Mean accuracy: 0.6963226571767497\n",
      "Training transformer model for 0 and 5...\n",
      "Shape of dataset: (221490, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.905773/1.49861  Validation accuracy: 0.55\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.479537/2.73032  Validation accuracy: 0.43\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.0158963/4.0971  Validation accuracy: 0.43\n",
      "Test accuracy for run 2/0: 0.7897058823529411\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.22955/0.00374799  Validation accuracy: 1.00\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.247316/0.00019112  Validation accuracy: 0.98\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.0804271/0.00650721  Validation accuracy: 1.00\n",
      "Test accuracy for run 2/1: 0.7911764705882353\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.236127/4.02205  Validation accuracy: 0.37\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.0741902/5.51001  Validation accuracy: 0.28\n",
      "Test accuracy for run 2/2: 0.7897058823529411\n",
      "Test accuracies:\n",
      "[0.7901960784313725]\n",
      "Mean accuracy: 0.7901960784313725\n",
      "Training transformer model for 1 and 2...\n",
      "Shape of dataset: (220475, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 1.40894/0.192259  Validation accuracy: 0.78\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.0880437/1.70552  Validation accuracy: 0.59\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.112759/0.256573  Validation accuracy: 0.71\n",
      "Test accuracy for run 2/0: 0.42536327608982827\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.698806/2.41407  Validation accuracy: 0.43\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.66409/4.69277  Validation accuracy: 0.52\n",
      "Test accuracy for run 2/1: 0.45970937912813736\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.632943/1.51993  Validation accuracy: 0.45\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.302384/1.24162  Validation accuracy: 0.44\n",
      "Test accuracy for run 2/2: 0.46895640686922063\n",
      "Test accuracies:\n",
      "[0.45134302069572874]\n",
      "Mean accuracy: 0.45134302069572874\n",
      "Training transformer model for 1 and 3...\n",
      "Shape of dataset: (220723, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 1.20982/4.93738  Validation accuracy: 0.45\n",
      "Subject: 2/0  Epoch:   1  Loss: 2.16011/4.45948  Validation accuracy: 0.59\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.0572167/3.88368  Validation accuracy: 0.59\n",
      "Test accuracy for run 2/0: 0.5941176470588235\n",
      "Subject: 2/1  Epoch:   0  Loss: 4.71904/4.1042  Validation accuracy: 0.66\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.500317/0.102655  Validation accuracy: 0.51\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.00058324/0.692224  Validation accuracy: 0.71\n",
      "Test accuracy for run 2/1: 0.5823529411764706\n",
      "Subject: 2/2  Epoch:   0  Loss: 4.05878/9.42998  Validation accuracy: 0.30\n",
      "Subject: 2/2  Epoch:   1  Loss: 2.41509/4.0988  Validation accuracy: 0.45\n",
      "Test accuracy for run 2/2: 0.5941176470588235\n",
      "Test accuracies:\n",
      "[0.5901960784313726]\n",
      "Mean accuracy: 0.5901960784313726\n",
      "Training transformer model for 1 and 4...\n",
      "Shape of dataset: (220896, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.000125035/0.652078  Validation accuracy: 0.80\n",
      "Subject: 2/0  Epoch:   1  Loss: 1.81399/1.77475  Validation accuracy: 0.68\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.000145065/1.78184  Validation accuracy: 0.83\n",
      "Test accuracy for run 2/0: 0.90234375\n",
      "Subject: 2/1  Epoch:   0  Loss: 1.46161/1.54152  Validation accuracy: 0.52\n",
      "Subject: 2/1  Epoch:   1  Loss: 9.83473e-07/0.432261  Validation accuracy: 0.61\n",
      "Test accuracy for run 2/1: 0.9401041666666666\n",
      "Subject: 2/2  Epoch:   0  Loss: 1.21438/0.0  Validation accuracy: 0.98\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.00986525/2.98023e-08  Validation accuracy: 1.00\n",
      "Subject: 2/2  Epoch:   2  Loss: 0.0663028/0.000219854  Validation accuracy: 0.65\n",
      "Test accuracy for run 2/2: 0.53125\n",
      "Test accuracies:\n",
      "[0.7912326388888888]\n",
      "Mean accuracy: 0.7912326388888888\n",
      "Training transformer model for 1 and 5...\n",
      "Shape of dataset: (221138, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 6.2869/2.98739  Validation accuracy: 0.84\n",
      "Subject: 2/0  Epoch:   1  Loss: 3.48598/1.58659  Validation accuracy: 0.75\n",
      "Subject: 2/0  Epoch:   2  Loss: 2.35437e-06/1.89647  Validation accuracy: 0.55\n",
      "Test accuracy for run 2/0: 0.9583333333333334\n",
      "Subject: 2/1  Epoch:   0  Loss: 3.8641/6.44875  Validation accuracy: 0.53\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.240056/2.33727  Validation accuracy: 0.59\n",
      "Test accuracy for run 2/1: 0.9583333333333334\n",
      "Subject: 2/2  Epoch:   0  Loss: 3.83384/6.2932  Validation accuracy: 0.65\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.641309/13.3732  Validation accuracy: 0.62\n",
      "Test accuracy for run 2/2: 0.9464285714285714\n",
      "Test accuracies:\n",
      "[0.9543650793650794]\n",
      "Mean accuracy: 0.9543650793650794\n",
      "Training transformer model for 2 and 3...\n",
      "Shape of dataset: (220546, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 2.04187/3.07515  Validation accuracy: 0.54\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.423067/1.12863  Validation accuracy: 0.32\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.0411656/9.86949  Validation accuracy: 0.49\n",
      "Test accuracy for run 2/0: 0.5728900255754475\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.276459/0.0306916  Validation accuracy: 0.47\n",
      "Subject: 2/1  Epoch:   1  Loss: 1.58561/5.36333  Validation accuracy: 0.42\n",
      "Test accuracy for run 2/1: 0.5601023017902813\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.711112/0.416589  Validation accuracy: 0.70\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.513431/0.0019748  Validation accuracy: 0.51\n",
      "Subject: 2/2  Epoch:   2  Loss: 0.526288/0.00378566  Validation accuracy: 0.57\n",
      "Test accuracy for run 2/2: 0.5076726342710998\n",
      "Test accuracies:\n",
      "[0.5468883205456095]\n",
      "Mean accuracy: 0.5468883205456095\n",
      "Training transformer model for 2 and 4...\n",
      "Shape of dataset: (220719, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 3.13066/14.1281  Validation accuracy: 0.57\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.0/3.57628e-07  Validation accuracy: 1.00\n",
      "Subject: 2/0  Epoch:   2  Loss: 5.96036e-06/3.63586e-06  Validation accuracy: 0.97\n",
      "Test accuracy for run 2/0: 0.48812664907651715\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.0/19.8294  Validation accuracy: 0.75\n",
      "Subject: 2/1  Epoch:   1  Loss: 1.19209e-07/3.04542  Validation accuracy: 0.84\n",
      "Test accuracy for run 2/1: 0.6094986807387863\n",
      "Subject: 2/2  Epoch:   0  Loss: 2.59584/2.40437  Validation accuracy: 0.50\n",
      "Subject: 2/2  Epoch:   1  Loss: 1.98356/13.986  Validation accuracy: 0.75\n",
      "Test accuracy for run 2/2: 0.5013192612137203\n",
      "Test accuracies:\n",
      "[0.5329815303430079]\n",
      "Mean accuracy: 0.5329815303430079\n",
      "Training transformer model for 2 and 5...\n",
      "Shape of dataset: (220961, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.124877/14.4123  Validation accuracy: 0.65\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.00305573/2.29196  Validation accuracy: 0.65\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.0/10.3834  Validation accuracy: 0.63\n",
      "Test accuracy for run 2/0: 0.9974293059125964\n",
      "Subject: 2/1  Epoch:   0  Loss: 2.27375/5.53998  Validation accuracy: 0.39\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.0400051/5.36511  Validation accuracy: 0.42\n",
      "Test accuracy for run 2/1: 0.9948586118251928\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.0874163/0.109633  Validation accuracy: 0.93\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.0269735/0.344623  Validation accuracy: 0.79\n",
      "Subject: 2/2  Epoch:   2  Loss: 0.222507/0.0135797  Validation accuracy: 0.96\n",
      "Test accuracy for run 2/2: 0.993573264781491\n",
      "Test accuracies:\n",
      "[0.99528706083976]\n",
      "Mean accuracy: 0.99528706083976\n",
      "Training transformer model for 3 and 4...\n",
      "Shape of dataset: (220967, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.0213068/0.0246063  Validation accuracy: 1.00\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.0897662/6.15097e-05  Validation accuracy: 1.00\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.00331463/7.43067e-06  Validation accuracy: 1.00\n",
      "Test accuracy for run 2/0: 0.5561160151324086\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.0/3.03114  Validation accuracy: 0.73\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.0/1.51969  Validation accuracy: 0.84\n",
      "Test accuracy for run 2/1: 0.5662042875157629\n",
      "Subject: 2/2  Epoch:   0  Loss: 2.14908/9.77903e-05  Validation accuracy: 0.91\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.111829/0.293772  Validation accuracy: 0.84\n",
      "Test accuracy for run 2/2: 0.501891551071879\n",
      "Test accuracies:\n",
      "[0.5414039512400168]\n",
      "Mean accuracy: 0.5414039512400168\n",
      "Training transformer model for 3 and 5...\n",
      "Shape of dataset: (221209, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.357137/0.204217  Validation accuracy: 0.55\n",
      "Subject: 2/0  Epoch:   1  Loss: 1.28705/0.0680145  Validation accuracy: 0.79\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.119338/0.255488  Validation accuracy: 0.70\n",
      "Test accuracy for run 2/0: 0.9329896907216495\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.000131036/0.0  Validation accuracy: 0.76\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.0137658/0.0  Validation accuracy: 0.55\n",
      "Test accuracy for run 2/1: 1.0\n",
      "Subject: 2/2  Epoch:   0  Loss: 3.79372/0.0  Validation accuracy: 0.76\n",
      "Subject: 2/2  Epoch:   1  Loss: 1.99891/0.0248597  Validation accuracy: 0.79\n",
      "Test accuracy for run 2/2: 1.0\n",
      "Test accuracies:\n",
      "[0.9776632302405499]\n",
      "Mean accuracy: 0.9776632302405499\n",
      "Training transformer model for 4 and 5...\n",
      "Shape of dataset: (221382, 100)\n",
      "Subject: 2/0  Epoch:   0  Loss: 7.06065/0.0  Validation accuracy: 0.71\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.464501/0.00225056  Validation accuracy: 0.83\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.0088306/1.76724e-05  Validation accuracy: 0.73\n",
      "Test accuracy for run 2/0: 0.4860759493670886\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.167746/0.0456459  Validation accuracy: 0.66\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.876323/1.18486  Validation accuracy: 0.68\n",
      "Test accuracy for run 2/1: 0.4582278481012658\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.29887/1.78814e-06  Validation accuracy: 0.84\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.0122091/0.284859  Validation accuracy: 0.96\n",
      "Subject: 2/2  Epoch:   2  Loss: 0.760844/0.0891035  Validation accuracy: 0.91\n",
      "Test accuracy for run 2/2: 0.49873417721518987\n",
      "Test accuracies:\n",
      "[0.48101265822784806]\n",
      "Mean accuracy: 0.48101265822784806\n",
      "{(0, 1): 0.60790273556231, (0, 2): 0.7335811648079306, (0, 3): 0.6062378167641325, (0, 4): 0.6963226571767497, (0, 5): 0.7901960784313725, (1, 2): 0.45134302069572874, (1, 3): 0.5901960784313726, (1, 4): 0.7912326388888888, (1, 5): 0.9543650793650794, (2, 3): 0.5468883205456095, (2, 4): 0.5329815303430079, (2, 5): 0.99528706083976, (3, 4): 0.5414039512400168, (3, 5): 0.9776632302405499, (4, 5): 0.48101265822784806}\n"
     ]
    }
   ],
   "source": [
    "# train all models\n",
    "for i in range(6):\n",
    "    for j in range(i+1, 6):\n",
    "        list_targets = [i, j]\n",
    "        accuracy = train_model_for_specific_test_subj(list_labels,list_targets, epochs, learning_rate, weight_decay, device, num_validation_subjects, train_df,3)\n",
    "        results_dict[tuple(list_targets)] = accuracy\n",
    "\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Specify the CSV file path\n",
    "csv_file_path = '../model_transformer/results.csv'\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header (assuming your CSV should have columns \"Targets\" and \"Accuracy\")\n",
    "    csv_writer.writerow(['Targets', 'Accuracy'])\n",
    "\n",
    "    # Write each row in the dictionary to the CSV file\n",
    "    for targets, accuracy in results_dict.items():\n",
    "        # Convert the tuple of lists to a string for easy representation in CSV\n",
    "        targets_str = ', '.join(map(str, targets))\n",
    "        csv_writer.writerow([targets_str, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transformer model for 0 and 1...\n",
      "Shape of dataset: (221004, 100)\n",
      "Subject: 0/0  Epoch:   0  Loss: 0.550789/0.542654  Validation accuracy: 0.59\n",
      "Subject: 0/0  Epoch:   1  Loss: 0.162036/2.45319  Validation accuracy: 0.61\n",
      "Subject: 0/0  Epoch:   2  Loss: 0.248414/2.03016  Validation accuracy: 0.63\n",
      "Test accuracy for run 0/0: 0.5886736214605067\n",
      "Subject: 0/1  Epoch:   0  Loss: 2.16938/6.52067e-06  Validation accuracy: 0.91\n",
      "Subject: 0/1  Epoch:   1  Loss: 0.0244382/0.153086  Validation accuracy: 0.89\n",
      "Subject: 0/1  Epoch:   2  Loss: 0.374548/0.00167039  Validation accuracy: 0.93\n",
      "Test accuracy for run 0/1: 0.5141579731743666\n",
      "Subject: 0/2  Epoch:   0  Loss: 0.00199405/3.58995  Validation accuracy: 0.58\n",
      "Subject: 0/2  Epoch:   1  Loss: 0.000936904/0.953114  Validation accuracy: 0.77\n",
      "Test accuracy for run 0/2: 0.5424739195230999\n",
      "Subject: 1/0  Epoch:   0  Loss: 0.716223/0.912724  Validation accuracy: 0.70\n",
      "Subject: 1/0  Epoch:   1  Loss: 0.249753/3.01613  Validation accuracy: 0.57\n",
      "Subject: 1/0  Epoch:   2  Loss: 0.0139821/3.6298  Validation accuracy: 0.56\n",
      "Test accuracy for run 1/0: 0.7011331444759207\n",
      "Subject: 1/1  Epoch:   0  Loss: 0.805845/0.0  Validation accuracy: 0.50\n",
      "Subject: 1/1  Epoch:   1  Loss: 0.908155/3.05171e-05  Validation accuracy: 0.60\n",
      "Test accuracy for run 1/1: 0.7252124645892352\n",
      "Subject: 1/2  Epoch:   0  Loss: 0.354941/0.643957  Validation accuracy: 0.59\n",
      "Subject: 1/2  Epoch:   1  Loss: 0.113895/0.353625  Validation accuracy: 0.76\n",
      "Subject: 1/2  Epoch:   2  Loss: 0.499171/0.245905  Validation accuracy: 0.85\n",
      "Test accuracy for run 1/2: 0.7223796033994334\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.0250641/0.253334  Validation accuracy: 0.80\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.00123711/0.0240372  Validation accuracy: 0.62\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.596741/0.342657  Validation accuracy: 0.75\n",
      "Test accuracy for run 2/0: 0.5911854103343465\n",
      "Subject: 2/1  Epoch:   0  Loss: 1.38346/0.0644349  Validation accuracy: 0.95\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.441372/0.0030594  Validation accuracy: 0.95\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.170982/0.00278904  Validation accuracy: 0.95\n",
      "Test accuracy for run 2/1: 0.5866261398176292\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.489527/0.139217  Validation accuracy: 0.79\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.283083/0.85729  Validation accuracy: 0.72\n",
      "Test accuracy for run 2/2: 0.5820668693009119\n",
      "Subject: 3/0  Epoch:   0  Loss: 0.411799/0.0988815  Validation accuracy: 0.58\n",
      "Subject: 3/0  Epoch:   1  Loss: 0.073537/0.0186801  Validation accuracy: 0.58\n",
      "Subject: 3/0  Epoch:   2  Loss: 0.0238796/0.0744823  Validation accuracy: 0.57\n",
      "Test accuracy for run 3/0: 0.6157635467980296\n",
      "Subject: 3/1  Epoch:   0  Loss: 1.72699/1.88412  Validation accuracy: 0.43\n",
      "Subject: 3/1  Epoch:   1  Loss: 0.199786/1.20025  Validation accuracy: 0.61\n",
      "Subject: 3/1  Epoch:   2  Loss: 0.721116/1.7284  Validation accuracy: 0.62\n",
      "Test accuracy for run 3/1: 0.8596059113300493\n",
      "Subject: 3/2  Epoch:   0  Loss: 0.79052/0.00992119  Validation accuracy: 0.53\n",
      "Subject: 3/2  Epoch:   1  Loss: 0.0451529/0.000320893  Validation accuracy: 0.50\n",
      "Test accuracy for run 3/2: 0.7684729064039408\n",
      "Subject: 4/0  Epoch:   0  Loss: 1.76433/0.000298452  Validation accuracy: 0.99\n",
      "Subject: 4/0  Epoch:   1  Loss: 0.228381/0.00907258  Validation accuracy: 0.96\n",
      "Subject: 4/0  Epoch:   2  Loss: 0.437769/0.00721  Validation accuracy: 0.93\n",
      "Test accuracy for run 4/0: 0.5037783375314862\n",
      "Subject: 4/1  Epoch:   0  Loss: 1.15585/4.69288  Validation accuracy: 0.33\n",
      "Subject: 4/1  Epoch:   1  Loss: 0.443232/1.75756  Validation accuracy: 0.33\n",
      "Test accuracy for run 4/1: 0.5037783375314862\n",
      "Subject: 4/2  Epoch:   0  Loss: 0.0148321/4.07403  Validation accuracy: 0.49\n",
      "Subject: 4/2  Epoch:   1  Loss: 0.408579/0.346578  Validation accuracy: 0.79\n",
      "Test accuracy for run 4/2: 0.5138539042821159\n",
      "Subject: 5/0  Epoch:   0  Loss: 0.654124/1.561  Validation accuracy: 0.55\n",
      "Subject: 5/0  Epoch:   1  Loss: 0.379617/0.501482  Validation accuracy: 0.67\n",
      "Subject: 5/0  Epoch:   2  Loss: 0.117796/1.96767  Validation accuracy: 0.61\n",
      "Test accuracy for run 5/0: 0.685337726523888\n",
      "Subject: 5/1  Epoch:   0  Loss: 1.36097/1.33695  Validation accuracy: 0.64\n",
      "Subject: 5/1  Epoch:   1  Loss: 0.00212958/1.04887  Validation accuracy: 0.60\n",
      "Test accuracy for run 5/1: 0.7397034596375618\n",
      "Subject: 5/2  Epoch:   0  Loss: 0.763043/0.102208  Validation accuracy: 0.55\n",
      "Subject: 5/2  Epoch:   1  Loss: 0.0268743/0.0154923  Validation accuracy: 0.65\n",
      "Test accuracy for run 5/2: 0.6342668863261944\n",
      "Subject: 6/0  Epoch:   0  Loss: 2.20719/1.08396  Validation accuracy: 0.75\n",
      "Subject: 6/0  Epoch:   1  Loss: 0.401631/0.82076  Validation accuracy: 0.69\n",
      "Subject: 6/0  Epoch:   2  Loss: 0.000106272/0.411209  Validation accuracy: 0.81\n",
      "Test accuracy for run 6/0: 0.6328600405679513\n",
      "Subject: 6/1  Epoch:   0  Loss: 0.453908/0.0952918  Validation accuracy: 0.99\n",
      "Subject: 6/1  Epoch:   1  Loss: 1.36209/0.0126251  Validation accuracy: 0.98\n",
      "Subject: 6/1  Epoch:   2  Loss: 0.515512/0.071191  Validation accuracy: 0.90\n",
      "Test accuracy for run 6/1: 0.7200811359026369\n",
      "Subject: 6/2  Epoch:   0  Loss: 0.149365/3.84616  Validation accuracy: 0.71\n",
      "Subject: 6/2  Epoch:   1  Loss: 0.64502/0.729837  Validation accuracy: 0.87\n",
      "Test accuracy for run 6/2: 0.5862068965517241\n",
      "Subject: 7/0  Epoch:   0  Loss: 0.421395/0.245687  Validation accuracy: 0.66\n",
      "Subject: 7/0  Epoch:   1  Loss: 0.299401/0.0194935  Validation accuracy: 0.62\n",
      "Subject: 7/0  Epoch:   2  Loss: 0.0939501/0.819715  Validation accuracy: 0.54\n",
      "Test accuracy for run 7/0: 0.7380191693290735\n",
      "Subject: 7/1  Epoch:   0  Loss: 1.40664/3.3789  Validation accuracy: 0.41\n",
      "Subject: 7/1  Epoch:   1  Loss: 1.1547/3.14652  Validation accuracy: 0.39\n",
      "Test accuracy for run 7/1: 0.7779552715654952\n",
      "Subject: 7/2  Epoch:   0  Loss: 0.396639/0.387511  Validation accuracy: 0.68\n",
      "Subject: 7/2  Epoch:   1  Loss: 0.45098/1.18714  Validation accuracy: 0.75\n",
      "Subject: 7/2  Epoch:   2  Loss: 2.17497/5.9  Validation accuracy: 0.57\n",
      "Test accuracy for run 7/2: 0.8146964856230032\n",
      "Subject: 8/0  Epoch:   0  Loss: 0.564789/2.36919  Validation accuracy: 0.49\n",
      "Subject: 8/0  Epoch:   1  Loss: 0.343432/4.6548  Validation accuracy: 0.43\n",
      "Subject: 8/0  Epoch:   2  Loss: 0.635235/2.79612  Validation accuracy: 0.39\n",
      "Test accuracy for run 8/0: 0.6389496717724289\n",
      "Subject: 8/1  Epoch:   0  Loss: 0.680662/0.0106115  Validation accuracy: 0.57\n",
      "Subject: 8/1  Epoch:   1  Loss: 0.418853/0.00261863  Validation accuracy: 0.64\n",
      "Subject: 8/1  Epoch:   2  Loss: 0.00647844/0.00376825  Validation accuracy: 0.65\n",
      "Test accuracy for run 8/1: 0.7789934354485777\n",
      "Subject: 8/2  Epoch:   0  Loss: 1.79487/5.11189  Validation accuracy: 0.72\n",
      "Subject: 8/2  Epoch:   1  Loss: 0.0316194/7.53643  Validation accuracy: 0.70\n",
      "Subject: 8/2  Epoch:   2  Loss: 0.0187924/25.0434  Validation accuracy: 0.60\n",
      "Test accuracy for run 8/2: 0.6455142231947484\n",
      "Subject: 9/0  Epoch:   0  Loss: 0.0360209/2.79007  Validation accuracy: 0.33\n",
      "Subject: 9/0  Epoch:   1  Loss: 0.0245005/1.57968  Validation accuracy: 0.42\n",
      "Subject: 9/0  Epoch:   2  Loss: 0.0865244/0.304463  Validation accuracy: 0.49\n",
      "Test accuracy for run 9/0: 0.5676855895196506\n",
      "Subject: 9/1  Epoch:   0  Loss: 1.45764/0.00312837  Validation accuracy: 1.00\n",
      "Subject: 9/1  Epoch:   1  Loss: 0.064449/0.0260927  Validation accuracy: 1.00\n",
      "Subject: 9/1  Epoch:   2  Loss: 0.842119/0.134708  Validation accuracy: 0.93\n",
      "Test accuracy for run 9/1: 0.5982532751091703\n",
      "Subject: 9/2  Epoch:   0  Loss: 1.44611/2.24448  Validation accuracy: 0.53\n",
      "Subject: 9/2  Epoch:   1  Loss: 0.641417/0.0564685  Validation accuracy: 0.82\n",
      "Test accuracy for run 9/2: 0.6302765647743813\n",
      "Subject: 10/0  Epoch:   0  Loss: 0.431167/0.770576  Validation accuracy: 0.56\n",
      "Subject: 10/0  Epoch:   1  Loss: 2.36857/3.32579  Validation accuracy: 0.49\n",
      "Subject: 10/0  Epoch:   2  Loss: 0.350554/3.51479  Validation accuracy: 0.50\n",
      "Test accuracy for run 10/0: 0.6435452793834296\n",
      "Subject: 10/1  Epoch:   0  Loss: 1.19209e-06/3.01625  Validation accuracy: 0.64\n",
      "Subject: 10/1  Epoch:   1  Loss: 0.00931323/1.85211  Validation accuracy: 0.70\n",
      "Subject: 10/1  Epoch:   2  Loss: 0.0173896/0.00165334  Validation accuracy: 0.52\n",
      "Test accuracy for run 10/1: 0.8362235067437379\n",
      "Subject: 10/2  Epoch:   0  Loss: 0.0192921/0.0995485  Validation accuracy: 0.46\n",
      "Subject: 10/2  Epoch:   1  Loss: 0.0318549/0.74216  Validation accuracy: 0.46\n",
      "Test accuracy for run 10/2: 0.6685934489402697\n",
      "Subject: 11/0  Epoch:   0  Loss: 0.259813/1.76111  Validation accuracy: 0.49\n",
      "Subject: 11/0  Epoch:   1  Loss: 0.0766069/3.13875  Validation accuracy: 0.46\n",
      "Subject: 11/0  Epoch:   2  Loss: 0.140209/4.02956  Validation accuracy: 0.41\n",
      "Test accuracy for run 11/0: 0.24105011933174225\n",
      "Subject: 11/1  Epoch:   0  Loss: 0.173093/0.0390854  Validation accuracy: 0.70\n",
      "Subject: 11/1  Epoch:   1  Loss: 0.0242587/0.000591654  Validation accuracy: 0.71\n",
      "Subject: 11/1  Epoch:   2  Loss: 0.0141168/0.322595  Validation accuracy: 0.75\n",
      "Test accuracy for run 11/1: 0.3317422434367542\n",
      "Subject: 11/2  Epoch:   0  Loss: 1.64211/0.377994  Validation accuracy: 0.63\n",
      "Subject: 11/2  Epoch:   1  Loss: 0.579965/0.208359  Validation accuracy: 0.59\n",
      "Test accuracy for run 11/2: 0.30787589498806683\n",
      "Subject: 12/0  Epoch:   0  Loss: 2.05454/1.6908  Validation accuracy: 0.49\n",
      "Subject: 12/0  Epoch:   1  Loss: 0.301485/1.48158  Validation accuracy: 0.56\n",
      "Subject: 12/0  Epoch:   2  Loss: 0.432577/1.85023  Validation accuracy: 0.49\n",
      "Test accuracy for run 12/0: 0.9337349397590361\n",
      "Subject: 12/1  Epoch:   0  Loss: 0.0608747/0.306254  Validation accuracy: 0.58\n",
      "Subject: 12/1  Epoch:   1  Loss: 0.0558453/0.0357613  Validation accuracy: 0.55\n",
      "Subject: 12/1  Epoch:   2  Loss: 0.185971/0.00199741  Validation accuracy: 0.65\n",
      "Test accuracy for run 12/1: 0.9879518072289156\n",
      "Subject: 12/2  Epoch:   0  Loss: 1.01213/4.30349  Validation accuracy: 0.38\n",
      "Subject: 12/2  Epoch:   1  Loss: 2.95657/3.10844  Validation accuracy: 0.37\n",
      "Test accuracy for run 12/2: 0.9518072289156626\n",
      "Subject: 13/0  Epoch:   0  Loss: 1.94882/0.756873  Validation accuracy: 0.56\n",
      "Subject: 13/0  Epoch:   1  Loss: 0.182806/0.0430931  Validation accuracy: 0.65\n",
      "Subject: 13/0  Epoch:   2  Loss: 0.223615/0.0282224  Validation accuracy: 0.53\n",
      "Test accuracy for run 13/0: 0.478494623655914\n",
      "Subject: 13/1  Epoch:   0  Loss: 0.642021/0.393788  Validation accuracy: 0.85\n",
      "Subject: 13/1  Epoch:   1  Loss: 0.286894/0.0657557  Validation accuracy: 0.91\n",
      "Subject: 13/1  Epoch:   2  Loss: 0.328423/0.982777  Validation accuracy: 0.53\n",
      "Test accuracy for run 13/1: 0.482078853046595\n",
      "Subject: 13/2  Epoch:   0  Loss: 0.995079/0.00137061  Validation accuracy: 0.54\n",
      "Subject: 13/2  Epoch:   1  Loss: 0.745757/1.99458  Validation accuracy: 0.68\n",
      "Test accuracy for run 13/2: 0.46953405017921146\n",
      "Subject: 14/0  Epoch:   0  Loss: 0.0123403/0.133799  Validation accuracy: 0.78\n",
      "Subject: 14/0  Epoch:   1  Loss: 6.55234/1.68158e-05  Validation accuracy: 0.44\n",
      "Subject: 14/0  Epoch:   2  Loss: 4.76837e-07/0.0203318  Validation accuracy: 0.73\n",
      "Test accuracy for run 14/0: 0.4762979683972912\n",
      "Subject: 14/1  Epoch:   0  Loss: 0.348175/0.126347  Validation accuracy: 0.67\n",
      "Subject: 14/1  Epoch:   1  Loss: 0.13396/0.073345  Validation accuracy: 0.57\n",
      "Test accuracy for run 14/1: 0.6117381489841986\n",
      "Subject: 14/2  Epoch:   0  Loss: 0.605951/2.72092  Validation accuracy: 0.65\n",
      "Subject: 14/2  Epoch:   1  Loss: 0.0037612/0.491345  Validation accuracy: 0.87\n",
      "Subject: 14/2  Epoch:   2  Loss: 0.837753/1.45159  Validation accuracy: 0.82\n",
      "Test accuracy for run 14/2: 0.4469525959367946\n",
      "Subject: 15/0  Epoch:   0  Loss: 0.161603/3.27331  Validation accuracy: 0.37\n",
      "Subject: 15/0  Epoch:   1  Loss: 0.504695/6.39632  Validation accuracy: 0.37\n",
      "Subject: 15/0  Epoch:   2  Loss: 0.00854197/7.02647  Validation accuracy: 0.48\n",
      "Test accuracy for run 15/0: 0.5944798301486199\n",
      "Subject: 15/1  Epoch:   0  Loss: 3.72568/2.27019  Validation accuracy: 0.51\n",
      "Subject: 15/1  Epoch:   1  Loss: 0.295713/2.10553  Validation accuracy: 0.57\n",
      "Subject: 15/1  Epoch:   2  Loss: 0.00343891/0.0818174  Validation accuracy: 0.51\n",
      "Test accuracy for run 15/1: 0.6878980891719745\n",
      "Subject: 15/2  Epoch:   0  Loss: 0.385618/1.69846  Validation accuracy: 0.51\n",
      "Subject: 15/2  Epoch:   1  Loss: 0.0970436/2.69491  Validation accuracy: 0.49\n",
      "Test accuracy for run 15/2: 0.583864118895966\n",
      "Test accuracies:\n",
      "[0.5484351713859911, 0.7162417374881964, 0.5866261398176292, 0.7479474548440065, 0.5071368597816961, 0.686436024162548, 0.6463826910074375, 0.7768903088391906, 0.687819110138585, 0.598738476467734, 0.716120745022479, 0.2935560859188544, 0.9578313253012047, 0.4767025089605735, 0.5116629044394282, 0.6220806794055201]\n",
      "Mean accuracy: 0.6300380139363172\n",
      "Training transformer model for 0 and 2...\n",
      "Shape of dataset: (220827, 100)\n",
      "Subject: 0/0  Epoch:   0  Loss: 1.12054e-05/13.8112  Validation accuracy: 0.43\n",
      "Subject: 0/0  Epoch:   1  Loss: 5.35406/0.545419  Validation accuracy: 0.50\n",
      "Subject: 0/0  Epoch:   2  Loss: 0.000168577/1.47304  Validation accuracy: 0.37\n",
      "Test accuracy for run 0/0: 0.302158273381295\n",
      "Subject: 0/1  Epoch:   0  Loss: 3.26333/1.66225  Validation accuracy: 0.57\n",
      "Subject: 0/1  Epoch:   1  Loss: 0.231171/1.36073  Validation accuracy: 0.69\n",
      "Subject: 0/1  Epoch:   2  Loss: 1.87348/1.94348  Validation accuracy: 0.71\n",
      "Test accuracy for run 0/1: 0.31654676258992803\n",
      "Subject: 0/2  Epoch:   0  Loss: 1.79743/0.686133  Validation accuracy: 0.80\n",
      "Subject: 0/2  Epoch:   1  Loss: 0.0187709/2.61164  Validation accuracy: 0.57\n",
      "Subject: 0/2  Epoch:   2  Loss: 0.00862764/1.92366  Validation accuracy: 0.60\n",
      "Test accuracy for run 0/2: 0.4316546762589928\n",
      "Subject: 1/0  Epoch:   0  Loss: 1.1361/6.17345  Validation accuracy: 0.63\n",
      "Subject: 1/0  Epoch:   1  Loss: 0.142113/3.58292  Validation accuracy: 0.71\n",
      "Subject: 1/0  Epoch:   2  Loss: 2.06621/2.95092  Validation accuracy: 0.67\n",
      "Test accuracy for run 1/0: 0.6220095693779905\n",
      "Subject: 1/1  Epoch:   0  Loss: 0.719265/4.1401  Validation accuracy: 0.77\n",
      "Subject: 1/1  Epoch:   1  Loss: 0.717797/13.8898  Validation accuracy: 0.67\n",
      "Subject: 1/1  Epoch:   2  Loss: 0.0163996/7.45404  Validation accuracy: 0.73\n",
      "Test accuracy for run 1/1: 0.6507177033492823\n",
      "Subject: 1/2  Epoch:   0  Loss: 1.62988/1.21074  Validation accuracy: 0.75\n",
      "Subject: 1/2  Epoch:   1  Loss: 1.4732/2.97774  Validation accuracy: 0.67\n",
      "Test accuracy for run 1/2: 0.6220095693779905\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.773608/2.17898  Validation accuracy: 0.77\n",
      "Subject: 2/0  Epoch:   1  Loss: 2.2393/0.706697  Validation accuracy: 0.82\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.00857719/0.605149  Validation accuracy: 0.85\n",
      "Test accuracy for run 2/0: 0.7026022304832714\n",
      "Subject: 2/1  Epoch:   0  Loss: 1.15299/2.06788  Validation accuracy: 0.80\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.660972/3.36846  Validation accuracy: 0.80\n",
      "Test accuracy for run 2/1: 0.7360594795539034\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.833838/0.00157765  Validation accuracy: 0.50\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.183983/0.0162691  Validation accuracy: 0.50\n",
      "Test accuracy for run 2/2: 0.7286245353159851\n",
      "Subject: 3/0  Epoch:   0  Loss: 7.07396/9.43267  Validation accuracy: 0.53\n",
      "Subject: 3/0  Epoch:   1  Loss: 0.439736/1.75066  Validation accuracy: 0.80\n",
      "Subject: 3/0  Epoch:   2  Loss: 0.360714/3.49434  Validation accuracy: 0.73\n",
      "Test accuracy for run 3/0: 0.4681372549019608\n",
      "Subject: 3/1  Epoch:   0  Loss: 4.21403/0.78325  Validation accuracy: 0.67\n",
      "Subject: 3/1  Epoch:   1  Loss: 8.80635e-05/2.95533  Validation accuracy: 0.60\n",
      "Test accuracy for run 3/1: 0.47549019607843135\n",
      "Subject: 3/2  Epoch:   0  Loss: 0.473393/0.0119345  Validation accuracy: 0.61\n",
      "Subject: 3/2  Epoch:   1  Loss: 0.0945148/0.00451438  Validation accuracy: 0.67\n",
      "Test accuracy for run 3/2: 0.41421568627450983\n",
      "Subject: 4/0  Epoch:   0  Loss: 0.80974/3.43587  Validation accuracy: 0.39\n",
      "Subject: 4/0  Epoch:   1  Loss: 0.601895/3.10679  Validation accuracy: 0.43\n",
      "Subject: 4/0  Epoch:   2  Loss: 0.188896/8.49454  Validation accuracy: 0.76\n",
      "Test accuracy for run 4/0: 0.543859649122807\n",
      "Subject: 4/1  Epoch:   0  Loss: 1.36676/2.93794  Validation accuracy: 0.58\n",
      "Subject: 4/1  Epoch:   1  Loss: 0.846548/7.3907e-05  Validation accuracy: 0.70\n",
      "Test accuracy for run 4/1: 0.5789473684210527\n",
      "Subject: 4/2  Epoch:   0  Loss: 8.83461/14.2599  Validation accuracy: 0.47\n",
      "Subject: 4/2  Epoch:   1  Loss: 0.30395/0.435362  Validation accuracy: 0.82\n",
      "Subject: 4/2  Epoch:   2  Loss: 0.123185/0.350623  Validation accuracy: 0.82\n",
      "Test accuracy for run 4/2: 0.543859649122807\n",
      "Subject: 5/0  Epoch:   0  Loss: 0.683786/4.69578  Validation accuracy: 0.54\n",
      "Subject: 5/0  Epoch:   1  Loss: 0.0829656/2.77736  Validation accuracy: 0.44\n",
      "Subject: 5/0  Epoch:   2  Loss: 0.275083/2.08091  Validation accuracy: 0.69\n",
      "Test accuracy for run 5/0: 0.5601965601965602\n",
      "Subject: 5/1  Epoch:   0  Loss: 0.346693/0.0371985  Validation accuracy: 1.00\n",
      "Subject: 5/1  Epoch:   1  Loss: 0.13245/0.0391928  Validation accuracy: 1.00\n",
      "Subject: 5/1  Epoch:   2  Loss: 1.05685/2.08629  Validation accuracy: 0.63\n",
      "Test accuracy for run 5/1: 0.769041769041769\n",
      "Subject: 5/2  Epoch:   0  Loss: 2.65407/0.0892474  Validation accuracy: 0.88\n",
      "Subject: 5/2  Epoch:   1  Loss: 0.326494/0.192475  Validation accuracy: 0.85\n",
      "Test accuracy for run 5/2: 0.6683046683046683\n",
      "Subject: 6/0  Epoch:   0  Loss: 1.14471/4.39323  Validation accuracy: 0.50\n",
      "Subject: 6/0  Epoch:   1  Loss: 1.00629/3.45949  Validation accuracy: 0.53\n",
      "Subject: 6/0  Epoch:   2  Loss: 0.675914/4.37687  Validation accuracy: 0.43\n",
      "Test accuracy for run 6/0: 0.615916955017301\n",
      "Subject: 6/1  Epoch:   0  Loss: 6.32617/9.74481  Validation accuracy: 0.75\n",
      "Subject: 6/1  Epoch:   1  Loss: 0.0/12.3901  Validation accuracy: 0.73\n",
      "Subject: 6/1  Epoch:   2  Loss: 2.30633/9.93142  Validation accuracy: 0.75\n",
      "Test accuracy for run 6/1: 0.6885813148788927\n",
      "Subject: 6/2  Epoch:   0  Loss: 0.839266/1.68669  Validation accuracy: 0.73\n",
      "Subject: 6/2  Epoch:   1  Loss: 0.279011/1.70787  Validation accuracy: 0.63\n",
      "Test accuracy for run 6/2: 0.7024221453287197\n",
      "Subject: 7/0  Epoch:   0  Loss: 0.242027/2.81456  Validation accuracy: 0.48\n",
      "Subject: 7/0  Epoch:   1  Loss: 0.529233/3.43441  Validation accuracy: 0.52\n",
      "Subject: 7/0  Epoch:   2  Loss: 0.0107091/3.12359  Validation accuracy: 0.34\n",
      "Test accuracy for run 7/0: 0.7818930041152263\n",
      "Subject: 7/1  Epoch:   0  Loss: 1.45348/11.5291  Validation accuracy: 0.51\n",
      "Subject: 7/1  Epoch:   1  Loss: 1.62357/4.31012  Validation accuracy: 0.53\n",
      "Subject: 7/1  Epoch:   2  Loss: 0.174474/4.15944  Validation accuracy: 0.53\n",
      "Test accuracy for run 7/1: 0.7325102880658436\n",
      "Subject: 7/2  Epoch:   0  Loss: 1.23598/6.35482  Validation accuracy: 0.53\n",
      "Subject: 7/2  Epoch:   1  Loss: 1.22625/4.90645  Validation accuracy: 0.53\n",
      "Test accuracy for run 7/2: 0.7037037037037037\n",
      "Subject: 8/0  Epoch:   0  Loss: 4.20319/8.48062  Validation accuracy: 0.45\n",
      "Subject: 8/0  Epoch:   1  Loss: 0.000524741/5.38915  Validation accuracy: 0.36\n",
      "Subject: 8/0  Epoch:   2  Loss: 3.60006e-05/8.32215  Validation accuracy: 0.34\n",
      "Test accuracy for run 8/0: 0.6529411764705882\n",
      "Subject: 8/1  Epoch:   0  Loss: 0.238282/3.33155  Validation accuracy: 0.73\n",
      "Subject: 8/1  Epoch:   1  Loss: 0.501285/2.58503  Validation accuracy: 0.73\n",
      "Subject: 8/1  Epoch:   2  Loss: 0.114031/1.52291  Validation accuracy: 0.81\n",
      "Test accuracy for run 8/1: 0.6058823529411764\n",
      "Subject: 8/2  Epoch:   0  Loss: 0.846801/3.83372  Validation accuracy: 0.57\n",
      "Subject: 8/2  Epoch:   1  Loss: 0.671725/2.19962  Validation accuracy: 0.50\n",
      "Test accuracy for run 8/2: 0.5117647058823529\n",
      "Subject: 9/0  Epoch:   0  Loss: 10.6852/5.64517  Validation accuracy: 0.34\n",
      "Subject: 9/0  Epoch:   1  Loss: 0.00569377/2.09934  Validation accuracy: 0.37\n",
      "Subject: 9/0  Epoch:   2  Loss: 0.0357818/2.04583  Validation accuracy: 0.34\n",
      "Test accuracy for run 9/0: 0.43389830508474575\n",
      "Subject: 9/1  Epoch:   0  Loss: 8.31341/6.02966  Validation accuracy: 0.59\n",
      "Subject: 9/1  Epoch:   1  Loss: 0.87351/2.04814  Validation accuracy: 0.58\n",
      "Subject: 9/1  Epoch:   2  Loss: 0.0254117/0.159302  Validation accuracy: 0.56\n",
      "Test accuracy for run 9/1: 0.34915254237288135\n",
      "Subject: 9/2  Epoch:   0  Loss: 0.360097/1.37089e-05  Validation accuracy: 0.52\n",
      "Subject: 9/2  Epoch:   1  Loss: 0.25177/0.130911  Validation accuracy: 0.61\n",
      "Subject: 9/2  Epoch:   2  Loss: 0.00168974/8.58864e-05  Validation accuracy: 0.52\n",
      "Test accuracy for run 9/2: 0.511864406779661\n",
      "Subject: 10/0  Epoch:   0  Loss: 2.38419e-07/11.8861  Validation accuracy: 0.51\n",
      "Subject: 10/0  Epoch:   1  Loss: 0.121046/4.27074  Validation accuracy: 0.53\n",
      "Subject: 10/0  Epoch:   2  Loss: 0.133651/3.17516  Validation accuracy: 0.51\n",
      "Test accuracy for run 10/0: 0.409375\n",
      "Subject: 10/1  Epoch:   0  Loss: 2.24234/0.252429  Validation accuracy: 0.88\n",
      "Subject: 10/1  Epoch:   1  Loss: 0.194649/0.0313834  Validation accuracy: 0.52\n",
      "Subject: 10/1  Epoch:   2  Loss: 0.00534205/0.486819  Validation accuracy: 0.85\n",
      "Test accuracy for run 10/1: 0.440625\n",
      "Subject: 10/2  Epoch:   0  Loss: 0.607897/0.445331  Validation accuracy: 0.67\n",
      "Subject: 10/2  Epoch:   1  Loss: 0.382073/0.422574  Validation accuracy: 0.73\n",
      "Test accuracy for run 10/2: 0.396875\n",
      "Subject: 11/0  Epoch:   0  Loss: 1.95733/6.44748  Validation accuracy: 0.51\n",
      "Subject: 11/0  Epoch:   1  Loss: 0.0992537/3.65677  Validation accuracy: 0.50\n",
      "Subject: 11/0  Epoch:   2  Loss: 0.179569/4.09305  Validation accuracy: 0.51\n",
      "Test accuracy for run 11/0: 0.5724815724815725\n",
      "Subject: 11/1  Epoch:   0  Loss: 9.76915/20.8205  Validation accuracy: 0.34\n",
      "Subject: 11/1  Epoch:   1  Loss: 0.194487/1.04991  Validation accuracy: 0.80\n",
      "Subject: 11/1  Epoch:   2  Loss: 0.537094/0.251325  Validation accuracy: 0.85\n",
      "Test accuracy for run 11/1: 0.4348894348894349\n",
      "Subject: 11/2  Epoch:   0  Loss: 1.91363/0.769611  Validation accuracy: 0.62\n",
      "Subject: 11/2  Epoch:   1  Loss: 0.990846/0.505701  Validation accuracy: 0.60\n",
      "Test accuracy for run 11/2: 0.5921375921375921\n",
      "Subject: 12/0  Epoch:   0  Loss: 3.33452/2.06538  Validation accuracy: 0.73\n",
      "Subject: 12/0  Epoch:   1  Loss: 0.161738/2.18692  Validation accuracy: 0.79\n",
      "Subject: 12/0  Epoch:   2  Loss: 0.0867796/2.30046  Validation accuracy: 0.65\n",
      "Test accuracy for run 12/0: 0.9281767955801105\n",
      "Subject: 12/1  Epoch:   0  Loss: 0.725337/0.364405  Validation accuracy: 0.85\n",
      "Subject: 12/1  Epoch:   1  Loss: 0.416646/0.397391  Validation accuracy: 0.54\n",
      "Subject: 12/1  Epoch:   2  Loss: 0.07934/0.367917  Validation accuracy: 0.59\n",
      "Test accuracy for run 12/1: 0.8784530386740331\n",
      "Subject: 12/2  Epoch:   0  Loss: 0.744568/0.375914  Validation accuracy: 0.46\n",
      "Subject: 12/2  Epoch:   1  Loss: 0.776343/1.3696  Validation accuracy: 0.34\n",
      "Test accuracy for run 12/2: 0.9226519337016574\n",
      "Subject: 13/0  Epoch:   0  Loss: 1.54279/1.83629  Validation accuracy: 0.70\n",
      "Subject: 13/0  Epoch:   1  Loss: 1.62948/2.63616  Validation accuracy: 0.60\n",
      "Subject: 13/0  Epoch:   2  Loss: 0.0633693/0.151693  Validation accuracy: 0.93\n",
      "Test accuracy for run 13/0: 0.5299145299145299\n",
      "Subject: 13/1  Epoch:   0  Loss: 4.76837e-07/28.5345  Validation accuracy: 0.65\n",
      "Subject: 13/1  Epoch:   1  Loss: 7.15256e-07/3.16186  Validation accuracy: 0.39\n",
      "Test accuracy for run 13/1: 0.5441595441595442\n",
      "Subject: 13/2  Epoch:   0  Loss: 0.200207/0.284924  Validation accuracy: 0.83\n",
      "Subject: 13/2  Epoch:   1  Loss: 0.431614/0.57455  Validation accuracy: 0.51\n",
      "Test accuracy for run 13/2: 0.5156695156695157\n",
      "Subject: 14/0  Epoch:   0  Loss: 0.00411765/0.933284  Validation accuracy: 0.44\n",
      "Subject: 14/0  Epoch:   1  Loss: 1.31129e-05/3.06329  Validation accuracy: 0.31\n",
      "Subject: 14/0  Epoch:   2  Loss: 0.0456386/5.00005  Validation accuracy: 0.31\n",
      "Test accuracy for run 14/0: 0.7125506072874493\n",
      "Subject: 14/1  Epoch:   0  Loss: 1.78814e-06/1.48866  Validation accuracy: 0.52\n",
      "Subject: 14/1  Epoch:   1  Loss: 0.0535122/0.0138599  Validation accuracy: 0.48\n",
      "Subject: 14/1  Epoch:   2  Loss: 0.279052/0.850396  Validation accuracy: 0.61\n",
      "Test accuracy for run 14/1: 0.680161943319838\n",
      "Subject: 14/2  Epoch:   0  Loss: 1.55156/1.21196  Validation accuracy: 0.67\n",
      "Subject: 14/2  Epoch:   1  Loss: 0.00630647/2.7746  Validation accuracy: 0.63\n",
      "Subject: 14/2  Epoch:   2  Loss: 0.370861/2.10173  Validation accuracy: 0.70\n",
      "Test accuracy for run 14/2: 0.854251012145749\n",
      "Subject: 15/0  Epoch:   0  Loss: 0.818529/0.447961  Validation accuracy: 0.75\n",
      "Subject: 15/0  Epoch:   1  Loss: 1.11871/0.37827  Validation accuracy: 0.70\n",
      "Subject: 15/0  Epoch:   2  Loss: 0.030689/1.67103  Validation accuracy: 0.75\n",
      "Test accuracy for run 15/0: 0.7425149700598802\n",
      "Subject: 15/1  Epoch:   0  Loss: 0.931412/2.97816  Validation accuracy: 0.73\n",
      "Subject: 15/1  Epoch:   1  Loss: 0.350313/1.56156  Validation accuracy: 0.67\n",
      "Test accuracy for run 15/1: 0.6646706586826348\n",
      "Subject: 15/2  Epoch:   0  Loss: 4.06614/4.04264  Validation accuracy: 0.48\n",
      "Subject: 15/2  Epoch:   1  Loss: 1.34949/2.70483  Validation accuracy: 0.42\n",
      "Test accuracy for run 15/2: 0.7065868263473054\n",
      "Test accuracies:\n",
      "[0.3501199040767386, 0.6315789473684211, 0.7224287484510533, 0.4526143790849673, 0.5555555555555555, 0.6658476658476659, 0.6689734717416379, 0.7393689986282578, 0.5901960784313726, 0.43163841807909603, 0.41562499999999997, 0.5331695331695331, 0.9097605893186004, 0.5299145299145299, 0.7489878542510121, 0.7045908183632735]\n",
      "Mean accuracy: 0.6031481557676073\n",
      "Training transformer model for 0 and 3...\n",
      "Shape of dataset: (221075, 100)\n",
      "Subject: 0/0  Epoch:   0  Loss: 1.31011/1.1673  Validation accuracy: 0.78\n",
      "Subject: 0/0  Epoch:   1  Loss: 0.00786476/1.95218  Validation accuracy: 0.77\n",
      "Subject: 0/0  Epoch:   2  Loss: 0.525591/0.000505235  Validation accuracy: 0.75\n",
      "Test accuracy for run 0/0: 0.6369047619047619\n",
      "Subject: 0/1  Epoch:   0  Loss: 1.53263/1.36935  Validation accuracy: 0.86\n",
      "Subject: 0/1  Epoch:   1  Loss: 0.0948589/1.48136  Validation accuracy: 0.85\n",
      "Subject: 0/1  Epoch:   2  Loss: 0.0319018/2.43766  Validation accuracy: 0.82\n",
      "Test accuracy for run 0/1: 0.6145833333333334\n",
      "Subject: 0/2  Epoch:   0  Loss: 2.44782/3.4182e-05  Validation accuracy: 0.97\n",
      "Subject: 0/2  Epoch:   1  Loss: 0.00967878/0.00717512  Validation accuracy: 0.97\n",
      "Subject: 0/2  Epoch:   2  Loss: 0.72408/2.36928e-06  Validation accuracy: 0.91\n",
      "Test accuracy for run 0/2: 0.6220238095238095\n",
      "Subject: 1/0  Epoch:   0  Loss: 0.915617/12.9599  Validation accuracy: 0.60\n",
      "Subject: 1/0  Epoch:   1  Loss: 0.184049/0.89919  Validation accuracy: 0.60\n",
      "Subject: 1/0  Epoch:   2  Loss: 0.000987006/1.34735  Validation accuracy: 0.60\n",
      "Test accuracy for run 1/0: 0.6452991452991453\n",
      "Subject: 1/1  Epoch:   0  Loss: 0.700375/0.440139  Validation accuracy: 0.83\n",
      "Subject: 1/1  Epoch:   1  Loss: 0.0434411/0.322041  Validation accuracy: 0.81\n",
      "Subject: 1/1  Epoch:   2  Loss: 0.345064/1.07617  Validation accuracy: 0.58\n",
      "Test accuracy for run 1/1: 0.7421652421652422\n",
      "Subject: 1/2  Epoch:   0  Loss: 0.630498/0.0  Validation accuracy: 0.66\n",
      "Subject: 1/2  Epoch:   1  Loss: 0.513842/7.94728e-08  Validation accuracy: 0.63\n",
      "Test accuracy for run 1/2: 0.7307692307692307\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.588019/7.04565  Validation accuracy: 0.65\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.198121/0.326641  Validation accuracy: 0.52\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.590278/5.43896  Validation accuracy: 0.64\n",
      "Test accuracy for run 2/0: 0.6023391812865497\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.856803/0.716006  Validation accuracy: 0.51\n",
      "Subject: 2/1  Epoch:   1  Loss: 1.01627/0.584178  Validation accuracy: 0.51\n",
      "Test accuracy for run 2/1: 0.6023391812865497\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.813736/3.01171  Validation accuracy: 0.89\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.00147299/7.81407  Validation accuracy: 0.89\n",
      "Subject: 2/2  Epoch:   2  Loss: 0.00812229/5.87686  Validation accuracy: 0.86\n",
      "Test accuracy for run 2/2: 0.6038011695906432\n",
      "Subject: 3/0  Epoch:   0  Loss: 0.525195/0.164685  Validation accuracy: 0.67\n",
      "Subject: 3/0  Epoch:   1  Loss: 0.400569/0.0238009  Validation accuracy: 0.69\n",
      "Subject: 3/0  Epoch:   2  Loss: 0.0320608/0.146707  Validation accuracy: 0.64\n",
      "Test accuracy for run 3/0: 0.6646706586826348\n",
      "Subject: 3/1  Epoch:   0  Loss: 0.537464/1.48233  Validation accuracy: 0.86\n",
      "Subject: 3/1  Epoch:   1  Loss: 0.690943/1.86214  Validation accuracy: 0.86\n",
      "Subject: 3/1  Epoch:   2  Loss: 0.0364311/1.78951  Validation accuracy: 0.88\n",
      "Test accuracy for run 3/1: 0.5828343313373253\n",
      "Subject: 3/2  Epoch:   0  Loss: 2.33092/6.5255  Validation accuracy: 0.41\n",
      "Subject: 3/2  Epoch:   1  Loss: 0.226537/2.09043  Validation accuracy: 0.50\n",
      "Test accuracy for run 3/2: 0.7544910179640718\n",
      "Subject: 4/0  Epoch:   0  Loss: 0.0893545/1.6732  Validation accuracy: 0.81\n",
      "Subject: 4/0  Epoch:   1  Loss: 0.153656/1.59768  Validation accuracy: 0.68\n",
      "Subject: 4/0  Epoch:   2  Loss: 2.13079/3.56923  Validation accuracy: 0.68\n",
      "Test accuracy for run 4/0: 0.49\n",
      "Subject: 4/1  Epoch:   0  Loss: 0.797472/0.0466447  Validation accuracy: 0.97\n",
      "Subject: 4/1  Epoch:   1  Loss: 0.0573041/7.70385e-06  Validation accuracy: 0.84\n",
      "Subject: 4/1  Epoch:   2  Loss: 0.066165/1.96246e-05  Validation accuracy: 0.88\n",
      "Test accuracy for run 4/1: 0.598\n",
      "Subject: 4/2  Epoch:   0  Loss: 0.39435/4.17232e-07  Validation accuracy: 1.00\n",
      "Subject: 4/2  Epoch:   1  Loss: 0.128306/1.07288e-06  Validation accuracy: 1.00\n",
      "Subject: 4/2  Epoch:   2  Loss: 0.380642/0.0  Validation accuracy: 1.00\n",
      "Test accuracy for run 4/2: 0.598\n",
      "Subject: 5/0  Epoch:   0  Loss: 0.923139/1.29249  Validation accuracy: 0.36\n",
      "Subject: 5/0  Epoch:   1  Loss: 0.680466/1.60792  Validation accuracy: 0.35\n",
      "Subject: 5/0  Epoch:   2  Loss: 0.00115305/0.54909  Validation accuracy: 0.45\n",
      "Test accuracy for run 5/0: 0.7855421686746988\n",
      "Subject: 5/1  Epoch:   0  Loss: 0.0/0.0  Validation accuracy: 1.00\n",
      "Subject: 5/1  Epoch:   1  Loss: 2.46161e-05/0.0  Validation accuracy: 0.99\n",
      "Subject: 5/1  Epoch:   2  Loss: 0.00487754/0.0  Validation accuracy: 0.92\n",
      "Test accuracy for run 5/1: 0.8048192771084337\n",
      "Subject: 5/2  Epoch:   0  Loss: 0.970078/0.792545  Validation accuracy: 0.55\n",
      "Subject: 5/2  Epoch:   1  Loss: 0.0612425/0.872195  Validation accuracy: 0.57\n",
      "Test accuracy for run 5/2: 0.7855421686746988\n",
      "Subject: 6/0  Epoch:   0  Loss: 1.53552/1.2337  Validation accuracy: 0.79\n",
      "Subject: 6/0  Epoch:   1  Loss: 0.326556/0.000232441  Validation accuracy: 0.80\n",
      "Subject: 6/0  Epoch:   2  Loss: 0.177431/0.0194716  Validation accuracy: 0.85\n",
      "Test accuracy for run 6/0: 0.7782340862422998\n",
      "Subject: 6/1  Epoch:   0  Loss: 0.478509/0.0  Validation accuracy: 0.69\n",
      "Subject: 6/1  Epoch:   1  Loss: 0.00228367/0.0  Validation accuracy: 0.65\n",
      "Test accuracy for run 6/1: 0.7002053388090349\n",
      "Subject: 6/2  Epoch:   0  Loss: 0.810603/0.0  Validation accuracy: 0.64\n",
      "Subject: 6/2  Epoch:   1  Loss: 0.0373218/0.0  Validation accuracy: 0.64\n",
      "Test accuracy for run 6/2: 0.7659137577002053\n",
      "Subject: 7/0  Epoch:   0  Loss: 0.0967778/0.171329  Validation accuracy: 0.84\n",
      "Subject: 7/0  Epoch:   1  Loss: 0.0736469/0.00311864  Validation accuracy: 0.84\n",
      "Subject: 7/0  Epoch:   2  Loss: 0.0156036/0.0021551  Validation accuracy: 0.84\n",
      "Test accuracy for run 7/0: 0.8244766505636071\n",
      "Subject: 7/1  Epoch:   0  Loss: 1.31783/1.84087  Validation accuracy: 0.56\n",
      "Subject: 7/1  Epoch:   1  Loss: 0.42924/1.36989  Validation accuracy: 0.62\n",
      "Test accuracy for run 7/1: 0.7600644122383253\n",
      "Subject: 7/2  Epoch:   0  Loss: 0.317596/2.90519  Validation accuracy: 0.70\n",
      "Subject: 7/2  Epoch:   1  Loss: 0.0602271/0.653135  Validation accuracy: 0.65\n",
      "Test accuracy for run 7/2: 0.7971014492753623\n",
      "Subject: 8/0  Epoch:   0  Loss: 1.1917/0.713562  Validation accuracy: 0.70\n",
      "Subject: 8/0  Epoch:   1  Loss: 0.0873244/0.60526  Validation accuracy: 0.88\n",
      "Subject: 8/0  Epoch:   2  Loss: 2.06887/1.93229  Validation accuracy: 0.50\n",
      "Test accuracy for run 8/0: 0.7650862068965517\n",
      "Subject: 8/1  Epoch:   0  Loss: 0.668297/0.511694  Validation accuracy: 0.57\n",
      "Subject: 8/1  Epoch:   1  Loss: 0.0143048/1.46426  Validation accuracy: 0.60\n",
      "Test accuracy for run 8/1: 0.7047413793103449\n",
      "Subject: 8/2  Epoch:   0  Loss: 0.7408/3.97364e-08  Validation accuracy: 0.77\n",
      "Subject: 8/2  Epoch:   1  Loss: 0.0819225/3.97364e-08  Validation accuracy: 0.62\n",
      "Test accuracy for run 8/2: 0.7262931034482759\n",
      "Subject: 9/0  Epoch:   0  Loss: 3.67666/0.00818724  Validation accuracy: 0.60\n",
      "Subject: 9/0  Epoch:   1  Loss: 0.00541182/9.33798e-06  Validation accuracy: 0.60\n",
      "Subject: 9/0  Epoch:   2  Loss: 0.0200355/3.97364e-07  Validation accuracy: 0.61\n",
      "Test accuracy for run 9/0: 0.7398843930635838\n",
      "Subject: 9/1  Epoch:   0  Loss: 2.33597/0.322773  Validation accuracy: 0.93\n",
      "Subject: 9/1  Epoch:   1  Loss: 0.16269/4.08506  Validation accuracy: 0.83\n",
      "Subject: 9/1  Epoch:   2  Loss: 0.199443/2.2629  Validation accuracy: 0.88\n",
      "Test accuracy for run 9/1: 0.8395953757225434\n",
      "Subject: 9/2  Epoch:   0  Loss: 0.662422/4.96364  Validation accuracy: 0.61\n",
      "Subject: 9/2  Epoch:   1  Loss: 0.246906/1.82997  Validation accuracy: 0.54\n",
      "Test accuracy for run 9/2: 0.8208092485549133\n",
      "Subject: 10/0  Epoch:   0  Loss: 0.223054/2.54798  Validation accuracy: 0.90\n",
      "Subject: 10/0  Epoch:   1  Loss: 0.123977/1.96592  Validation accuracy: 0.80\n",
      "Subject: 10/0  Epoch:   2  Loss: 0.174576/0.999835  Validation accuracy: 0.61\n",
      "Test accuracy for run 10/0: 0.9211045364891519\n",
      "Subject: 10/1  Epoch:   0  Loss: 1.11715/1.17624  Validation accuracy: 0.57\n",
      "Subject: 10/1  Epoch:   1  Loss: 0.090265/1.48195  Validation accuracy: 0.65\n",
      "Test accuracy for run 10/1: 0.9132149901380671\n",
      "Subject: 10/2  Epoch:   0  Loss: 1.47887/0.0851604  Validation accuracy: 0.55\n",
      "Subject: 10/2  Epoch:   1  Loss: 0.14644/0.200188  Validation accuracy: 0.50\n",
      "Test accuracy for run 10/2: 0.8915187376725838\n",
      "Subject: 11/0  Epoch:   0  Loss: 0.448548/0.0  Validation accuracy: 0.72\n",
      "Subject: 11/0  Epoch:   1  Loss: 2.54017/7.94728e-08  Validation accuracy: 0.69\n",
      "Subject: 11/0  Epoch:   2  Loss: 1.13249e-06/1.11262e-06  Validation accuracy: 0.60\n",
      "Test accuracy for run 11/0: 0.4921875\n",
      "Subject: 11/1  Epoch:   0  Loss: 0.00748385/1.9187  Validation accuracy: 0.63\n",
      "Subject: 11/1  Epoch:   1  Loss: 1.31456/0.0281656  Validation accuracy: 0.45\n",
      "Test accuracy for run 11/1: 0.533203125\n",
      "Subject: 11/2  Epoch:   0  Loss: 1.84767/3.32103  Validation accuracy: 0.82\n",
      "Subject: 11/2  Epoch:   1  Loss: 0.00172814/2.57923  Validation accuracy: 0.81\n",
      "Subject: 11/2  Epoch:   2  Loss: 0.46065/3.26337  Validation accuracy: 0.81\n",
      "Test accuracy for run 11/2: 0.44921875\n",
      "Subject: 12/0  Epoch:   0  Loss: 1.04867/1.23046  Validation accuracy: 0.74\n",
      "Subject: 12/0  Epoch:   1  Loss: 1.16546/1.03929  Validation accuracy: 0.74\n",
      "Subject: 12/0  Epoch:   2  Loss: 0.00175295/0.728649  Validation accuracy: 0.73\n",
      "Test accuracy for run 12/0: 0.9966216216216216\n",
      "Subject: 12/1  Epoch:   0  Loss: 0.225775/1.69329  Validation accuracy: 0.64\n",
      "Subject: 12/1  Epoch:   1  Loss: 1.35686/1.36083  Validation accuracy: 0.56\n",
      "Test accuracy for run 12/1: 1.0\n",
      "Subject: 12/2  Epoch:   0  Loss: 0.00577554/0.0241349  Validation accuracy: 0.60\n",
      "Subject: 12/2  Epoch:   1  Loss: 0.237732/1.47904  Validation accuracy: 0.53\n",
      "Test accuracy for run 12/2: 1.0\n",
      "Subject: 13/0  Epoch:   0  Loss: 0.478062/0.0695728  Validation accuracy: 0.64\n",
      "Subject: 13/0  Epoch:   1  Loss: 0.503435/1.2249  Validation accuracy: 0.81\n",
      "Subject: 13/0  Epoch:   2  Loss: 0.358088/0.0254949  Validation accuracy: 0.78\n",
      "Test accuracy for run 13/0: 0.6577777777777778\n",
      "Subject: 13/1  Epoch:   0  Loss: 0.117286/2.03546e-05  Validation accuracy: 1.00\n",
      "Subject: 13/1  Epoch:   1  Loss: 0.0344334/2.38419e-07  Validation accuracy: 1.00\n",
      "Subject: 13/1  Epoch:   2  Loss: 0.0145146/2.68221e-07  Validation accuracy: 1.00\n",
      "Test accuracy for run 13/1: 0.8355555555555556\n",
      "Subject: 13/2  Epoch:   0  Loss: 0.557373/1.96132  Validation accuracy: 0.45\n",
      "Subject: 13/2  Epoch:   1  Loss: 0.249668/1.78702  Validation accuracy: 0.55\n",
      "Test accuracy for run 13/2: 0.7511111111111111\n",
      "Subject: 14/0  Epoch:   0  Loss: 1.03959/0.0115313  Validation accuracy: 0.81\n",
      "Subject: 14/0  Epoch:   1  Loss: 0.294142/0.0376152  Validation accuracy: 0.69\n",
      "Subject: 14/0  Epoch:   2  Loss: 4.07893/0.00440454  Validation accuracy: 0.74\n",
      "Test accuracy for run 14/0: 0.6754385964912281\n",
      "Subject: 14/1  Epoch:   0  Loss: 0.459561/0.955633  Validation accuracy: 0.78\n",
      "Subject: 14/1  Epoch:   1  Loss: 0.390991/0.824902  Validation accuracy: 0.83\n",
      "Subject: 14/1  Epoch:   2  Loss: 0.0577593/0.80102  Validation accuracy: 0.87\n",
      "Test accuracy for run 14/1: 0.5855263157894737\n",
      "Subject: 14/2  Epoch:   0  Loss: 2.84995/2.48737  Validation accuracy: 0.79\n",
      "Subject: 14/2  Epoch:   1  Loss: 0.0159682/3.06497  Validation accuracy: 0.44\n",
      "Test accuracy for run 14/2: 0.6644736842105263\n",
      "Subject: 15/0  Epoch:   0  Loss: 0.0726369/0.000105925  Validation accuracy: 0.60\n",
      "Subject: 15/0  Epoch:   1  Loss: 0.514672/0.0163369  Validation accuracy: 0.60\n",
      "Subject: 15/0  Epoch:   2  Loss: 0.0129465/8.10616e-06  Validation accuracy: 0.61\n",
      "Test accuracy for run 15/0: 0.7947826086956522\n",
      "Subject: 15/1  Epoch:   0  Loss: 0.344849/0.83461  Validation accuracy: 0.67\n",
      "Subject: 15/1  Epoch:   1  Loss: 0.990162/2.6446  Validation accuracy: 0.71\n",
      "Subject: 15/1  Epoch:   2  Loss: 0.154048/2.46782  Validation accuracy: 0.58\n",
      "Test accuracy for run 15/1: 0.7843478260869565\n",
      "Subject: 15/2  Epoch:   0  Loss: 0.702304/1.53618  Validation accuracy: 0.73\n",
      "Subject: 15/2  Epoch:   1  Loss: 0.070979/0.683896  Validation accuracy: 0.85\n",
      "Subject: 15/2  Epoch:   2  Loss: 0.0233464/1.26533  Validation accuracy: 0.87\n",
      "Test accuracy for run 15/2: 0.7617391304347826\n",
      "Test accuracies:\n",
      "[0.6245039682539683, 0.7060778727445394, 0.6028265107212475, 0.667332002661344, 0.5619999999999999, 0.7919678714859438, 0.7481177275838468, 0.7938808373590982, 0.7320402298850576, 0.8000963391136802, 0.908612754766601, 0.4915364583333333, 0.9988738738738738, 0.7481481481481481, 0.641812865497076, 0.7802898550724637]\n",
      "Mean accuracy: 0.7248823322187639\n",
      "Training transformer model for 0 and 4...\n",
      "Shape of dataset: (221248, 100)\n",
      "Subject: 0/0  Epoch:   0  Loss: 0.650801/1.36428  Validation accuracy: 0.82\n",
      "Subject: 0/0  Epoch:   1  Loss: 0.000995111/1.93961  Validation accuracy: 0.76\n",
      "Subject: 0/0  Epoch:   2  Loss: 0.177/2.31635  Validation accuracy: 0.78\n",
      "Test accuracy for run 0/0: 0.7527675276752768\n",
      "Subject: 0/1  Epoch:   0  Loss: 10.8828/0.0  Validation accuracy: 0.84\n",
      "Subject: 0/1  Epoch:   1  Loss: 0.00906738/0.0  Validation accuracy: 0.82\n",
      "Subject: 0/1  Epoch:   2  Loss: 0.000130873/0.0  Validation accuracy: 0.49\n",
      "Test accuracy for run 0/1: 0.7527675276752768\n",
      "Subject: 0/2  Epoch:   0  Loss: 1.96517/2.68221e-06  Validation accuracy: 0.53\n",
      "Subject: 0/2  Epoch:   1  Loss: 0.0414017/0.000375617  Validation accuracy: 0.94\n",
      "Subject: 0/2  Epoch:   2  Loss: 0.0663597/0.00773498  Validation accuracy: 0.98\n",
      "Test accuracy for run 0/2: 0.7601476014760148\n",
      "Subject: 1/0  Epoch:   0  Loss: 1.80446/3.25293  Validation accuracy: 0.45\n",
      "Subject: 1/0  Epoch:   1  Loss: 0.504628/1.28466  Validation accuracy: 0.68\n",
      "Subject: 1/0  Epoch:   2  Loss: 0.276683/4.35828  Validation accuracy: 0.48\n",
      "Test accuracy for run 1/0: 0.7238095238095238\n",
      "Subject: 1/1  Epoch:   0  Loss: 0.254399/0.252856  Validation accuracy: 0.89\n",
      "Subject: 1/1  Epoch:   1  Loss: 0.0549849/0.200671  Validation accuracy: 0.87\n",
      "Subject: 1/1  Epoch:   2  Loss: 0.0656239/0.0665279  Validation accuracy: 1.00\n",
      "Test accuracy for run 1/1: 0.7380952380952381\n",
      "Subject: 1/2  Epoch:   0  Loss: 4.76837e-07/0.411551  Validation accuracy: 0.94\n",
      "Subject: 1/2  Epoch:   1  Loss: 0.0/6.51654  Validation accuracy: 0.68\n",
      "Test accuracy for run 1/2: 0.7476190476190476\n",
      "Subject: 2/0  Epoch:   0  Loss: 3.17345/2.80505  Validation accuracy: 0.85\n",
      "Subject: 2/0  Epoch:   1  Loss: 4.76837e-08/9.83276  Validation accuracy: 0.80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m     23\u001b[0m         list_targets \u001b[38;5;241m=\u001b[39m [i, j]\n\u001b[0;32m---> 24\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_validation_subjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         results_dict[\u001b[38;5;28mtuple\u001b[39m(list_targets)] \u001b[38;5;241m=\u001b[39m accuracy\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_dict)\n",
      "Cell \u001b[0;32mIn[19], line 235\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Validation accuracy\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_subj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m### Early stopping\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m, in \u001b[0;36mvalidation_accuracy\u001b[0;34m(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m Variable(labels)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward propagation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m error(outputs, labels)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Get predictions from the maximum value\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 36\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_enc(src_pos) \u001b[38;5;66;03m# (16, 1000, 100)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m---> 36\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# (query, key, value)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(x \u001b[38;5;241m+\u001b[39m x2)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:5407\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5405\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   5406\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 5407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   5408\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n\u001b[1;32m   5410\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_output_weights, v)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 0: SelfStim\n",
    "# 1: CtrlStim\n",
    "# 2: SelfRest\n",
    "# 3: CtrlRest\n",
    "# 4: SelfSoc\n",
    "# 5: CtrlSoc\n",
    "\n",
    "\n",
    "# train all models\n",
    "for i in range(6):\n",
    "    for j in range(i+1, 6):\n",
    "        list_targets = [i, j]\n",
    "        accuracy = train_model(list_labels,list_targets, epochs, learning_rate, weight_decay, device, num_validation_subjects, train_df)\n",
    "        results_dict[tuple(list_targets)] = accuracy\n",
    "\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input operand has more dimensions than allowed by the axis remapping",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m list_targets, accuracies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults_dict\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create a bar plot\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlist_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mList Targets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:2739\u001b[0m, in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[1;32m   2730\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2737\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2738\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarContainer:\n\u001b[0;32m-> 2739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2744\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2745\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2746\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2747\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2569\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_container(bar_container)\n\u001b[1;32m   2568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tick_labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2569\u001b[0m     tick_labels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtick_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2570\u001b[0m     tick_label_axis\u001b[38;5;241m.\u001b[39mset_ticks(tick_label_position)\n\u001b[1;32m   2571\u001b[0m     tick_label_axis\u001b[38;5;241m.\u001b[39mset_ticklabels(tick_labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/stride_tricks.py:413\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/stride_tricks.py:349\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    347\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    348\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 349\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnditer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrefs_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzerosize_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadonly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitershape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: input operand has more dimensions than allowed by the axis remapping"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mapping between digits and their names\n",
    "label_mapping = {\n",
    "    0: 'SelfStim',\n",
    "    1: 'CtrlStim',\n",
    "    2: 'SelfRest',\n",
    "    3: 'CtrlRest',\n",
    "    4: 'SelfSoc',\n",
    "    5: 'CtrlSoc'\n",
    "}\n",
    "\n",
    "# Replace the digits with their names in list_targets\n",
    "#list_targets_names = [(label_mapping[i], label_mapping[j]) for i, j in results_dict.keys()]\n",
    "\n",
    "# Extract the list of list_targets and accuracy values\n",
    "list_targets, accuracies = zip(*results_dict.items())\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(range(len(list_targets)), accuracies, tick_label=list_targets)\n",
    "plt.xlabel('List Targets')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different List Targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_targets = [0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "csvfile = \"../../data/video/All_Subs_Diff_Modules_nofilter_withoutAUc.csv\"\n",
    "train_df = pd.read_csv(csvfile,  delimiter=\",\")  # 101 features (only AU_r)\n",
    "\n",
    "# Select only the classes we want to predict\n",
    "train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "# Convert the subject names (strings) into numbers\n",
    "subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "# Normalise the features\n",
    "features_numpy = normalize_data(train_df, False) #parameters.normalise_individual_subjects\n",
    "input_dim = features_numpy.shape[1]\n",
    "print(f\"Number of features: {input_dim}\")\n",
    "print(f\"Shape of dataset: {features_numpy.shape}\")\n",
    "\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable we will use throughout the training and testing\n",
    "test_accuracies = []\n",
    "calibrated_test_accuracies = []\n",
    "all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "# Create folder to save models\n",
    "if not os.path.exists(\"../model_transformer/\"):\n",
    "    os.makedirs(\"../model_transformer/\")\n",
    "\n",
    "# Validation accuracy\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "epoch_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Get distinct subjects\n",
    "subj = np.unique(subjects)\n",
    "\n",
    "# Loop over all subjects\n",
    "for test_subj in subj:\n",
    "    xv_max_val = 0\n",
    "    avg_test_acc = 0\n",
    "    val_acc_val_loss_list = []\n",
    "    test_acc_list = []\n",
    "    best_accuracy = 0\n",
    "    file_name = f'../model_cnn/best_model_checkpoint_{list_targets[0]}_{list_targets[1]}_{test_subj}.pth'\n",
    "\n",
    "    # Cross validation\n",
    "    for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "        # Set up the train, validation and test sets\n",
    "        test_idx = np.array([test_subj])\n",
    "\n",
    "        # Take out test subject from trainval (Crooss validation)\n",
    "        trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "        val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "        val_idx = val_idx%len(subj)\n",
    "\n",
    "        # Remove test & validation subjects from trainval\n",
    "        train_idx = np.setxor1d(subj, test_idx)\n",
    "        train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "        #print(\"Generating train/val/test split...\")\n",
    "        features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "        #print(\"Generating sequences...\")\n",
    "        features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "        features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "        \n",
    "        # Overlap or no\n",
    "        if parameters.test_with_subsequences:\n",
    "            features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "        else:\n",
    "            features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "        #print(f\"Number of training examples: {len(targets_train)}\")\n",
    "        #print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "        #print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "        # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "        featuresTrain = torch.from_numpy(features_train)\n",
    "        targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        featuresVal = torch.from_numpy(features_val)\n",
    "        targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        # Pytorch train and validation sets\n",
    "        train = TensorDataset(featuresTrain, targetsTrain)\n",
    "        val = TensorDataset(featuresVal, targetsVal)\n",
    "        \n",
    "        # Data loader\n",
    "        train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "\n",
    "        # Create feature and targets tensor for test set\n",
    "        if parameters.test_with_subsequences:\n",
    "            featuresTest = torch.from_numpy(features_test)\n",
    "            targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "            test = TensorDataset(featuresTest, targetsTest)\n",
    "            test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "        \n",
    "        # Model\n",
    "        model = Transformer(parameters.batch_size, 64).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        error = nn.CrossEntropyLoss()\n",
    "        error_cpu = nn.CrossEntropyLoss().to('cpu')\n",
    "\n",
    "        # Early Stopping\n",
    "        \n",
    "        patience = epochs -1\n",
    "        #patience = 4\n",
    "        current_patience = 0\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = error(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Validation accuracy\n",
    "            accuracy = validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\n",
    "\n",
    "            ### Early stopping\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(model.state_dict(), file_name)\n",
    "                current_patience = 0  # Reset patience counter\n",
    "            else:\n",
    "                current_patience += 1  # No improvement, increase patience counter\n",
    "            \n",
    "            if current_patience >= patience:\n",
    "                # Early stopping condition met\n",
    "                print(f'Early stopping at epoch {epoch} due to lack of improvement.')\n",
    "                break\n",
    "\n",
    "        # Restore the best model checkpoint\n",
    "        model.load_state_dict(torch.load(file_name))\n",
    "    \n",
    "        # Cross validation accuracy\n",
    "        cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj)\n",
    "\n",
    "    avg_test_acc = np.mean(test_acc_list)\n",
    "    test_accuracies.append(avg_test_acc)\n",
    "  \n",
    "print(\"Test accuracies:\")\n",
    "print(test_accuracies)\n",
    "print(f\"Mean accuracy: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = './tr_model_0_3.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding => keep position's information\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div)\n",
    "        pe[:, 1::2] = torch.cos(position * div)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe) # store \"pe\" without gradient update\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x # self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder => compute a rich representation of sequence\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=500, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead) # , dropout=dropout\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2 = self.self_attn(x, x, x)[0]\n",
    "        x = x + self.dropout1(x2)\n",
    "        x = self.norm1(x)\n",
    "        x2 = self.linear2(self.dropout(self.linear1(x)))\n",
    "        x = x + self.dropout2(x2)\n",
    "        x = self.norm2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier replace Decoder => decision instead of generation\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, num_classes, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.encoder_layer = TransformerEncoder(d_model, nhead, dim_feedforward, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pos_encoder(x)\n",
    "        output = self.transformer_encoder(x)\n",
    "        output = self.classifier(output[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "d_model = 1\n",
    "nhead = 10\n",
    "num_layers = 2\n",
    "dim_feedforward = 500\n",
    "num_classes = 2\n",
    "dropout = 0.1\n",
    "# Create the model\n",
    "model = TransformerClassifier(d_model, nhead, num_layers, dim_feedforward, num_classes, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
