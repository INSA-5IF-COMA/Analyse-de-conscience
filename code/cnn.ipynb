{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import sklearn.metrics as metrics\n",
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\n",
    "from torchinfo import summary\n",
    "import parameters\n",
    "import random\n",
    "from data_formatting import split_sequence_overlap, split_sequence_nooverlap, split_sequence, split_train_test, normalize_data, set_targets\n",
    "parameters.initialize_parameters()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim, seq_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Define the architecture with layers based on the input arguments\n",
    "        self.conv1 = nn.Conv1d(seq_dim, 128, 5)\n",
    "        self.conv2 = nn.Conv1d(128, 256, 3)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 3)\n",
    "        self.conv4 = nn.Conv1d(512, 1024,3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Mise Ã  jour de fc_input_size en fonction des couches de pooling\n",
    "        self.fc_input_size = 1024 * ( input_dim - 5 - 3 - 3 - 3 + 4) \n",
    "        self.fc = nn.Linear(self.fc_input_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list):\n",
    "    all_val_predicted = []\n",
    "    all_val_labels = []\n",
    "    all_val_outputs = np.empty((0, nclasses), dtype='float')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate through validation dataset\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = Variable(features.view(-1, parameters.seq_dim, input_dim)).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(features)\n",
    "            val_loss = error(outputs, labels)\n",
    "\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            predicted = predicted.to('cpu')\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cpu()).sum()\n",
    "            all_val_predicted.extend(list(predicted.detach().numpy()))\n",
    "            all_val_labels.extend(list(labels.cpu().detach().numpy()))\n",
    "            all_val_outputs = np.concatenate((all_val_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "    al_np = np.array(all_val_labels)   \n",
    "    ao_np = np.array(all_val_outputs)  \n",
    "    accuracy = correct / float(total)\n",
    "\n",
    "    # store loss and iteration\n",
    "    loss_list.append(loss.data)\n",
    "    val_loss_list.append(val_loss.data)\n",
    "    epoch_list.append(epoch)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Subject: {}/{}  Epoch: {:>3}  Loss: {:.6}/{:.6}  Validation accuracy: {:.2f}'.format(test_subj, xv, epoch, loss, val_loss, accuracy))\n",
    "    return accuracy\n",
    "    \n",
    "def cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    prev_label = -1\n",
    "    class_hist = np.zeros(nclasses, dtype='int')\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "    # Iterate through test dataset\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if parameters.test_with_subsequences:\n",
    "            for features, labels in test_loader:\n",
    "                features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "                labels = Variable(labels).to('cpu')\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(features)\n",
    "                test_loss = error_cpu(outputs.to('cpu'), labels)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                predicted = predicted.to('cpu')\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_predicted.extend(list(predicted.detach().numpy()))\n",
    "                all_labels.extend(list(labels.detach().numpy()))\n",
    "                all_outputs = np.concatenate((all_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "        \n",
    "        else:\n",
    "            count=0\n",
    "            for features in features_test:\n",
    "                features = torch.tensor(features)\n",
    "                features = torch.unsqueeze(features, 0).to(device)\n",
    "                labels = torch.unsqueeze(torch.tensor(targets_test[count]), 0)\n",
    "                features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(features)\n",
    "\n",
    "                test_loss = error(outputs.to('cpu'), labels)\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                predicted = predicted.to('cpu')\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                count += 1\n",
    "\n",
    "        al_np = np.array(all_labels)   \n",
    "        ao_np = np.array(all_outputs)  \n",
    "\n",
    "        accuracy = correct / float(total)\n",
    "\n",
    "        print(f\"Test accuracy for run {test_subj}/{xv}: {accuracy}\")\n",
    "\n",
    "    avg_test_acc += accuracy\n",
    "    test_acc_list.append(accuracy)\n",
    "\n",
    "\n",
    "def train_model(list_labels, list_targets, epochs, learning_rate, weight_decay, device, num_validation_subjects, train_df):\n",
    "    \n",
    "    target_1 = list_targets[0]\n",
    "    target_2 = list_targets[1]\n",
    "\n",
    "    file_name = f'best_model_checkpoint_{target_1}_{target_2}.pth'\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print(f'The file {file_name} has been deleted.')\n",
    "\n",
    "    print(f\"Training model for {target_1} and {target_2}...\")\n",
    "    # Select only the classes we want to predict\n",
    "    train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "    # Convert the subject names (strings) into numbers\n",
    "    subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "    # Normalise the features\n",
    "    features_numpy = normalize_data(train_df, False) #parameters.normalise_individual_subjects\n",
    "    input_dim = features_numpy.shape[1]\n",
    "    #print(f\"Number of features: {input_dim}\")\n",
    "\n",
    "    del train_df\n",
    "    \n",
    "    # Variable we will use throughout the training and testing\n",
    "    test_accuracies = []\n",
    "    calibrated_test_accuracies = []\n",
    "    all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "    # Validation accuracy\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    epoch_list = []\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Get distinct subjects\n",
    "    subj = np.unique(subjects)\n",
    "\n",
    "    # Loop over all subjects\n",
    "    for test_subj in subj:\n",
    "        xv_max_val = 0\n",
    "        avg_test_acc = 0\n",
    "        val_acc_val_loss_list = []\n",
    "        test_acc_list = []\n",
    "        best_accuracy = 0\n",
    "\n",
    "        # Cross validation\n",
    "        for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "            # Set up the train, validation and test sets\n",
    "            test_idx = np.array([test_subj])\n",
    "\n",
    "            # Take out test subject from trainval (Crooss validation)\n",
    "            trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "            val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "            val_idx = val_idx%len(subj)\n",
    "\n",
    "            # Remove test & validation subjects from trainval\n",
    "            train_idx = np.setxor1d(subj, test_idx)\n",
    "            train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "            #print(\"Generating train/val/test split...\")\n",
    "            features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "            #print(\"Generating sequences...\")\n",
    "            features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "            features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "            \n",
    "            # Overlap or no\n",
    "            if parameters.test_with_subsequences:\n",
    "                features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "            else:\n",
    "                features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "            #print(f\"Number of training examples: {len(targets_train)}\")\n",
    "            #print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "            #print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "            # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "            featuresTrain = torch.from_numpy(features_train)\n",
    "            targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "            featuresVal = torch.from_numpy(features_val)\n",
    "            targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "            # Pytorch train and validation sets\n",
    "            train = TensorDataset(featuresTrain, targetsTrain)\n",
    "            val = TensorDataset(featuresVal, targetsVal)\n",
    "            \n",
    "            # Data loader\n",
    "            train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "\n",
    "            # Create feature and targets tensor for test set\n",
    "            if parameters.test_with_subsequences:\n",
    "                featuresTest = torch.from_numpy(features_test)\n",
    "                targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "                test = TensorDataset(featuresTest, targetsTest)\n",
    "                test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "            \n",
    "            # Model\n",
    "            model = CNN(input_dim, parameters.seq_dim).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            error = nn.CrossEntropyLoss()\n",
    "            error_cpu = nn.CrossEntropyLoss().to('cpu')\n",
    "\n",
    "            # Early Stopping\n",
    "            \n",
    "            patience = epochs -1\n",
    "            #patience = 4\n",
    "            current_patience = 0\n",
    "\n",
    "            # Train the model\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                running_loss = 0\n",
    "                for data, target in train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(data)\n",
    "                    loss = error(outputs, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation accuracy\n",
    "                accuracy = validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\n",
    "\n",
    "                ### Early stopping\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    torch.save(model.state_dict(), file_name)\n",
    "                    current_patience = 0  # Reset patience counter\n",
    "                else:\n",
    "                    current_patience += 1  # No improvement, increase patience counter\n",
    "                \n",
    "                if current_patience >= patience:\n",
    "                    # Early stopping condition met\n",
    "                    #print(f'Early stopping at epoch {epoch} due to lack of improvement.')\n",
    "                    break\n",
    "\n",
    "            # Restore the best model checkpoint\n",
    "            model.load_state_dict(torch.load(file_name))\n",
    "        \n",
    "            # Cross validation accuracy\n",
    "            cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj)\n",
    "\n",
    "        avg_test_acc = np.mean(test_acc_list)\n",
    "        test_accuracies.append(avg_test_acc)\n",
    "    \n",
    "    print(\"Test accuracies:\")\n",
    "    print(test_accuracies)\n",
    "    mean_accuracy = np.mean(test_accuracies)\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    return mean_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# Classes we want to predict and binary outputs\n",
    "list_labels = [0, 1]\n",
    "\n",
    "# number of subjects used for validation\n",
    "num_validation_subjects = 1\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 10e-4\n",
    "epochs = 3\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 0 and 4...\n",
      "Test accuracies:\n",
      "[0.6568265682656826, 0.4238095238095238, 0.31198102016607354, 0.7072758037225042, 0.8590381426202321, 0.7420147420147419, 0.7854671280276818, 0.4888888888888889, 0.41814595660749515, 0.6409395973154363, 0.6489028213166144, 0.6108374384236454, 0.5549242424242423, 0.576, 0.5748031496062992, 0.5787545787545788]\n",
      "Mean accuracy: 0.5986631001227276\n",
      "Training model for 0 and 5...\n",
      "Test accuracies:\n",
      "[0.707843137254902, 0.7254901960784315, 0.6073529411764705, 0.6713709677419355, 0.7048748353096178, 0.5260545905707196, 0.959349593495935, 0.9947423764458465, 0.4745547073791349, 0.9066091954022989, 0.9136276391554703, 0.6072607260726072, 0.7297777777777777, 0.5504201680672268, 0.23115942028985506, 0.6329849012775842]\n",
      "Mean accuracy: 0.6839670733434884\n",
      "Training model for 1 and 4...\n",
      "Test accuracies:\n",
      "[0.674074074074074, 0.5912305516265912, 0.4856770833333333, 0.8157019294743845, 1.0, 0.7646076794657763, 0.844368986983588, 0.9726247987117552, 0.5565345080763583, 0.6974683544303798, 0.9284552845528454, 0.6054018445322793, 1.0, 0.9534482758620689, 0.6013309134906232, 0.9936440677966102]\n",
      "Mean accuracy: 0.7802855220256667\n",
      "Training model for 1 and 5...\n",
      "Test accuracies:\n",
      "[0.5561497326203209, 0.5562770562770563, 0.6130952380952381, 0.5008210180623974, 0.6086956521739131, 0.5109983079526227, 0.5811965811965812, 0.5538461538461538, 0.492, 0.5340314136125656, 0.4444444444444444, 0.4625199362041467, 0.7496991576413959, 0.6277777777777778, 0.3651804670912951, 0.5189393939393939]\n",
      "Mean accuracy: 0.5422295206834564\n",
      "Training model for 2 and 4...\n",
      "Test accuracies:\n",
      "[0.5468066491688539, 0.5977564102564102, 0.48548812664907653, 0.8810720268006701, 0.9966996699669967, 0.6766666666666667, 0.7426597582037996, 1.0, 0.5389221556886228, 0.8509212730318257, 0.6217948717948718, 0.747702589807853, 1.0, 0.68, 0.5847457627118644, 0.9161676646706587]\n",
      "Mean accuracy: 0.7417127265886356\n",
      "Training model for 2 and 5...\n",
      "Test accuracies:\n",
      "[0.4628019323671498, 0.6769953051643193, 0.5959725792630677, 0.7549668874172185, 0.6617243272926964, 0.5033557046979866, 0.7509903791737408, 0.9272151898734177, 0.41603053435114506, 0.4811557788944724, 0.5842818428184282, 0.4080267558528428, 0.5710306406685237, 0.8422459893048129, 0.48888888888888893, 0.554561717352415]\n",
      "Mean accuracy: 0.6050152783363203\n",
      "Training model for 3 and 4...\n",
      "Test accuracies:\n",
      "[0.7239506172839506, 0.584045584045584, 0.501891551071879, 0.9494949494949495, 1.0, 0.8729535036018335, 0.9513172966781213, 1.0, 0.5956521739130435, 0.8065326633165829, 1.0, 0.7386489479512736, 0.9789473684210527, 1.0, 0.5879218472468917, 0.9270833333333334]\n",
      "Mean accuracy: 0.826152489772406\n",
      "Training model for 3 and 5...\n",
      "Test accuracies:\n",
      "[0.5161290322580645, 0.6054590570719603, 0.5154639175257731, 0.6180904522613065, 0.7439613526570049, 0.5, 0.6415770609318997, 0.524822695035461, 0.5159176029962547, 0.549828178694158, 0.6484245439469319, 0.4876847290640394, 0.7441441441441441, 0.7894736842105262, 0.5906432748538012, 0.6413043478260869]\n",
      "Mean accuracy: 0.6020577545923382\n",
      "{'0_4': 0.5986631001227276, '0_5': 0.6839670733434884, '1_4': 0.7802855220256667, '1_5': 0.5422295206834564, '2_4': 0.7417127265886356, '2_5': 0.6050152783363203, '3_4': 0.826152489772406, '3_5': 0.6020577545923382}\n"
     ]
    }
   ],
   "source": [
    "# 0: SelfStim\n",
    "# 1: CtrlStim\n",
    "# 2: SelfRest\n",
    "# 3: CtrlRest\n",
    "# 4: SelfSoc\n",
    "# 5: CtrlSoc\n",
    "\n",
    "# Get data\n",
    "csvfile = \"../../data/video/All_Subs_Diff_Modules_nofilter_withoutAUc.csv\"\n",
    "train_df = pd.read_csv(csvfile,  delimiter=\",\")  # 101 features (only AU_r)\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "# train all models\n",
    "for i in range(4):  # Start the outer loop at 1 and end at 4 \n",
    "    for j in range(4, 6):  # Start the inner loop at 5 and end at 6\n",
    "        list_targets = [i, j]\n",
    "        accuracy = train_model(list_labels,list_targets, epochs, learning_rate, weight_decay, device, num_validation_subjects, train_df)\n",
    "        results_dict[tuple(list_targets)] = accuracy\n",
    "\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEqUlEQVR4nO3de1RVdf7/8RcgF1FEFAQlBEXzUiqKingfI+nmqFlpzgjSRJPJZDE1qRWkVjiWSjmWk+Olr2Eympq/ySwHpcaRRpNMrbTRUtTklgWIBgb790fLM504KAeBA9vnY629VnzOZ+/z/uzNyReffTlOhmEYAgAAMAlnRxcAAABQlwg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3wDXiv//9r0aPHi1vb285OTlp8+bNji7JSmZmppycnJSZmWnVvmbNGnXv3l2urq5q3bq1pf2FF15Q586d5eLiorCwsAat1dFWr14tJycnHT9+3NGlAI0S4QZNyiuvvCInJydFREQ4upQmJzY2VgcPHtRzzz2nNWvWqH///vX2XsePH5eTk5NlcXV1la+vrwYPHqzZs2crJyenRts5fPiwpk6dqtDQUC1fvlyvvfaaJOn999/Xn/70Jw0ZMkSrVq3S888/X29juVq7d+/WM888o++//75G/adOnaqWLVvWeR3nz5/XM888UyU82hISEmJ1/KpbVq9eXed1Xo3PP/9czzzzDKEPauboAgB7pKWlKSQkRHv27NHRo0fVpUsXR5fUJFy4cEFZWVl68sknlZCQ0GDve++99+q2225TZWWlvvvuO+3du1epqal66aWXtGLFCk2aNMnSd/jw4bpw4YLc3NwsbZmZmaqsrNRLL71kdax37NghZ2dnrVixwqp/Y7R7927NmTNHU6dOtZp5uhpTpkzRpEmT5O7uXuN1zp8/rzlz5kiSRo4cedm+qampOnfunOXnrVu36s0339TixYvl6+traR88eLB9hdezzz//XHPmzNHIkSMVEhLi6HLgQIQbNBlff/21du/erY0bN+r3v/+90tLSlJyc7OiybCotLVWLFi0cXYZFQUGBJNXZP65SzcbYr18//fa3v7VqO3HihEaPHq3Y2Fj16NFDffr0kSQ5OzvLw8PDqm9+fr7NuvPz89W8efM6DTbnz5+Xp6dnnW2vPrm4uMjFxaXetj9u3Dirn3Nzc/Xmm29q3LhxdRIamtK+RhNlAE3EvHnzDB8fH6OsrMyYNm2a0bVrV5v9vvvuO+ORRx4xgoODDTc3NyMwMNCYMmWKUVBQYOlz4cIFIzk52ejatavh7u5uBAQEGOPHjzeOHj1qGIZh7Ny505Bk7Ny502rbX3/9tSHJWLVqlaUtNjbWaNGihXH06FHj1ltvNVq2bGmMHTvWMAzD+PDDD4277rrLCAoKMtzc3IzrrrvOeOSRR4zz589XqfuLL74w7r77bsPX19fw8PAwrr/+emP27NmGYRjGjh07DEnGxo0bq6yXlpZmSDJ2795tc38kJycbkqyW4OBgy+vZ2dnGLbfcYnh5eRktWrQwRo0aZWRlZVltY9WqVYYkIzMz05g2bZrh5+dntG7d2ub7/Xw/vfDCCzZf3717tyHJmDx5sqXtl/s8ODi4St22xvLL47FmzRqjX79+hoeHh+Hj42NMnDjRyMnJsXr/ESNGGDfccIPx8ccfG8OGDTOaN29uzJgxwzAMw/jhhx+MpKQkIzQ01HLMHn/8ceOHH36w2oYkY/r06camTZuMG264wXBzczN69uxpvPvuu5fd95KMr7/+utp9d+n36XIuHY+fb2fv3r3G6NGjjbZt2xoeHh5GSEiIERcXZxjG/46Hrf1ZEy+88EKV99u8ebNx2223Ge3btzfc3NyMzp07G3PnzjV+/PFHq3Uvt68LCwuN3/72t4aXl5fh7e1txMTEGPv3769yTA3jp8/HhAkTDB8fH8Pd3d0IDw833n777Sr75JfLpd+ny+0fmA8zN2gy0tLSdOedd8rNzU333nuvXn31Ve3du1cDBgyw9Dl37pyGDRumL774Qvfdd5/69eunwsJCbdmyRadOnZKvr68qKip0xx13KCMjQ5MmTdKMGTNUUlKi7du369ChQwoNDbW7th9//FHR0dEaOnSoXnzxRctfpevXr9f58+c1bdo0tW3bVnv27NGSJUt06tQprV+/3rL+gQMHNGzYMLm6uuqBBx5QSEiIjh07pv/3//6fnnvuOY0cOVJBQUFKS0vT+PHjq+yX0NBQRUZG2qztzjvvVOvWrfXoo49aThNduqbjs88+07Bhw9SqVSv96U9/kqurq/76179q5MiR+uCDD6pc2/TQQw/Jz89PSUlJKi0ttXs/XRIZGanQ0FBt37692j6pqan6v//7P23atEmvvvqqWrZsqd69e6tLly567bXXtGfPHv3tb3+T9L/TI88995yefvpp3XPPPbr//vtVUFCgJUuWaPjw4frkk0+sZoC+/fZb3XrrrZo0aZJ++9vfyt/fX5WVlfr1r3+tXbt26YEHHlCPHj108OBBLV68WF9++WWVi7B37dqljRs36qGHHpKXl5defvllTZgwQTk5OWrbtq3uvPNOffnll1VO6fj5+dV639mSn5+v0aNHy8/PTzNnzlTr1q11/Phxbdy40fJ+r776qqZNm6bx48frzjvvlCT17t271u+5evVqtWzZUomJiWrZsqV27NihpKQkFRcX64UXXrDqW92+HjNmjPbs2aNp06ape/fuevvttxUbG1vlvT777DMNGTJEgYGBmjlzplq0aKG///3vGjdunN566y2NHz9ew4cP18MPP6yXX35Zs2fPVo8ePSRJPXr0uOL+gQk5Ol0BNfHxxx8bkozt27cbhmEYlZWVxnXXXWf5C/CSpKSkamc4KisrDcMwjJUrVxqSjEWLFlXbx96ZG0nGzJkzq2zP1gxNSkqK4eTkZJw4ccLSNnz4cMPLy8uq7ef1GIZhzJo1y3B3dze+//57S1t+fr7RrFmzK/4FXt1Myrhx4ww3Nzfj2LFjlrZvvvnG8PLyMoYPH25pu/RX8dChQ6v8ZW7P+/3c2LFjDUlGUVGRYRi29/mlmY+fz7oZhu3ZjePHjxsuLi7Gc889Z9V+8OBBo1mzZlbtI0aMMCQZy5Yts+q7Zs0aw9nZ2fjXv/5l1b5s2TJDkvHvf//b0ibJcHNzs8z2GYZhfPrpp4YkY8mSJZY2W7Mel1ObmZtNmzYZkoy9e/dWu05BQYFdszU/Z2sMtn63f//73xuenp5Ws1zV7eu33nrLkGSkpqZa2ioqKoxRo0ZV+YzddNNNRq9evay2W1lZaQwePNhqBnf9+vU2P7c12T8wF+6WQpOQlpYmf39//epXv5IkOTk5aeLEiVq3bp0qKios/d566y316dOnyuzGpXUu9fH19dUf/vCHavvUxrRp06q0NW/e3PLfpaWlKiws1ODBg2UYhj755BNJP10P8+GHH+q+++5Tx44dq60nJiZGZWVl2rBhg6UtPT1dP/74Y5XrWmqioqJC77//vsaNG6fOnTtb2tu3b6/Jkydr165dKi4utlonPj6+zq71uDR7VFJSUifb27hxoyorK3XPPfeosLDQsgQEBKhr167auXOnVX93d3fFxcVZta1fv149evRQ9+7drbYxatQoSaqyjaioKKuZvt69e6tVq1b66quv6mRMNXVpRuof//iHLl682CDv+fPf7ZKSEhUWFmrYsGE6f/68Dh8+bNXX1r7etm2bXF1dFR8fb2lzdnbW9OnTrfqdPXtWO3bs0D333GN5n8LCQn377beKjo7Wf//7X50+ffqytTpi/8CxCDdo9CoqKrRu3Tr96le/0tdff62jR4/q6NGjioiIUF5enjIyMix9jx07phtvvPGy2zt27Ji6deumZs3q7qxss2bNdN1111Vpz8nJ0dSpU9WmTRu1bNlSfn5+GjFihCSpqKhIkiz/EF6p7u7du2vAgAFKS0uztKWlpWnQoEG1umusoKBA58+fV7du3aq81qNHD1VWVurkyZNW7Z06dbL7fapz6W4cLy+vOtnef//7XxmGoa5du8rPz89q+eKLLywXJ18SGBhY5YLk//73v/rss8+qrH/99ddLUpVt/DKMSpKPj4++++67OhlTTY0YMUITJkzQnDlz5Ovrq7Fjx2rVqlUqKyurt/f87LPPNH78eHl7e6tVq1by8/OzhOxLv9uX2NrXJ06cUPv27atcWPzL3+WjR4/KMAw9/fTTVY7LpRsKfnlcfskR+weOxTU3aPR27NihM2fOaN26dVq3bl2V19PS0jR69Og6fc/qZnB+Pkv0c+7u7nJ2dq7S9+abb9bZs2f1xBNPqHv37mrRooVOnz6tqVOnqrKy0u66YmJiNGPGDJ06dUplZWX66KOP9Je//MXu7dTWz/9av1qHDh1Su3bt1KpVqzrZXmVlpZycnPTuu+/anF365bNjbI2lsrJSvXr10qJFi2y+R1BQkNXP1c1iGYZR07LrhJOTkzZs2KCPPvpI/+///T+99957uu+++7Rw4UJ99NFHdf7cnO+//14jRoxQq1atNHfuXIWGhsrDw0PZ2dl64oknqvxuX83vzaVtPfbYY4qOjrbZ50rhvqH3DxyPcINGLy0tTe3atdPSpUurvLZx40Zt2rRJy5YtU/PmzRUaGqpDhw5ddnuhoaH6z3/+o4sXL8rV1dVmHx8fH0mq8uC1EydO1LjugwcP6ssvv9Trr7+umJgYS/svL6K9dEroSnVL0qRJk5SYmKg333xTFy5ckKurqyZOnFjjmn7Oz89Pnp6eOnLkSJXXDh8+LGdn5yr/mNeVrKwsHTt2rFan06oTGhoqwzDUqVMny0xLbbbx6aef6qabbrqqU5Q/V1fbqYlBgwZp0KBBeu6557R27Vr95je/0bp163T//ffXaR2ZmZn69ttvtXHjRg0fPtzS/vXXX9d4G8HBwdq5c2eV28KPHj1q1e/S58PV1VVRUVGX3eaVxni5/QNz4bQUGrULFy5o48aNuuOOO3TXXXdVWRISElRSUqItW7ZIkiZMmKBPP/1UmzZtqrKtS39NT5gwQYWFhTZnPC71CQ4OlouLiz788EOr11955ZUa137pr/qf/xVvGIZeeuklq35+fn4aPny4Vq5cWeXJvb+cAfD19dWtt96qN954Q2lpabrlllusHqpmDxcXF40ePVpvv/221RNd8/LytHbtWg0dOrTOZlV+7sSJE5o6darc3Nz0+OOP19l277zzTrm4uGjOnDlV9pthGPr222+vuI177rlHp0+f1vLly6u8duHChVrdIXbpWUA1fUJxbXz33XdVxnzpKykunXq5FCDqog5bv9vl5eV2fT6io6N18eJFq31dWVlZ5Y+Ydu3aaeTIkfrrX/+qM2fOVNnOpWc4SdXv65rsH5gLMzdo1LZs2aKSkhL9+te/tvn6oEGD5Ofnp7S0NE2cOFGPP/64NmzYoLvvvlv33XefwsPDdfbsWW3ZskXLli1Tnz59FBMTo//7v/9TYmKi9uzZo2HDhqm0tFT//Oc/9dBDD2ns2LHy9vbW3XffrSVLlsjJyUmhoaH6xz/+ccVz+z/XvXt3hYaG6rHHHtPp06fVqlUrvfXWWzavx3j55Zc1dOhQ9evXTw888IA6deqk48eP65133tH+/fut+sbExOiuu+6SJM2bN6/mO9OGZ599Vtu3b9fQoUP10EMPqVmzZvrrX/+qsrIyLViw4Kq2LUnZ2dl64403VFlZqe+//1579+7VW2+9JScnJ61Zs+aqbkX+pdDQUD377LOaNWuWjh8/rnHjxsnLy0tff/21Nm3apAceeECPPfbYZbcxZcoU/f3vf9eDDz6onTt3asiQIaqoqNDhw4f197//Xe+9957dX1sRHh4uSXryySc1adIkubq6asyYMZd9AOLFixf17LPPVmlv06aNHnrooSrtr7/+ul555RWNHz9eoaGhKikp0fLly9WqVSvddtttkn46NdSzZ0+lp6fr+uuvV5s2bXTjjTde8VovWwYPHiwfHx/Fxsbq4YcfthxPe07HjRs3TgMHDtQf//hHHT16VN27d9eWLVt09uxZSdazMEuXLtXQoUPVq1cvxcfHq3PnzsrLy1NWVpZOnTqlTz/9VNJPgcXFxUV//vOfVVRUJHd3d40aNUpr16694v6ByTT8DVpAzY0ZM8bw8PAwSktLq+0zdepUw9XV1SgsLDQMwzC+/fZbIyEhwQgMDLQ8hC02NtbyumH8dBvrk08+aXTq1MlwdXU1AgICjLvuusvqluiCggJjwoQJhqenp+Hj42P8/ve/Nw4dOlTtQ/xs+fzzz42oqCijZcuWhq+vrxEfH2+5XfiXDyk7dOiQMX78eKN169aGh4eH0a1bN+Ppp5+uss2ysjLDx8fH8Pb2Ni5cuFCT3XjZW7Ozs7ON6Ohoo2XLloanp6fxq1/9qsoDAS/delzTW2l/+dC4Zs2aGW3atDEiIiKMWbNmVbnl3TCu/lbwS9566y1j6NChRosWLYwWLVoY3bt3N6ZPn24cOXLE0ufSg+VsKS8vN/785z8bN9xwg+Hu7m74+PgY4eHhxpw5cyy3rRvG/x7i90vBwcFGbGysVdu8efOMwMBAw9nZuUYP8fv5vvv5EhoaahhG1VvBs7OzjXvvvdfo2LGj4e7ubrRr18644447jI8//thq27t37zbCw8MNNze3q36I37///W9j0KBBRvPmzY0OHToYf/rTn4z33nuvyjG83L4uKCgwJk+ebHmI39SpU41///vfhiRj3bp1Vn2PHTtmxMTEGAEBAYarq6sRGBho3HHHHcaGDRus+i1fvtzo3Lmz4eLiYqmlpvsH5uFkGA185RuAq/Ljjz+qQ4cOGjNmjFasWOHocoA6tXnzZo0fP167du3SkCFDHF0OmiiuuQGamM2bN6ugoMDqImWgKbpw4YLVzxUVFVqyZIlatWqlfv36OagqmAHX3ABNxH/+8x8dOHBA8+bNU9++fS3PywGaqj/84Q+6cOGCIiMjVVZWpo0bN2r37t16/vnn6/SxA7j2EG6AJuLVV1/VG2+8obCwMK1evdrR5QBXbdSoUVq4cKH+8Y9/6IcfflCXLl20ZMkSJSQkOLo0NHFccwMAAEyFa24AAICpEG4AAICpXHPX3FRWVuqbb76Rl5dXgz4WHQAA1J5hGCopKVGHDh2qfJffL11z4eabb76pt+/LAQAA9evkyZO67rrrLtvnmgs3Xl5ekn7aOfXxvTkAAKDuFRcXKygoyPLv+OVcc+Hm0qmoVq1aEW4AAGhianJJCRcUAwAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAU2nm6AIAALBXyMx3HF1CrRyff7ujS7gmMHMDAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMxeHhZunSpQoJCZGHh4ciIiK0Z8+ey/ZPTU1Vt27d1Lx5cwUFBenRRx/VDz/80EDVAgCAxs6h4SY9PV2JiYlKTk5Wdna2+vTpo+joaOXn59vsv3btWs2cOVPJycn64osvtGLFCqWnp2v27NkNXDkAAGisHBpuFi1apPj4eMXFxalnz55atmyZPD09tXLlSpv9d+/erSFDhmjy5MkKCQnR6NGjde+9915xtgcAAFw7HBZuysvLtW/fPkVFRf2vGGdnRUVFKSsry+Y6gwcP1r59+yxh5quvvtLWrVt12223Vfs+ZWVlKi4utloAAIB5OezrFwoLC1VRUSF/f3+rdn9/fx0+fNjmOpMnT1ZhYaGGDh0qwzD0448/6sEHH7zsaamUlBTNmTOnTmsHAACNl8MvKLZHZmamnn/+eb3yyivKzs7Wxo0b9c4772jevHnVrjNr1iwVFRVZlpMnTzZgxQAAoKE5bObG19dXLi4uysvLs2rPy8tTQECAzXWefvppTZkyRffff78kqVevXiotLdUDDzygJ598Us7OVbOau7u73N3d634AAACgUXLYzI2bm5vCw8OVkZFhaausrFRGRoYiIyNtrnP+/PkqAcbFxUWSZBhG/RULAACaDIfN3EhSYmKiYmNj1b9/fw0cOFCpqakqLS1VXFycJCkmJkaBgYFKSUmRJI0ZM0aLFi1S3759FRERoaNHj+rpp5/WmDFjLCEHAABc2xwabiZOnKiCggIlJSUpNzdXYWFh2rZtm+Ui45ycHKuZmqeeekpOTk566qmndPr0afn5+WnMmDF67rnnHDUEAADQyDgZ19j5nOLiYnl7e6uoqEitWrVydDkAgFoImfmOo0uolePzb3d0CU2WPf9+N6m7pQAAAK7EoaelgMasqf5lKPHXIYBrGzM3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVJo5ugAAaAghM99xdAm1cnz+7Y4uAWhymLkBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACm0ijCzdKlSxUSEiIPDw9FRERoz5491fYdOXKknJycqiy3386XywEAgEYQbtLT05WYmKjk5GRlZ2erT58+io6OVn5+vs3+Gzdu1JkzZyzLoUOH5OLiorvvvruBKwcAAI2Rw8PNokWLFB8fr7i4OPXs2VPLli2Tp6enVq5cabN/mzZtFBAQYFm2b98uT09Pwg0AAJDk4HBTXl6uffv2KSoqytLm7OysqKgoZWVl1WgbK1as0KRJk9SiRQubr5eVlam4uNhqAQAA5uXQcFNYWKiKigr5+/tbtfv7+ys3N/eK6+/Zs0eHDh3S/fffX22flJQUeXt7W5agoKCrrhsAADReDj8tdTVWrFihXr16aeDAgdX2mTVrloqKiizLyZMnG7BCAADQ0Jo58s19fX3l4uKivLw8q/a8vDwFBARcdt3S0lKtW7dOc+fOvWw/d3d3ubu7X3WtAACgaXDozI2bm5vCw8OVkZFhaausrFRGRoYiIyMvu+769etVVlam3/72t/VdJgAAaEIcOnMjSYmJiYqNjVX//v01cOBApaamqrS0VHFxcZKkmJgYBQYGKiUlxWq9FStWaNy4cWrbtq0jygYAAI2Uw8PNxIkTVVBQoKSkJOXm5iosLEzbtm2zXGSck5MjZ2frCaYjR45o165dev/99x1RMgAAaMQcHm4kKSEhQQkJCTZfy8zMrNLWrVs3GYZRz1UBAICmqFGEGzQ9ITPfcXQJtXJ8Pl/TAQBm16RvBQcAAPglwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVh4ebpUuXKiQkRB4eHoqIiNCePXsu2//777/X9OnT1b59e7m7u+v666/X1q1bG6haAADQ2DVz5Junp6crMTFRy5YtU0REhFJTUxUdHa0jR46oXbt2VfqXl5fr5ptvVrt27bRhwwYFBgbqxIkTat26dcMXDwAAGiWHhptFixYpPj5ecXFxkqRly5bpnXfe0cqVKzVz5swq/VeuXKmzZ89q9+7dcnV1lSSFhIQ0ZMkA0KiFzHzH0SXUyvH5tzu6BJiIw8JNeXm59u3bp1mzZlnanJ2dFRUVpaysLJvrbNmyRZGRkZo+fbrefvtt+fn5afLkyXriiSfk4uJic52ysjKVlZVZfi4uLq7bgQAAUA+aalCVHB9WHXbNTWFhoSoqKuTv72/V7u/vr9zcXJvrfPXVV9qwYYMqKiq0detWPf3001q4cKGeffbZat8nJSVF3t7eliUoKKhOxwEAABoXh56WsldlZaXatWun1157TS4uLgoPD9fp06f1wgsvKDk52eY6s2bNUmJiouXn4uLieg04TTVpOzplAwBQVxwWbnx9feXi4qK8vDyr9ry8PAUEBNhcp3379nJ1dbU6BdWjRw/l5uaqvLxcbm5uVdZxd3eXu7t73RYPAAAaLYedlnJzc1N4eLgyMjIsbZWVlcrIyFBkZKTNdYYMGaKjR4+qsrLS0vbll1+qffv2NoMNAAC49jj0OTeJiYlavny5Xn/9dX3xxReaNm2aSktLLXdPxcTEWF1wPG3aNJ09e1YzZszQl19+qXfeeUfPP/+8pk+f7qghAACARsah19xMnDhRBQUFSkpKUm5ursLCwrRt2zbLRcY5OTlydv5f/goKCtJ7772nRx99VL1791ZgYKBmzJihJ554wlFDAAAAjYzDLyhOSEhQQkKCzdcyMzOrtEVGRuqjjz6q56oAAEBT5fCvXwAAAKhLhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqzRxdAADHCpn5jqNLqJXj8293dAkAGilmbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKk0inCzdOlShYSEyMPDQxEREdqzZ0+1fVevXi0nJyerxcPDowGrBQAAjZnDw016eroSExOVnJys7Oxs9enTR9HR0crPz692nVatWunMmTOW5cSJEw1YMQAAaMwcHm4WLVqk+Ph4xcXFqWfPnlq2bJk8PT21cuXKatdxcnJSQECAZfH392/AigEAQGPm0HBTXl6uffv2KSoqytLm7OysqKgoZWVlVbveuXPnFBwcrKCgII0dO1afffZZQ5QLAACaALvDTUhIiObOnaucnJyrfvPCwkJVVFRUmXnx9/dXbm6uzXW6deumlStX6u2339Ybb7yhyspKDR48WKdOnbLZv6ysTMXFxVYLAAAwL7vDzSOPPKKNGzeqc+fOuvnmm7Vu3TqVlZXVR202RUZGKiYmRmFhYRoxYoQ2btwoPz8//fWvf7XZPyUlRd7e3pYlKCiowWoFAAANr1bhZv/+/dqzZ4969OihP/zhD2rfvr0SEhKUnZ1t17Z8fX3l4uKivLw8q/a8vDwFBATUaBuurq7q27evjh49avP1WbNmqaioyLKcPHnSrhoBAEDTUutrbvr166eXX35Z33zzjZKTk/W3v/1NAwYMUFhYmFauXCnDMK64DTc3N4WHhysjI8PSVllZqYyMDEVGRtaojoqKCh08eFDt27e3+bq7u7tatWpltQAAAPNqVtsVL168qE2bNmnVqlXavn27Bg0apN/97nc6deqUZs+erX/+859au3btFbeTmJio2NhY9e/fXwMHDlRqaqpKS0sVFxcnSYqJiVFgYKBSUlIkSXPnztWgQYPUpUsXff/993rhhRd04sQJ3X///bUdCgAAMBG7w012drZWrVqlN998U87OzoqJidHixYvVvXt3S5/x48drwIABNdrexIkTVVBQoKSkJOXm5iosLEzbtm2zXGSck5MjZ+f/TTB99913io+PV25urnx8fBQeHq7du3erZ8+e9g4FAACYkN3hZsCAAbr55pv16quvaty4cXJ1da3Sp1OnTpo0aVKNt5mQkKCEhASbr2VmZlr9vHjxYi1evNiumgEAwLXD7nDz1VdfKTg4+LJ9WrRooVWrVtW6KAAAgNqy+4Li/Px8/ec//6nS/p///Ecff/xxnRQFAABQW3aHm+nTp9u8nfr06dOaPn16nRQFAABQW3aHm88//1z9+vWr0t63b199/vnndVIUAABAbdkdbtzd3as8dE+Szpw5o2bNan1nOQAAQJ2wO9yMHj3a8tTfS77//nvNnj1bN998c50WBwAAYC+7p1pefPFFDR8+XMHBwerbt68kaf/+/fL399eaNWvqvEAAAAB72B1uAgMDdeDAAaWlpenTTz9V8+bNFRcXp3vvvdfmM28AAAAaUq0ukmnRooUeeOCBuq4FAADgqtX6CuDPP/9cOTk5Ki8vt2r/9a9/fdVFAQAA1FatnlA8fvx4HTx4UE5OTpZv/3ZycpL007d0AwAAOIrdd0vNmDFDnTp1Un5+vjw9PfXZZ5/pww8/VP/+/at8DxQAAEBDs3vmJisrSzt27JCvr6+cnZ3l7OysoUOHKiUlRQ8//LA++eST+qgTAACgRuyeuamoqJCXl5ckydfXV998840kKTg4WEeOHKnb6gAAAOxk98zNjTfeqE8//VSdOnVSRESEFixYIDc3N7322mvq3LlzfdQIAABQY3aHm6eeekqlpaWSpLlz5+qOO+7QsGHD1LZtW6Wnp9d5gQAAAPawO9xER0db/rtLly46fPiwzp49Kx8fH8sdUwAAAI5i1zU3Fy9eVLNmzXTo0CGr9jZt2hBsAABAo2BXuHF1dVXHjh15lg0AAGi07L5b6sknn9Ts2bN19uzZ+qgHAADgqth9zc1f/vIXHT16VB06dFBwcLBatGhh9Xp2dnadFQcAAGAvu8PNuHHj6qEMAACAumF3uElOTq6POgAAAOqE3dfcAAAANGZ2z9w4Oztf9rZv7qQCAACOZHe42bRpk9XPFy9e1CeffKLXX39dc+bMqbPCAAAAasPucDN27NgqbXfddZduuOEGpaen63e/+12dFAYAAFAbdXbNzaBBg5SRkVFXmwMAAKiVOgk3Fy5c0Msvv6zAwMC62BwAAECt2X1a6pdfkGkYhkpKSuTp6ak33nijTosDAACwl93hZvHixVbhxtnZWX5+foqIiJCPj0+dFgcAAGAvu8PN1KlT66EMAACAumH3NTerVq3S+vXrq7SvX79er7/+eq2KWLp0qUJCQuTh4aGIiAjt2bOnRuutW7dOTk5OfCUEAACwsDvcpKSkyNfXt0p7u3bt9Pzzz9tdQHp6uhITE5WcnKzs7Gz16dNH0dHRys/Pv+x6x48f12OPPaZhw4bZ/Z4AAMC87A43OTk56tSpU5X24OBg5eTk2F3AokWLFB8fr7i4OPXs2VPLli2Tp6enVq5cWe06FRUV+s1vfqM5c+aoc+fOdr8nAAAwL7vDTbt27XTgwIEq7Z9++qnatm1r17bKy8u1b98+RUVF/a8gZ2dFRUUpKyur2vXmzp2rdu3a1eiBgWVlZSouLrZaAACAedkdbu699149/PDD2rlzpyoqKlRRUaEdO3ZoxowZmjRpkl3bKiwsVEVFhfz9/a3a/f39lZuba3OdXbt2acWKFVq+fHmN3iMlJUXe3t6WJSgoyK4aAQBA02J3uJk3b54iIiJ00003qXnz5mrevLlGjx6tUaNG1eqaG3uUlJRoypQpWr58uc3rfmyZNWuWioqKLMvJkyfrtUYAAOBYdt8K7ubmpvT0dD377LPav3+/mjdvrl69eik4ONjuN/f19ZWLi4vy8vKs2vPy8hQQEFCl/7Fjx3T8+HGNGTPG0lZZWSlJatasmY4cOaLQ0FCrddzd3eXu7m53bQAAoGmyO9xc0rVrV3Xt2vWq3tzNzU3h4eHKyMiw3M5dWVmpjIwMJSQkVOnfvXt3HTx40KrtqaeeUklJiV566SVOOQEAAPvDzYQJEzRw4EA98cQTVu0LFizQ3r17bT4D53ISExMVGxur/v37a+DAgUpNTVVpaani4uIkSTExMQoMDFRKSoo8PDx04403Wq3funVrSarSDgAArk12h5sPP/xQzzzzTJX2W2+9VQsXLrS7gIkTJ6qgoEBJSUnKzc1VWFiYtm3bZrnIOCcnR87Odfbl5QAAwOTsDjfnzp2Tm5tblXZXV9da32adkJBg8zSUJGVmZl523dWrV9fqPQEAgDnZPSXSq1cvpaenV2lft26devbsWSdFAQAA1JbdMzdPP/207rzzTh07dkyjRo2SJGVkZGjt2rXasGFDnRcIAABgD7vDzZgxY7R582Y9//zz2rBhg5o3b64+ffpox44datOmTX3UCAAAUGO1uhX89ttv1+233y5JKi4u1ptvvqnHHntM+/btU0VFRZ0WCAAAYI9a34b04YcfKjY2Vh06dNDChQs1atQoffTRR3VZGwAAgN3smrnJzc3V6tWrtWLFChUXF+uee+5RWVmZNm/ezMXEAACgUajxzM2YMWPUrVs3HThwQKmpqfrmm2+0ZMmS+qwNAADAbjWeuXn33Xf18MMPa9q0aVf9tQsAAAD1pcYzN7t27VJJSYnCw8MVERGhv/zlLyosLKzP2gAAAOxW43AzaNAgLV++XGfOnNHvf/97rVu3Th06dFBlZaW2b9+ukpKS+qwTAACgRuy+W6pFixa67777tGvXLh08eFB//OMfNX/+fLVr106//vWv66NGAACAGruqb6Ts1q2bFixYoFOnTunNN9+sq5oAAABqrU6+btvFxUXjxo3Tli1b6mJzAAAAtVYn4QYAAKCxINwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTaRThZunSpQoJCZGHh4ciIiK0Z8+eavtu3LhR/fv3V+vWrdWiRQuFhYVpzZo1DVgtAABozBwebtLT05WYmKjk5GRlZ2erT58+io6OVn5+vs3+bdq00ZNPPqmsrCwdOHBAcXFxiouL03vvvdfAlQMAgMbI4eFm0aJFio+PV1xcnHr27Klly5bJ09NTK1eutNl/5MiRGj9+vHr06KHQ0FDNmDFDvXv31q5duxq4cgAA0Bg5NNyUl5dr3759ioqKsrQ5OzsrKipKWVlZV1zfMAxlZGToyJEjGj58uM0+ZWVlKi4utloAAIB5OTTcFBYWqqKiQv7+/lbt/v7+ys3NrXa9oqIitWzZUm5ubrr99tu1ZMkS3XzzzTb7pqSkyNvb27IEBQXV6RgAAEDj4vDTUrXh5eWl/fv3a+/evXruueeUmJiozMxMm31nzZqloqIiy3Ly5MmGLRYAADSoZo58c19fX7m4uCgvL8+qPS8vTwEBAdWu5+zsrC5dukiSwsLC9MUXXyglJUUjR46s0tfd3V3u7u51WjcAAGi8HDpz4+bmpvDwcGVkZFjaKisrlZGRocjIyBpvp7KyUmVlZfVRIgAAaGIcOnMjSYmJiYqNjVX//v01cOBApaamqrS0VHFxcZKkmJgYBQYGKiUlRdJP19D0799foaGhKisr09atW7VmzRq9+uqrjhwGAABoJBwebiZOnKiCggIlJSUpNzdXYWFh2rZtm+Ui45ycHDk7/2+CqbS0VA899JBOnTql5s2bq3v37nrjjTc0ceJERw0BAAA0Ig4PN5KUkJCghIQEm6/98kLhZ599Vs8++2wDVAUAAJqiJnm3FAAAQHUINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQaRbhZunSpQkJC5OHhoYiICO3Zs6favsuXL9ewYcPk4+MjHx8fRUVFXbY/AAC4tjg83KSnpysxMVHJycnKzs5Wnz59FB0drfz8fJv9MzMzde+992rnzp3KyspSUFCQRo8erdOnTzdw5QAAoDFyeLhZtGiR4uPjFRcXp549e2rZsmXy9PTUypUrbfZPS0vTQw89pLCwMHXv3l1/+9vfVFlZqYyMjAauHAAANEYODTfl5eXat2+foqKiLG3Ozs6KiopSVlZWjbZx/vx5Xbx4UW3atKmvMgEAQBPSzJFvXlhYqIqKCvn7+1u1+/v76/DhwzXaxhNPPKEOHTpYBaSfKysrU1lZmeXn4uLi2hcMAAAaPYeflroa8+fP17p167Rp0yZ5eHjY7JOSkiJvb2/LEhQU1MBVAgCAhuTQcOPr6ysXFxfl5eVZtefl5SkgIOCy67744ouaP3++3n//ffXu3bvafrNmzVJRUZFlOXnyZJ3UDgAAGieHhhs3NzeFh4dbXQx86eLgyMjIatdbsGCB5s2bp23btql///6XfQ93d3e1atXKagEAAObl0GtuJCkxMVGxsbHq37+/Bg4cqNTUVJWWliouLk6SFBMTo8DAQKWkpEiS/vznPyspKUlr165VSEiIcnNzJUktW7ZUy5YtHTYOAADQODg83EycOFEFBQVKSkpSbm6uwsLCtG3bNstFxjk5OXJ2/t8E06uvvqry8nLdddddVttJTk7WM88805ClAwCARsjh4UaSEhISlJCQYPO1zMxMq5+PHz9e/wUBAIAmq0nfLQUAAPBLhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqDg83S5cuVUhIiDw8PBQREaE9e/ZU2/ezzz7ThAkTFBISIicnJ6WmpjZcoQAAoElwaLhJT09XYmKikpOTlZ2drT59+ig6Olr5+fk2+58/f16dO3fW/PnzFRAQ0MDVAgCApsCh4WbRokWKj49XXFycevbsqWXLlsnT01MrV6602X/AgAF64YUXNGnSJLm7uzdwtQAAoClwWLgpLy/Xvn37FBUV9b9inJ0VFRWlrKysOnufsrIyFRcXWy0AAMC8HBZuCgsLVVFRIX9/f6t2f39/5ebm1tn7pKSkyNvb27IEBQXV2bYBAEDj4/ALiuvbrFmzVFRUZFlOnjzp6JIAAEA9auaoN/b19ZWLi4vy8vKs2vPy8ur0YmF3d3euzwEA4BrisJkbNzc3hYeHKyMjw9JWWVmpjIwMRUZGOqosAADQxDls5kaSEhMTFRsbq/79+2vgwIFKTU1VaWmp4uLiJEkxMTEKDAxUSkqKpJ8uQv78888t/3369Gnt379fLVu2VJcuXRw2DgAA0Hg4NNxMnDhRBQUFSkpKUm5ursLCwrRt2zbLRcY5OTlydv7f5NI333yjvn37Wn5+8cUX9eKLL2rEiBHKzMxs6PIBAEAj5NBwI0kJCQlKSEiw+dovA0tISIgMw2iAqgAAQFNl+rulAADAtYVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATKVRhJulS5cqJCREHh4eioiI0J49ey7bf/369erevbs8PDzUq1cvbd26tYEqBQAAjZ3Dw016eroSExOVnJys7Oxs9enTR9HR0crPz7fZf/fu3br33nv1u9/9Tp988onGjRuncePG6dChQw1cOQAAaIwcHm4WLVqk+Ph4xcXFqWfPnlq2bJk8PT21cuVKm/1feukl3XLLLXr88cfVo0cPzZs3T/369dNf/vKXBq4cAAA0Rg4NN+Xl5dq3b5+ioqIsbc7OzoqKilJWVpbNdbKysqz6S1J0dHS1/QEAwLWlmSPfvLCwUBUVFfL397dq9/f31+HDh22uk5uba7N/bm6uzf5lZWUqKyuz/FxUVCRJKi4uvprSq1VZdr5etlvf7N0f18I4m+oYpWtjnPzO2sY4G7dr4bMp1c+/sZe2aRjGFfs6NNw0hJSUFM2ZM6dKe1BQkAOqaby8Ux1dQcNgnOZxLYxRYpxmwzivXklJiby9vS/bx6HhxtfXVy4uLsrLy7Nqz8vLU0BAgM11AgIC7Oo/a9YsJSYmWn6urKzU2bNn1bZtWzk5OV3lCBpOcXGxgoKCdPLkSbVq1crR5dQbxmke18IYJcZpNoyz8TIMQyUlJerQocMV+zo03Li5uSk8PFwZGRkaN26cpJ/CR0ZGhhISEmyuExkZqYyMDD3yyCOWtu3btysyMtJmf3d3d7m7u1u1tW7dui7Kd4hWrVo1mV/Eq8E4zeNaGKPEOM2GcTZOV5qxucThp6USExMVGxur/v37a+DAgUpNTVVpaani4uIkSTExMQoMDFRKSookacaMGRoxYoQWLlyo22+/XevWrdPHH3+s1157zZHDAAAAjYTDw83EiRNVUFCgpKQk5ebmKiwsTNu2bbNcNJyTkyNn5//d1DV48GCtXbtWTz31lGbPnq2uXbtq8+bNuvHGGx01BAAA0Ig4PNxIUkJCQrWnoTIzM6u03X333br77rvruarGxd3dXcnJyVVOsZkN4zSPa2GMEuM0G8ZpDk5GTe6pAgAAaCIc/oRiAACAukS4AQAApkK4AQAApkK4AQAApkK4aSSWLl2qkJAQeXh4KCIiQnv27LFrfcMwdOutt8rJyUmbN2+unyKvUm3HOHLkSDk5OVktDz74YD1XWzsffvihxowZow4dOlzVsXjwwQfl5OSk1NTUOq2vrlzNOKdOnVrleN5yyy31V2wtpaSkaMCAAfLy8lK7du00btw4HTlyxO7tNPbP5tWOs6l8Pl999VX17t3b8tC6yMhIvfvuu3Zto7Efy6sZY1M5jjVFuGkE0tPTlZiYqOTkZGVnZ6tPnz6Kjo5Wfn5+jbeRmpraqL9O4mrHGB8frzNnzliWBQsW1HPFtVNaWqo+ffpo6dKltd7Gpk2b9NFHH9XoEeOOcrXjvOWWW6yO55tvvlnHFV69Dz74QNOnT9dHH32k7du36+LFixo9erRKS0vt2k5j/2zWxTibwufzuuuu0/z587Vv3z59/PHHGjVqlMaOHavPPvusxtto7MfyasfYFI5jjRlwuIEDBxrTp0+3/FxRUWF06NDBSElJqdH6n3zyiREYGGicOXPGkGRs2rSpniqtvasZ44gRI4wZM2bUY3X1ozbH4tSpU0ZgYKBx6NAhIzg42Fi8eHG91FaX7B1nbGysMXbs2Hqrp77k5+cbkowPPvigxus0hc/mL9k7zqb6+TQMw/Dx8TH+9re/1ahvUzyWhlHzMTbl42gLMzcOVl5ern379ikqKsrS5uzsrKioKGVlZV1x/fPnz2vy5MlaunRptV8e6mhXO0ZJSktLk6+vr2688UbNmjVL58+fr69yHaayslJTpkzR448/rhtuuMHR5dSrzMxMtWvXTt26ddO0adP07bffOrqkKyoqKpIktWnTpkb9m8Jn0xZ7xyk1vc9nRUWF1q1bp9LS0mq/l/DnmuKxtHeMUtM7jpfTKJ5QfC0rLCxURUWF5esmLvH399fhw4evuP6jjz6qwYMHa+zYsfVV4lW72jFOnjxZwcHB6tChgw4cOKAnnnhCR44c0caNG+urZIf485//rGbNmunhhx92dCn16pZbbtGdd96pTp066dixY5o9e7ZuvfVWZWVlycXFxdHl2VRZWalHHnlEQ4YMqfFXvTSFz+Yv1WacTenzefDgQUVGRuqHH35Qy5YttWnTJvXs2fOK6zWlY1nbMTal41gThJsmbMuWLdqxY4c++eQTR5dSrx544AHLf/fq1Uvt27fXTTfdpGPHjik0NNSBldWdffv26aWXXlJ2dnajPqdfFyZNmmT57169eql3794KDQ1VZmambrrpJgdWVr3p06fr0KFD2rVrV436N9XPpr3jlJrW57Nbt27av3+/ioqKtGHDBsXGxuqDDz647D/+Te1Y1maMUtM6jjXBaSkH8/X1lYuLi/Ly8qza8/Lyrjj9uWPHDh07dkytW7dWs2bN1KzZT1l1woQJGjlyZH2VbLerGaMtERERkqSjR4/WSX2Nwb/+9S/l5+erY8eOlmN54sQJ/fGPf1RISIijy6tXnTt3lq+vb6M9ngkJCfrHP/6hnTt36rrrrqvROk3ls/lztRmnLY358+nm5qYuXbooPDxcKSkp6tOnj1566aXLrtPUjmVtxmhLYz6ONcHMjYO5ubkpPDxcGRkZGjdunKSfpoYzMjKq/TLRS2bOnKn777/fqq1Xr15avHixxowZU18l2+1qxmjL/v37JUnt27evwyoda8qUKVbXJElSdHS0pkyZori4OAdV1TBOnTqlb7/9ttEdT8Mw9Ic//EGbNm1SZmamOnXqVON1m8pnU7q6cdrSlD6flZWVKisru2yfpnQsbanJGG1pSsfRFsJNI5CYmKjY2Fj1799fAwcOVGpqqkpLS6/4j1pAQIDNmY+OHTte9f+g6lptx3js2DGtXbtWt912m9q2basDBw7o0Ucf1fDhw9W7d+8Gqr7mzp07Z/WXztdff639+/erTZs26tixY7XrtW3bVm3btrVqc3V1VUBAgLp161Zv9dZWbcd57tw5zZkzRxMmTFBAQICOHTumP/3pT+rSpYuio6MbovQamz59utauXau3335bXl5eys3NlSR5e3urefPml123KX02r2acTenzOWvWLN16663q2LGjSkpKtHbtWmVmZuq999677HpN6VjWdoxN6TjWmKNv18JPlixZYnTs2NFwc3MzBg4caHz00Ue12o4a8S2KtRljTk6OMXz4cKNNmzaGu7u70aVLF+Pxxx83ioqKGqBi++3cudOQVGWJjY21e1uN+Vbw2o7z/PnzxujRow0/Pz/D1dXVCA4ONuLj443c3NyGKdwOtsYnyVi1alWtt9cYP5tXM86m9Pm87777jODgYMPNzc3w8/MzbrrpJuP999+v1bYa67Gs7Rib0nGsKSfDMIwGS1IAAAD1jAuKAQCAqRBuGrG0tDS1bNnS5mKWh7xdC2OUfrobqrpxtmzZ0tHl1ZlrZZzXyu/ttTBOxmiOMf4Sp6UasZKSkiq3T1/i6uqq4ODgBq6o7l0LY5SkCxcu6PTp09W+3qVLlwaspv5cK+O8Vn5vr4VxMkZzjPGXCDcAAMBUOC0FAABMhXADAABMhXADAABMhXADoF44OTlp8+bNji4DwDWIcAOgVqZOnWr5rjBbzpw5o1tvvbVG27pSEFq9erWcnJwuuxw/fty+AdSR1atXq3Xr1g55bwC2EW4A1IuAgAC5u7vXybYmTpyoM2fOWJbIyEjFx8dbtQUFBdV4e4Zh6Mcff6yT2gA0PoQbAPXi57Mx5eXlSkhIUPv27eXh4aHg4GClpKRIkkJCQiRJ48ePl5OTk+Xnn2vevLnlCwwDAgLk5uYmT09Py8/bt29XRESEvLy8FBAQoMmTJys/P9+yfmZmppycnPTuu+8qPDxc7u7u2rVrl0pKSvSb3/xGLVq0UPv27bV48WKNHDlSjzzyiGXdsrIyPfbYYwoMDFSLFi0UERGhzMxMy3bj4uJUVFRkmUF65plnJEmvvPKKunbtKg8PD/n7++uuu+6q610MoBp8KziAevfyyy9ry5Yt+vvf/66OHTvq5MmTOnnypCRp7969ateunVatWqVbbrlFLi4udm//4sWLmjdvnrp166b8/HwlJiZq6tSp2rp1q1W/mTNn6sUXX1Tnzp3l4+OjxMRE/fvf/9aWLVvk7++vpKQkZWdnKywszLJOQkKCPv/8c61bt04dOnTQpk2bdMstt+jgwYMaPHiwUlNTlZSUpCNHjkiSWrZsqY8//lgPP/yw1qxZo8GDB+vs2bP617/+VfsdCMAuhBsA9S4nJ0ddu3bV0KFD5eTkZPVEVD8/P0lS69atFRAQUKvt33fffZb/7ty5s15++WUNGDBA586ds/rah7lz5+rmm2+W9NNTW19//XWtXbtWN910kyRp1apV6tChg1Xdq1atUk5OjqX9scce07Zt27Rq1So9//zz8vb2lpOTk1XtOTk5atGihe644w55eXkpODhYffv2rdXYANiP01IA6t3UqVO1f/9+devWTQ8//LDef//9Ot3+vn37NGbMGHXs2FFeXl4aMWKEpJ9Cxs/179/f8t9fffWVLl68qIEDB1ravL291a1bN8vPBw8eVEVFha6//nqr7+P54IMPdOzYsWrrufnmmxUcHKzOnTtrypQpSktL0/nz5+tquACugJkbAPWuX79++vrrr/Xuu+/qn//8p+655x5FRUVpw4YNV73t0tJSRUdHKzo6WmlpafLz81NOTo6io6NVXl5u1bdFixZ2bfvcuXNycXHRvn37qpwuu9wXgXp5eSk7O1uZmZl6//33lZSUpGeeeUZ79+7lziqgATBzA6BBtGrVShMnTtTy5cuVnp6ut956S2fPnpX005f3VVRU1Gq7hw8f1rfffqv58+dr2LBh6t69u9XFxNXp3LmzXF1dtXfvXktbUVGRvvzyS8vPffv2VUVFhfLz89WlSxer5dJpKDc3N5u1N2vWTFFRUVqwYIEOHDig48ePa8eOHbUaIwD7MHMDoNaKioq0f/9+q7a2bdtWuS170aJFat++vfr27StnZ2etX79eAQEBllmMkJAQZWRkaMiQIXJ3d5ePj0+Na+jYsaPc3Ny0ZMkSPfjggzp06JDmzZt3xfW8vLwUGxurxx9/XG3atFG7du2UnJwsZ2dnOTk5SZKuv/56/eY3v1FMTIwWLlyovn37qqCgQBkZGerdu7duv/12hYSE6Ny5c8rIyFCfPn3k6empHTt26KuvvtLw4cPl4+OjrVu3qrKy0uqUF4D6w8wNgFrLzMxU3759rZY5c+ZU6efl5aUFCxaof//+GjBggI4fP66tW7fK2fmn/wUtXLhQ27dvV1BQkN0X3vr5+Wn16tVav369evbsqfnz5+vFF1+s0bqLFi1SZGSk7rjjDkVFRWnIkCHq0aOHPDw8LH1WrVqlmJgY/fGPf1S3bt00btw47d27Vx07dpQkDR48WA8++KAmTpwoPz8/LViwQK1bt9bGjRs1atQo9ejRQ8uWLdObb76pG264wa6xAagdJ8MwDEcXAQCNQWlpqQIDA7Vw4UL97ne/c3Q5AGqJ01IArlmffPKJDh8+rIEDB6qoqEhz586VJI0dO9bBlQG4GoQbANe0F198UUeOHJGbm5vCw8P1r3/9S76+vo4uC8BV4LQUAAAwFS4oBgAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApvL/AQKEi0NAhO3xAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mapping between digits and their names\n",
    "label_mapping = {\n",
    "    0: 'SelfStim',\n",
    "    1: 'CtrlStim',\n",
    "    2: 'SelfRest',\n",
    "    3: 'CtrlRest',\n",
    "    4: 'SelfSoc',\n",
    "    5: 'CtrlSoc'\n",
    "}\n",
    "\n",
    "# Replace the digits with their names in list_targets\n",
    "#list_targets_names = [(label_mapping[i], label_mapping[j]) for i, j in results_dict.keys()]\n",
    "\n",
    "# Extract the list of list_targets and accuracy values\n",
    "list_targets, accuracies = zip(*results_dict.items())\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(range(len(list_targets)), accuracies, tick_label=list_targets)\n",
    "plt.xlabel('List Targets')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different List Targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_targets = [0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 100\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "csvfile = \"../../data/video/All_Subs_Diff_Modules_nofilter_withoutAUc.csv\"\n",
    "train_df = pd.read_csv(csvfile,  delimiter=\",\")  # 101 features (only AU_r)\n",
    "\n",
    "# Select only the classes we want to predict\n",
    "train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "# Convert the subject names (strings) into numbers\n",
    "subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "# Normalise the features\n",
    "features_numpy = normalize_data(train_df, False) #parameters.normalise_individual_subjects\n",
    "input_dim = features_numpy.shape[1]\n",
    "print(f\"Number of features: {input_dim}\")\n",
    "\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 0/0  Epoch:   0  Loss: 0.583857/0.592311  Validation accuracy: 0.58\n",
      "Subject: 0/0  Epoch:   1  Loss: 0.630703/0.286828  Validation accuracy: 0.69\n",
      "Subject: 0/0  Epoch:   2  Loss: 0.163649/0.184626  Validation accuracy: 0.67\n",
      "Test accuracy for run 0/0: 0.7011070110701108\n",
      "Subject: 0/1  Epoch:   0  Loss: 0.728523/0.816499  Validation accuracy: 0.76\n",
      "Subject: 0/1  Epoch:   1  Loss: 0.434618/0.79356  Validation accuracy: 0.81\n",
      "Subject: 0/1  Epoch:   2  Loss: 0.250108/5.04538  Validation accuracy: 0.60\n",
      "Test accuracy for run 0/1: 0.6863468634686347\n",
      "Subject: 0/2  Epoch:   0  Loss: 0.728832/0.552415  Validation accuracy: 0.33\n",
      "Subject: 0/2  Epoch:   1  Loss: 0.194847/0.341698  Validation accuracy: 0.43\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 0/2: 0.6863468634686347\n",
      "Subject: 1/0  Epoch:   0  Loss: 0.619694/0.677383  Validation accuracy: 0.61\n",
      "Subject: 1/0  Epoch:   1  Loss: 0.466472/0.451869  Validation accuracy: 0.83\n",
      "Subject: 1/0  Epoch:   2  Loss: 0.158392/0.446298  Validation accuracy: 0.67\n",
      "Test accuracy for run 1/0: 0.5095238095238095\n",
      "Subject: 1/1  Epoch:   0  Loss: 0.712803/0.644012  Validation accuracy: 0.57\n",
      "Subject: 1/1  Epoch:   1  Loss: 0.484504/0.77922  Validation accuracy: 0.79\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 1/1: 0.5095238095238095\n",
      "Subject: 1/2  Epoch:   0  Loss: 0.73037/0.370232  Validation accuracy: 0.73\n",
      "Subject: 1/2  Epoch:   1  Loss: 0.319878/0.404585  Validation accuracy: 0.75\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 1/2: 0.5095238095238095\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.658195/0.785341  Validation accuracy: 0.51\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.37964/0.570747  Validation accuracy: 0.85\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.413046/0.537157  Validation accuracy: 0.68\n",
      "Test accuracy for run 2/0: 0.2526690391459075\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.563456/0.598732  Validation accuracy: 0.80\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.326734/0.189146  Validation accuracy: 0.89\n",
      "Subject: 2/1  Epoch:   2  Loss: 0.0096612/1.24011  Validation accuracy: 0.78\n",
      "Test accuracy for run 2/1: 0.302491103202847\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.560141/0.923835  Validation accuracy: 0.42\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.155497/1.11467  Validation accuracy: 0.65\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 2/2: 0.302491103202847\n",
      "Subject: 3/0  Epoch:   0  Loss: 0.609338/0.675285  Validation accuracy: 0.76\n",
      "Subject: 3/0  Epoch:   1  Loss: 0.30824/1.16514  Validation accuracy: 0.46\n",
      "Subject: 3/0  Epoch:   2  Loss: 0.126644/2.76835  Validation accuracy: 0.54\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 3/0: 0.8197969543147208\n",
      "Subject: 3/1  Epoch:   0  Loss: 0.649682/0.602942  Validation accuracy: 0.51\n",
      "Subject: 3/1  Epoch:   1  Loss: 0.424047/1.53252  Validation accuracy: 0.75\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 3/1: 0.8197969543147208\n",
      "Subject: 3/2  Epoch:   0  Loss: 0.631326/0.732593  Validation accuracy: 0.32\n",
      "Subject: 3/2  Epoch:   1  Loss: 0.169471/1.78474  Validation accuracy: 0.30\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 3/2: 0.8197969543147208\n",
      "Subject: 4/0  Epoch:   0  Loss: 0.452308/1.02155  Validation accuracy: 0.30\n",
      "Subject: 4/0  Epoch:   1  Loss: 0.056437/1.15957  Validation accuracy: 0.50\n",
      "Subject: 4/0  Epoch:   2  Loss: 0.00805061/2.09799  Validation accuracy: 0.48\n",
      "Test accuracy for run 4/0: 0.681592039800995\n",
      "Subject: 4/1  Epoch:   0  Loss: 0.61216/0.496285  Validation accuracy: 0.67\n",
      "Subject: 4/1  Epoch:   1  Loss: 0.196444/0.225909  Validation accuracy: 0.65\n",
      "Subject: 4/1  Epoch:   2  Loss: 0.021633/0.0830323  Validation accuracy: 0.88\n",
      "Test accuracy for run 4/1: 0.7189054726368159\n",
      "Subject: 4/2  Epoch:   0  Loss: 0.796884/0.408119  Validation accuracy: 0.73\n",
      "Subject: 4/2  Epoch:   1  Loss: 0.380286/0.144845  Validation accuracy: 0.85\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 4/2: 0.7189054726368159\n",
      "Subject: 5/0  Epoch:   0  Loss: 0.682039/0.597632  Validation accuracy: 0.80\n",
      "Subject: 5/0  Epoch:   1  Loss: 0.370663/0.234513  Validation accuracy: 0.73\n",
      "Subject: 5/0  Epoch:   2  Loss: 0.00847793/0.512033  Validation accuracy: 0.73\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 5/0: 0.5233415233415234\n",
      "Subject: 5/1  Epoch:   0  Loss: 0.731782/0.685869  Validation accuracy: 0.29\n",
      "Subject: 5/1  Epoch:   1  Loss: 0.486577/1.32083  Validation accuracy: 0.48\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 5/1: 0.5233415233415234\n",
      "Subject: 5/2  Epoch:   0  Loss: 0.835976/0.427971  Validation accuracy: 0.62\n",
      "Subject: 5/2  Epoch:   1  Loss: 0.23974/0.429124  Validation accuracy: 0.77\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 5/2: 0.5233415233415234\n",
      "Subject: 6/0  Epoch:   0  Loss: 0.598009/0.291228  Validation accuracy: 0.68\n",
      "Subject: 6/0  Epoch:   1  Loss: 0.550093/0.0917986  Validation accuracy: 0.50\n",
      "Subject: 6/0  Epoch:   2  Loss: 0.749717/0.0188534  Validation accuracy: 0.62\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 6/0: 0.7439446366782007\n",
      "Subject: 6/1  Epoch:   0  Loss: 0.628706/0.573392  Validation accuracy: 0.53\n",
      "Subject: 6/1  Epoch:   1  Loss: 0.505668/0.489588  Validation accuracy: 0.53\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 6/1: 0.7439446366782007\n",
      "Subject: 6/2  Epoch:   0  Loss: 0.749619/0.810707  Validation accuracy: 0.62\n",
      "Subject: 6/2  Epoch:   1  Loss: 0.478627/0.713185  Validation accuracy: 0.48\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 6/2: 0.7439446366782007\n",
      "Subject: 7/0  Epoch:   0  Loss: 0.593351/0.791855  Validation accuracy: 0.79\n",
      "Subject: 7/0  Epoch:   1  Loss: 0.0934388/1.49502  Validation accuracy: 0.73\n",
      "Subject: 7/0  Epoch:   2  Loss: 0.370956/1.35169  Validation accuracy: 0.82\n",
      "Test accuracy for run 7/0: 0.7866666666666666\n",
      "Subject: 7/1  Epoch:   0  Loss: 0.482357/0.83996  Validation accuracy: 0.89\n",
      "Subject: 7/1  Epoch:   1  Loss: 0.27321/1.92542  Validation accuracy: 0.71\n",
      "Subject: 7/1  Epoch:   2  Loss: 0.221706/0.370356  Validation accuracy: 0.56\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 7/1: 0.8088888888888889\n",
      "Subject: 7/2  Epoch:   0  Loss: 0.652848/0.720454  Validation accuracy: 0.70\n",
      "Subject: 7/2  Epoch:   1  Loss: 0.0946793/3.84747  Validation accuracy: 0.68\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 7/2: 0.8088888888888889\n",
      "Subject: 8/0  Epoch:   0  Loss: 0.54703/0.529817  Validation accuracy: 0.53\n",
      "Subject: 8/0  Epoch:   1  Loss: 0.213072/0.632543  Validation accuracy: 0.57\n",
      "Subject: 8/0  Epoch:   2  Loss: 0.0266416/1.16576  Validation accuracy: 0.57\n",
      "Test accuracy for run 8/0: 0.591715976331361\n",
      "Subject: 8/1  Epoch:   0  Loss: 0.679688/0.556717  Validation accuracy: 0.66\n",
      "Subject: 8/1  Epoch:   1  Loss: 0.235668/0.310502  Validation accuracy: 0.69\n",
      "Subject: 8/1  Epoch:   2  Loss: 0.0955925/0.20429  Validation accuracy: 0.69\n",
      "Test accuracy for run 8/1: 0.7337278106508875\n",
      "Subject: 8/2  Epoch:   0  Loss: 0.609257/0.634255  Validation accuracy: 0.86\n",
      "Subject: 8/2  Epoch:   1  Loss: 0.277633/0.281881  Validation accuracy: 0.64\n",
      "Subject: 8/2  Epoch:   2  Loss: 0.0499587/0.453371  Validation accuracy: 0.62\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 8/2: 0.4556213017751479\n",
      "Subject: 9/0  Epoch:   0  Loss: 0.604177/0.392908  Validation accuracy: 0.88\n",
      "Subject: 9/0  Epoch:   1  Loss: 0.0202158/0.23983  Validation accuracy: 0.83\n",
      "Subject: 9/0  Epoch:   2  Loss: 0.832456/0.0560539  Validation accuracy: 0.92\n",
      "Test accuracy for run 9/0: 0.7080536912751678\n",
      "Subject: 9/1  Epoch:   0  Loss: 0.754473/0.11491  Validation accuracy: 0.53\n",
      "Subject: 9/1  Epoch:   1  Loss: 0.117803/0.0234657  Validation accuracy: 0.74\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 9/1: 0.7080536912751678\n",
      "Subject: 9/2  Epoch:   0  Loss: 0.602829/0.481002  Validation accuracy: 0.52\n",
      "Subject: 9/2  Epoch:   1  Loss: 0.725812/0.240802  Validation accuracy: 0.67\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 9/2: 0.7080536912751678\n",
      "Subject: 10/0  Epoch:   0  Loss: 0.582344/0.679725  Validation accuracy: 0.87\n",
      "Subject: 10/0  Epoch:   1  Loss: 0.224926/0.911513  Validation accuracy: 0.57\n",
      "Subject: 10/0  Epoch:   2  Loss: 0.39871/0.443709  Validation accuracy: 0.58\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 10/0: 0.8401253918495298\n",
      "Subject: 10/1  Epoch:   0  Loss: 0.624412/0.540649  Validation accuracy: 0.80\n",
      "Subject: 10/1  Epoch:   1  Loss: 0.731678/0.191559  Validation accuracy: 0.78\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 10/1: 0.8401253918495298\n",
      "Subject: 10/2  Epoch:   0  Loss: 0.789431/0.755527  Validation accuracy: 0.43\n",
      "Subject: 10/2  Epoch:   1  Loss: 0.142334/0.827242  Validation accuracy: 0.52\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 10/2: 0.8401253918495298\n",
      "Subject: 11/0  Epoch:   0  Loss: 0.624415/0.650202  Validation accuracy: 0.78\n",
      "Subject: 11/0  Epoch:   1  Loss: 0.470917/0.187587  Validation accuracy: 0.89\n",
      "Subject: 11/0  Epoch:   2  Loss: 0.069164/0.0484498  Validation accuracy: 0.78\n",
      "Test accuracy for run 11/0: 0.8645320197044335\n",
      "Subject: 11/1  Epoch:   0  Loss: 0.591892/0.600052  Validation accuracy: 0.76\n",
      "Subject: 11/1  Epoch:   1  Loss: 0.278772/0.25503  Validation accuracy: 0.82\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 11/1: 0.8645320197044335\n",
      "Subject: 11/2  Epoch:   0  Loss: 0.525821/0.563543  Validation accuracy: 0.88\n",
      "Subject: 11/2  Epoch:   1  Loss: 0.280111/0.39243  Validation accuracy: 0.91\n",
      "Subject: 11/2  Epoch:   2  Loss: 0.0578582/0.168403  Validation accuracy: 0.66\n",
      "Test accuracy for run 11/2: 0.7019704433497537\n",
      "Subject: 12/0  Epoch:   0  Loss: 0.621386/0.270222  Validation accuracy: 0.70\n",
      "Subject: 12/0  Epoch:   1  Loss: 0.487665/1.57093  Validation accuracy: 0.61\n",
      "Subject: 12/0  Epoch:   2  Loss: 0.833925/0.554009  Validation accuracy: 0.55\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 12/0: 0.6590909090909091\n",
      "Subject: 12/1  Epoch:   0  Loss: 0.669446/0.572063  Validation accuracy: 0.76\n",
      "Subject: 12/1  Epoch:   1  Loss: 0.261482/0.388116  Validation accuracy: 0.76\n",
      "Subject: 12/1  Epoch:   2  Loss: 0.126915/0.274125  Validation accuracy: 0.76\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 12/1: 0.8352272727272727\n",
      "Subject: 12/2  Epoch:   0  Loss: 0.46788/0.606956  Validation accuracy: 0.55\n",
      "Subject: 12/2  Epoch:   1  Loss: 0.304032/0.38157  Validation accuracy: 0.68\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 12/2: 0.8352272727272727\n",
      "Subject: 13/0  Epoch:   0  Loss: 0.59517/0.58001  Validation accuracy: 0.62\n",
      "Subject: 13/0  Epoch:   1  Loss: 0.72343/0.119525  Validation accuracy: 0.71\n",
      "Subject: 13/0  Epoch:   2  Loss: 0.0247348/0.0116164  Validation accuracy: 0.65\n",
      "Test accuracy for run 13/0: 0.7386666666666667\n",
      "Subject: 13/1  Epoch:   0  Loss: 0.691358/0.167086  Validation accuracy: 0.50\n",
      "Subject: 13/1  Epoch:   1  Loss: 0.328926/0.106724  Validation accuracy: 0.62\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 13/1: 0.7386666666666667\n",
      "Subject: 13/2  Epoch:   0  Loss: 0.806805/0.866391  Validation accuracy: 0.39\n",
      "Subject: 13/2  Epoch:   1  Loss: 0.522212/0.855922  Validation accuracy: 0.45\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 13/2: 0.7386666666666667\n",
      "Subject: 14/0  Epoch:   0  Loss: 0.672116/0.929844  Validation accuracy: 0.71\n",
      "Subject: 14/0  Epoch:   1  Loss: 0.399662/2.77595  Validation accuracy: 0.77\n",
      "Subject: 14/0  Epoch:   2  Loss: 0.131816/3.04656  Validation accuracy: 0.82\n",
      "Test accuracy for run 14/0: 0.3661417322834646\n",
      "Subject: 14/1  Epoch:   0  Loss: 0.596479/0.539062  Validation accuracy: 0.83\n",
      "Subject: 14/1  Epoch:   1  Loss: 0.131955/0.325668  Validation accuracy: 0.89\n",
      "Subject: 14/1  Epoch:   2  Loss: 0.101516/1.04039  Validation accuracy: 0.59\n",
      "Test accuracy for run 14/1: 0.39763779527559057\n",
      "Subject: 14/2  Epoch:   0  Loss: 0.630602/0.443034  Validation accuracy: 0.33\n",
      "Subject: 14/2  Epoch:   1  Loss: 0.35195/0.215792  Validation accuracy: 0.33\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 14/2: 0.39763779527559057\n",
      "Subject: 15/0  Epoch:   0  Loss: 0.535883/1.00037  Validation accuracy: 0.30\n",
      "Subject: 15/0  Epoch:   1  Loss: 0.336097/0.770479  Validation accuracy: 0.64\n",
      "Subject: 15/0  Epoch:   2  Loss: 0.00133711/2.03  Validation accuracy: 0.41\n",
      "Test accuracy for run 15/0: 0.6593406593406593\n",
      "Subject: 15/1  Epoch:   0  Loss: 0.566955/0.786439  Validation accuracy: 0.42\n",
      "Subject: 15/1  Epoch:   1  Loss: 0.282762/1.03512  Validation accuracy: 0.45\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 15/1: 0.6593406593406593\n",
      "Subject: 15/2  Epoch:   0  Loss: 0.824321/0.858592  Validation accuracy: 0.53\n",
      "Subject: 15/2  Epoch:   1  Loss: 0.319743/0.332744  Validation accuracy: 0.65\n",
      "Subject: 15/2  Epoch:   2  Loss: 0.0699648/0.659006  Validation accuracy: 0.66\n",
      "Test accuracy for run 15/2: 0.7417582417582418\n",
      "Test accuracies:\n",
      "[0.6912669126691267, 0.5095238095238095, 0.2858837485172005, 0.8197969543147208, 0.7064676616915423, 0.5233415233415234, 0.7439446366782007, 0.8014814814814814, 0.5936883629191322, 0.7080536912751678, 0.8401253918495298, 0.8103448275862069, 0.7765151515151514, 0.7386666666666667, 0.3871391076115485, 0.6868131868131867]\n",
      "Mean accuracy: 0.6639408196533871\n"
     ]
    }
   ],
   "source": [
    "# Variable we will use throughout the training and testing\n",
    "test_accuracies = []\n",
    "calibrated_test_accuracies = []\n",
    "all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "# Validation accuracy\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "epoch_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Get distinct subjects\n",
    "subj = np.unique(subjects)\n",
    "\n",
    "# Loop over all subjects\n",
    "for test_subj in subj:\n",
    "    xv_max_val = 0\n",
    "    avg_test_acc = 0\n",
    "    val_acc_val_loss_list = []\n",
    "    test_acc_list = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Cross validation\n",
    "    for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "        # Set up the train, validation and test sets\n",
    "        test_idx = np.array([test_subj])\n",
    "\n",
    "        # Take out test subject from trainval (Crooss validation)\n",
    "        trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "        val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "        val_idx = val_idx%len(subj)\n",
    "\n",
    "        # Remove test & validation subjects from trainval\n",
    "        train_idx = np.setxor1d(subj, test_idx)\n",
    "        train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "        #print(\"Generating train/val/test split...\")\n",
    "        features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "        #print(\"Generating sequences...\")\n",
    "        features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "        features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "        \n",
    "        # Overlap or no\n",
    "        if parameters.test_with_subsequences:\n",
    "            features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "        else:\n",
    "            features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "        #print(f\"Number of training examples: {len(targets_train)}\")\n",
    "        #print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "        #print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "        # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "        featuresTrain = torch.from_numpy(features_train)\n",
    "        targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        featuresVal = torch.from_numpy(features_val)\n",
    "        targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        # Pytorch train and validation sets\n",
    "        train = TensorDataset(featuresTrain, targetsTrain)\n",
    "        val = TensorDataset(featuresVal, targetsVal)\n",
    "        \n",
    "        # Data loader\n",
    "        train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "\n",
    "        # Create feature and targets tensor for test set\n",
    "        if parameters.test_with_subsequences:\n",
    "            featuresTest = torch.from_numpy(features_test)\n",
    "            targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "            test = TensorDataset(featuresTest, targetsTest)\n",
    "            test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "        \n",
    "        # Model\n",
    "        model = CNN(input_dim, parameters.seq_dim).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        error = nn.CrossEntropyLoss()\n",
    "        error_cpu = nn.CrossEntropyLoss().to('cpu')\n",
    "\n",
    "        # Early Stopping\n",
    "        \n",
    "        patience = epochs -1\n",
    "        #patience = 4\n",
    "        current_patience = 0\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = error(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Validation accuracy\n",
    "            accuracy = validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\n",
    "\n",
    "            ### Early stopping\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "                current_patience = 0  # Reset patience counter\n",
    "            else:\n",
    "                current_patience += 1  # No improvement, increase patience counter\n",
    "            \n",
    "            if current_patience >= patience:\n",
    "                # Early stopping condition met\n",
    "                print(f'Early stopping at epoch {epoch} due to lack of improvement.')\n",
    "                break\n",
    "\n",
    "        # Restore the best model checkpoint\n",
    "        model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "    \n",
    "        # Cross validation accuracy\n",
    "        cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj)\n",
    "\n",
    "    avg_test_acc = np.mean(test_acc_list)\n",
    "    test_accuracies.append(avg_test_acc)\n",
    "  \n",
    "print(\"Test accuracies:\")\n",
    "print(test_accuracies)\n",
    "print(f\"Mean accuracy: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = './model_0_3.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
