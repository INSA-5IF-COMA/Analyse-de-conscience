{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sys\n",
    "import sklearn.metrics as metrics\n",
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\n",
    "from torchinfo import summary\n",
    "import parameters\n",
    "import random\n",
    "from data_formatting import split_sequence_overlap, split_sequence_nooverlap, split_sequence, split_train_test, normalize_data, set_targets\n",
    "parameters.initialize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list):\n",
    "    all_val_predicted = []\n",
    "    all_val_labels = []\n",
    "    all_val_outputs = np.empty((0, nclasses), dtype='float')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate through validation dataset\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = Variable(features.view(-1, parameters.seq_dim, input_dim)).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(features)\n",
    "            val_loss = error(outputs, labels)\n",
    "\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            predicted = predicted.to('cpu')\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cpu()).sum()\n",
    "            all_val_predicted.extend(list(predicted.detach().numpy()))\n",
    "            all_val_labels.extend(list(labels.cpu().detach().numpy()))\n",
    "            all_val_outputs = np.concatenate((all_val_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "    al_np = np.array(all_val_labels)   \n",
    "    ao_np = np.array(all_val_outputs)  \n",
    "    accuracy = correct / float(total)\n",
    "\n",
    "    # store loss and iteration\n",
    "    loss_list.append(loss.data)\n",
    "    val_loss_list.append(val_loss.data)\n",
    "    epoch_list.append(epoch)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Subject: {}/{}  Epoch: {:>3}  Loss: {:.6}/{:.6}  Validation accuracy: {:.2f}'.format(test_subj, xv, epoch, loss, val_loss, accuracy))\n",
    "    return accuracy\n",
    "    \n",
    "def cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    prev_label = -1\n",
    "    class_hist = np.zeros(nclasses, dtype='int')\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "    # Iterate through test dataset\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if parameters.test_with_subsequences:\n",
    "            for features, labels in test_loader:\n",
    "                features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "                labels = Variable(labels).to('cpu')\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(features)\n",
    "                test_loss = error_cpu(outputs.to('cpu'), labels)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                predicted = predicted.to('cpu')\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_predicted.extend(list(predicted.detach().numpy()))\n",
    "                all_labels.extend(list(labels.detach().numpy()))\n",
    "                all_outputs = np.concatenate((all_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "        \n",
    "        else:\n",
    "            count=0\n",
    "            for features in features_test:\n",
    "                features = torch.tensor(features)\n",
    "                features = torch.unsqueeze(features, 0).to(device)\n",
    "                labels = torch.unsqueeze(torch.tensor(targets_test[count]), 0)\n",
    "                features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(features)\n",
    "\n",
    "                test_loss = error(outputs.to('cpu'), labels)\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                predicted = predicted.to('cpu')\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                count += 1\n",
    "\n",
    "        al_np = np.array(all_labels)   \n",
    "        ao_np = np.array(all_outputs)  \n",
    "\n",
    "        accuracy = correct / float(total)\n",
    "\n",
    "        print(f\"Test accuracy for run {test_subj}/{xv}: {accuracy}\")\n",
    "\n",
    "    avg_test_acc += accuracy\n",
    "    test_acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim, seq_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Define the architecture with layers based on the input arguments\n",
    "        self.conv1 = nn.Conv1d(seq_dim, 32, 5)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv1d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv1d(128, 256, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Mise Ã  jour de fc_input_size en fonction des couches de pooling\n",
    "        self.fc_input_size = 256 * (( (input_dim - 5) - 3 - 3 - 3 + 4) )\n",
    "        self.fc = nn.Linear(self.fc_input_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# Classes we want to predict (0 et 3) and binary outputs\n",
    "list_targets = [0, 3] #SelfStim & CtrlRest\n",
    "list_labels = [0, 1]\n",
    "\n",
    "# number of subjects used for validation\n",
    "num_validation_subjects = 1\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 10e-4\n",
    "epochs = 3\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 100\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "csvfile = \"../../data/video/All_Subs_Diff_Modules_nofilter_withoutAUc.csv\"\n",
    "train_df = pd.read_csv(csvfile,  delimiter=\",\")  # 101 features (only AU_r)\n",
    "\n",
    "# Select only the classes we want to predict\n",
    "train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "# Convert the subject names (strings) into numbers\n",
    "subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "# Normalise the features\n",
    "features_numpy = normalize_data(train_df, False) #parameters.normalise_individual_subjects\n",
    "input_dim = features_numpy.shape[1]\n",
    "print(f\"Number of features: {input_dim}\")\n",
    "\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 0/0  Epoch:   0  Loss: 0.580261/0.0386062  Validation accuracy: 0.97\n",
      "Subject: 0/0  Epoch:   1  Loss: 0.249173/0.00502749  Validation accuracy: 0.97\n",
      "Subject: 0/0  Epoch:   2  Loss: 0.265492/0.000117812  Validation accuracy: 0.98\n",
      "Test accuracy for run 0/0: 0.6889880952380952\n",
      "Subject: 0/1  Epoch:   0  Loss: 0.226042/0.0317351  Validation accuracy: 0.60\n",
      "Subject: 0/1  Epoch:   1  Loss: 0.673647/0.00237981  Validation accuracy: 0.63\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 0/1: 0.6889880952380952\n",
      "Subject: 0/2  Epoch:   0  Loss: 0.23551/0.792246  Validation accuracy: 0.69\n",
      "Subject: 0/2  Epoch:   1  Loss: 0.21221/0.595318  Validation accuracy: 0.65\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 0/2: 0.6889880952380952\n",
      "Subject: 1/0  Epoch:   0  Loss: 0.363172/0.00570249  Validation accuracy: 0.60\n",
      "Subject: 1/0  Epoch:   1  Loss: 0.131268/0.00417277  Validation accuracy: 0.60\n",
      "Subject: 1/0  Epoch:   2  Loss: 0.0811955/0.000225195  Validation accuracy: 0.60\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 1/0: 0.7635327635327636\n",
      "Subject: 1/1  Epoch:   0  Loss: 0.0401336/1.02436  Validation accuracy: 0.94\n",
      "Subject: 1/1  Epoch:   1  Loss: 0.58306/0.563443  Validation accuracy: 0.99\n",
      "Subject: 1/1  Epoch:   2  Loss: 0.158488/0.219741  Validation accuracy: 0.91\n",
      "Test accuracy for run 1/1: 0.8888888888888888\n",
      "Subject: 1/2  Epoch:   0  Loss: 0.5749/2.38419e-07  Validation accuracy: 0.66\n",
      "Subject: 1/2  Epoch:   1  Loss: 0.230235/2.08616e-06  Validation accuracy: 0.75\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 1/2: 0.8888888888888888\n",
      "Subject: 2/0  Epoch:   0  Loss: 0.324847/0.441716  Validation accuracy: 0.76\n",
      "Subject: 2/0  Epoch:   1  Loss: 0.378158/0.568772  Validation accuracy: 0.87\n",
      "Subject: 2/0  Epoch:   2  Loss: 0.0303261/0.875655  Validation accuracy: 0.90\n",
      "Test accuracy for run 2/0: 0.618421052631579\n",
      "Subject: 2/1  Epoch:   0  Loss: 0.244636/0.675417  Validation accuracy: 0.56\n",
      "Subject: 2/1  Epoch:   1  Loss: 0.135777/1.31561  Validation accuracy: 0.52\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 2/1: 0.618421052631579\n",
      "Subject: 2/2  Epoch:   0  Loss: 0.597353/0.730119  Validation accuracy: 0.51\n",
      "Subject: 2/2  Epoch:   1  Loss: 0.290089/1.19892  Validation accuracy: 0.56\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 2/2: 0.618421052631579\n",
      "Subject: 3/0  Epoch:   0  Loss: 0.214521/0.0361528  Validation accuracy: 0.97\n",
      "Subject: 3/0  Epoch:   1  Loss: 0.251115/0.000936192  Validation accuracy: 1.00\n",
      "Subject: 3/0  Epoch:   2  Loss: 0.160054/2.80135e-05  Validation accuracy: 0.86\n",
      "Test accuracy for run 3/0: 0.6866267465069861\n",
      "Subject: 3/1  Epoch:   0  Loss: 0.163348/0.389155  Validation accuracy: 0.73\n",
      "Subject: 3/1  Epoch:   1  Loss: 0.428518/0.557389  Validation accuracy: 0.88\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 3/1: 0.6866267465069861\n",
      "Subject: 3/2  Epoch:   0  Loss: 0.236957/0.211999  Validation accuracy: 0.86\n",
      "Subject: 3/2  Epoch:   1  Loss: 0.464363/0.45486  Validation accuracy: 0.60\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 3/2: 0.6866267465069861\n",
      "Subject: 4/0  Epoch:   0  Loss: 0.309504/0.0212965  Validation accuracy: 0.60\n",
      "Subject: 4/0  Epoch:   1  Loss: 0.121079/0.00182935  Validation accuracy: 0.60\n",
      "Subject: 4/0  Epoch:   2  Loss: 0.0867973/2.88081e-05  Validation accuracy: 0.60\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 4/0: 0.708\n",
      "Subject: 4/1  Epoch:   0  Loss: 0.280176/0.000280698  Validation accuracy: 0.83\n",
      "Subject: 4/1  Epoch:   1  Loss: 0.310252/9.17907e-06  Validation accuracy: 0.82\n",
      "Subject: 4/1  Epoch:   2  Loss: 0.0592128/0.0  Validation accuracy: 0.67\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 4/1: 0.704\n",
      "Subject: 4/2  Epoch:   0  Loss: 0.289731/0.690744  Validation accuracy: 0.76\n",
      "Subject: 4/2  Epoch:   1  Loss: 0.211239/1.74956  Validation accuracy: 0.82\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 4/2: 0.704\n",
      "Subject: 5/0  Epoch:   0  Loss: 0.760704/0.0  Validation accuracy: 0.66\n",
      "Subject: 5/0  Epoch:   1  Loss: 0.250911/5.96046e-08  Validation accuracy: 0.70\n",
      "Subject: 5/0  Epoch:   2  Loss: 0.0858895/0.0  Validation accuracy: 0.74\n",
      "Test accuracy for run 5/0: 0.8722891566265061\n",
      "Subject: 5/1  Epoch:   0  Loss: 0.314935/0.0570484  Validation accuracy: 0.97\n",
      "Subject: 5/1  Epoch:   1  Loss: 0.217538/0.00390123  Validation accuracy: 0.97\n",
      "Subject: 5/1  Epoch:   2  Loss: 0.0124273/7.66172e-05  Validation accuracy: 0.93\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 5/1: 0.8674698795180723\n",
      "Subject: 5/2  Epoch:   0  Loss: 0.343723/0.412024  Validation accuracy: 0.87\n",
      "Subject: 5/2  Epoch:   1  Loss: 0.603354/0.357848  Validation accuracy: 0.73\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 5/2: 0.8674698795180723\n",
      "Subject: 6/0  Epoch:   0  Loss: 0.191928/0.862782  Validation accuracy: 0.67\n",
      "Subject: 6/0  Epoch:   1  Loss: 0.501721/1.47714  Validation accuracy: 0.52\n",
      "Subject: 6/0  Epoch:   2  Loss: 0.0529951/1.06412  Validation accuracy: 0.48\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 6/0: 0.8973305954825462\n",
      "Subject: 6/1  Epoch:   0  Loss: 0.329577/0.0223659  Validation accuracy: 0.63\n",
      "Subject: 6/1  Epoch:   1  Loss: 0.384886/0.00241149  Validation accuracy: 0.62\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 6/1: 0.8973305954825462\n",
      "Subject: 6/2  Epoch:   0  Loss: 0.417977/0.000629524  Validation accuracy: 0.65\n",
      "Subject: 6/2  Epoch:   1  Loss: 0.77747/7.03332e-06  Validation accuracy: 0.67\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 6/2: 0.8973305954825462\n",
      "Subject: 7/0  Epoch:   0  Loss: 0.250287/0.409575  Validation accuracy: 0.63\n",
      "Subject: 7/0  Epoch:   1  Loss: 0.150264/0.526996  Validation accuracy: 0.88\n",
      "Subject: 7/0  Epoch:   2  Loss: 0.033669/0.775736  Validation accuracy: 0.77\n",
      "Test accuracy for run 7/0: 0.9919484702093397\n",
      "Subject: 7/1  Epoch:   0  Loss: 0.465193/0.36959  Validation accuracy: 0.67\n",
      "Subject: 7/1  Epoch:   1  Loss: 0.0588003/0.332968  Validation accuracy: 0.80\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 7/1: 0.9919484702093397\n",
      "Subject: 7/2  Epoch:   0  Loss: 0.395973/0.0273299  Validation accuracy: 0.73\n",
      "Subject: 7/2  Epoch:   1  Loss: 0.27497/0.0196059  Validation accuracy: 0.70\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 7/2: 0.9919484702093397\n",
      "Subject: 8/0  Epoch:   0  Loss: 0.397472/0.0158977  Validation accuracy: 0.60\n",
      "Subject: 8/0  Epoch:   1  Loss: 0.231513/0.00179834  Validation accuracy: 0.60\n",
      "Subject: 8/0  Epoch:   2  Loss: 0.0482379/0.000183835  Validation accuracy: 0.60\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 8/0: 0.7306034482758621\n",
      "Subject: 8/1  Epoch:   0  Loss: 0.445051/0.0638378  Validation accuracy: 0.97\n",
      "Subject: 8/1  Epoch:   1  Loss: 0.483836/0.00948433  Validation accuracy: 0.97\n",
      "Subject: 8/1  Epoch:   2  Loss: 0.0459056/0.000475667  Validation accuracy: 0.91\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 8/1: 0.8060344827586207\n",
      "Subject: 8/2  Epoch:   0  Loss: 0.40864/1.4817  Validation accuracy: 0.88\n",
      "Subject: 8/2  Epoch:   1  Loss: 0.110331/2.74532  Validation accuracy: 0.90\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 8/2: 0.8060344827586207\n",
      "Subject: 9/0  Epoch:   0  Loss: 0.255529/1.36786  Validation accuracy: 0.95\n",
      "Subject: 9/0  Epoch:   1  Loss: 0.115364/2.16828  Validation accuracy: 0.92\n",
      "Subject: 9/0  Epoch:   2  Loss: 0.178462/2.18121  Validation accuracy: 0.86\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 9/0: 0.7528901734104047\n",
      "Subject: 9/1  Epoch:   0  Loss: 0.534768/0.659791  Validation accuracy: 0.77\n",
      "Subject: 9/1  Epoch:   1  Loss: 0.00141735/0.549901  Validation accuracy: 0.82\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 9/1: 0.7528901734104047\n",
      "Subject: 9/2  Epoch:   0  Loss: 0.543979/0.513407  Validation accuracy: 0.94\n",
      "Subject: 9/2  Epoch:   1  Loss: 0.245758/0.557831  Validation accuracy: 0.88\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 9/2: 0.7528901734104047\n",
      "Subject: 10/0  Epoch:   0  Loss: 0.424986/0.0401554  Validation accuracy: 0.61\n",
      "Subject: 10/0  Epoch:   1  Loss: 0.239231/0.00292353  Validation accuracy: 0.62\n",
      "Subject: 10/0  Epoch:   2  Loss: 0.0492182/0.000542014  Validation accuracy: 0.66\n",
      "Test accuracy for run 10/0: 0.9191321499013807\n",
      "Subject: 10/1  Epoch:   0  Loss: 0.437572/0.519044  Validation accuracy: 0.70\n",
      "Subject: 10/1  Epoch:   1  Loss: 0.144129/0.639085  Validation accuracy: 0.75\n",
      "Subject: 10/1  Epoch:   2  Loss: 0.608352/3.64401  Validation accuracy: 0.74\n",
      "Test accuracy for run 10/1: 0.9309664694280079\n",
      "Subject: 10/2  Epoch:   0  Loss: 0.142903/0.0947349  Validation accuracy: 0.60\n",
      "Subject: 10/2  Epoch:   1  Loss: 0.695018/0.0088619  Validation accuracy: 0.63\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 10/2: 0.9309664694280079\n",
      "Subject: 11/0  Epoch:   0  Loss: 0.752498/0.58892  Validation accuracy: 0.85\n",
      "Subject: 11/0  Epoch:   1  Loss: 0.284702/0.245524  Validation accuracy: 0.66\n",
      "Subject: 11/0  Epoch:   2  Loss: 0.0711711/1.38572  Validation accuracy: 0.79\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 11/0: 0.623046875\n",
      "Subject: 11/1  Epoch:   0  Loss: 0.360194/0.413017  Validation accuracy: 0.76\n",
      "Subject: 11/1  Epoch:   1  Loss: 0.155266/0.308753  Validation accuracy: 0.77\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 11/1: 0.623046875\n",
      "Subject: 11/2  Epoch:   0  Loss: 0.190795/1.36506  Validation accuracy: 0.94\n",
      "Subject: 11/2  Epoch:   1  Loss: 0.32386/2.16731  Validation accuracy: 0.93\n",
      "Subject: 11/2  Epoch:   2  Loss: 0.0408583/2.62109  Validation accuracy: 0.93\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 11/2: 0.60546875\n",
      "Subject: 12/0  Epoch:   0  Loss: 0.452916/0.285648  Validation accuracy: 0.76\n",
      "Subject: 12/0  Epoch:   1  Loss: 0.465396/0.302513  Validation accuracy: 0.67\n",
      "Subject: 12/0  Epoch:   2  Loss: 0.0440313/0.00678998  Validation accuracy: 0.84\n",
      "Test accuracy for run 12/0: 0.9847972972972973\n",
      "Subject: 12/1  Epoch:   0  Loss: 0.457331/0.0284  Validation accuracy: 0.82\n",
      "Subject: 12/1  Epoch:   1  Loss: 0.0598337/0.00958852  Validation accuracy: 0.97\n",
      "Subject: 12/1  Epoch:   2  Loss: 0.295661/1.77024e-05  Validation accuracy: 0.97\n",
      "Test accuracy for run 12/1: 1.0\n",
      "Subject: 12/2  Epoch:   0  Loss: 0.346178/0.662104  Validation accuracy: 0.71\n",
      "Subject: 12/2  Epoch:   1  Loss: 0.113376/0.692759  Validation accuracy: 0.67\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 12/2: 1.0\n",
      "Subject: 13/0  Epoch:   0  Loss: 0.431503/0.292467  Validation accuracy: 0.82\n",
      "Subject: 13/0  Epoch:   1  Loss: 0.535737/0.802422  Validation accuracy: 0.67\n",
      "Subject: 13/0  Epoch:   2  Loss: 0.453313/0.215129  Validation accuracy: 0.63\n",
      "Early stopping at epoch 2 due to lack of improvement.\n",
      "Test accuracy for run 13/0: 0.94\n",
      "Subject: 13/1  Epoch:   0  Loss: 0.469979/0.391993  Validation accuracy: 0.55\n",
      "Subject: 13/1  Epoch:   1  Loss: 0.0669582/0.340259  Validation accuracy: 0.85\n",
      "Subject: 13/1  Epoch:   2  Loss: 0.00664229/0.128054  Validation accuracy: 0.82\n",
      "Test accuracy for run 13/1: 0.7555555555555555\n",
      "Subject: 13/2  Epoch:   0  Loss: 0.501465/4.66799  Validation accuracy: 0.83\n",
      "Subject: 13/2  Epoch:   1  Loss: 0.307041/6.46561  Validation accuracy: 0.86\n",
      "Subject: 13/2  Epoch:   2  Loss: 0.00541414/6.74555  Validation accuracy: 0.89\n",
      "Test accuracy for run 13/2: 0.9\n",
      "Subject: 14/0  Epoch:   0  Loss: 0.0993364/0.672302  Validation accuracy: 0.57\n",
      "Subject: 14/0  Epoch:   1  Loss: 0.831297/0.554209  Validation accuracy: 0.64\n",
      "Subject: 14/0  Epoch:   2  Loss: 0.251679/0.85712  Validation accuracy: 0.69\n",
      "Test accuracy for run 14/0: 0.6842105263157895\n",
      "Subject: 14/1  Epoch:   0  Loss: 0.0413095/0.380874  Validation accuracy: 0.73\n",
      "Subject: 14/1  Epoch:   1  Loss: 0.260637/0.18898  Validation accuracy: 0.85\n",
      "Subject: 14/1  Epoch:   2  Loss: 0.0785763/0.13277  Validation accuracy: 0.76\n",
      "Test accuracy for run 14/1: 0.6513157894736842\n",
      "Subject: 14/2  Epoch:   0  Loss: 0.326888/0.679203  Validation accuracy: 0.64\n",
      "Subject: 14/2  Epoch:   1  Loss: 0.792644/0.862516  Validation accuracy: 0.66\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 14/2: 0.6513157894736842\n",
      "Subject: 15/0  Epoch:   0  Loss: 0.468062/0.807809  Validation accuracy: 0.81\n",
      "Subject: 15/0  Epoch:   1  Loss: 0.479836/1.24944  Validation accuracy: 0.82\n",
      "Subject: 15/0  Epoch:   2  Loss: 0.0203669/1.9013  Validation accuracy: 0.82\n",
      "Test accuracy for run 15/0: 0.8660869565217392\n",
      "Subject: 15/1  Epoch:   0  Loss: 0.379819/0.657935  Validation accuracy: 0.82\n",
      "Subject: 15/1  Epoch:   1  Loss: 0.142827/0.833536  Validation accuracy: 0.86\n",
      "Subject: 15/1  Epoch:   2  Loss: 0.209566/2.12913  Validation accuracy: 0.78\n",
      "Test accuracy for run 15/1: 0.9321739130434783\n",
      "Subject: 15/2  Epoch:   0  Loss: 0.132035/0.621931  Validation accuracy: 0.59\n",
      "Subject: 15/2  Epoch:   1  Loss: 0.252728/0.573067  Validation accuracy: 0.68\n",
      "Early stopping at epoch 1 due to lack of improvement.\n",
      "Test accuracy for run 15/2: 0.9321739130434783\n",
      "Test accuracies:\n",
      "[0.6889880952380952, 0.8471035137701804, 0.618421052631579, 0.6866267465069861, 0.7053333333333333, 0.8690763052208835, 0.8973305954825462, 0.9919484702093397, 0.7808908045977011, 0.7528901734104047, 0.9270216962524654, 0.6171875, 0.9949324324324325, 0.8651851851851852, 0.662280701754386, 0.910144927536232]\n",
      "Mean accuracy: 0.8009600958476094\n"
     ]
    }
   ],
   "source": [
    "# Variable we will use throughout the training and testing\n",
    "test_accuracies = []\n",
    "calibrated_test_accuracies = []\n",
    "all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "# Validation accuracy\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "epoch_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Get distinct subjects\n",
    "subj = np.unique(subjects)\n",
    "\n",
    "# Loop over all subjects\n",
    "for test_subj in subj:\n",
    "    xv_max_val = 0\n",
    "    avg_test_acc = 0\n",
    "    val_acc_val_loss_list = []\n",
    "    test_acc_list = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Cross validation\n",
    "    for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "        # Set up the train, validation and test sets\n",
    "        test_idx = np.array([test_subj])\n",
    "\n",
    "        # Take out test subject from trainval (Crooss validation)\n",
    "        trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "        val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "        val_idx = val_idx%len(subj)\n",
    "\n",
    "        # Remove test & validation subjects from trainval\n",
    "        train_idx = np.setxor1d(subj, test_idx)\n",
    "        train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "        #print(\"Generating train/val/test split...\")\n",
    "        features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "        #print(\"Generating sequences...\")\n",
    "        features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "        features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "        \n",
    "        # Overlap or no\n",
    "        if parameters.test_with_subsequences:\n",
    "            features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "        else:\n",
    "            features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "        #print(f\"Number of training examples: {len(targets_train)}\")\n",
    "        #print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "        #print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "        # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "        featuresTrain = torch.from_numpy(features_train)\n",
    "        targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        featuresVal = torch.from_numpy(features_val)\n",
    "        targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "        # Pytorch train and validation sets\n",
    "        train = TensorDataset(featuresTrain, targetsTrain)\n",
    "        val = TensorDataset(featuresVal, targetsVal)\n",
    "        \n",
    "        # Data loader\n",
    "        train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "\n",
    "        # Create feature and targets tensor for test set\n",
    "        if parameters.test_with_subsequences:\n",
    "            featuresTest = torch.from_numpy(features_test)\n",
    "            targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "            test = TensorDataset(featuresTest, targetsTest)\n",
    "            test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "        \n",
    "        # Model\n",
    "        model = CNN(input_dim, parameters.seq_dim).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        error = nn.CrossEntropyLoss()\n",
    "        error_cpu = nn.CrossEntropyLoss().to('cpu')\n",
    "\n",
    "        # Early Stopping\n",
    "        \n",
    "        patience = epochs -1\n",
    "        #patience = 4\n",
    "        current_patience = 0\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = error(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Validation accuracy\n",
    "            accuracy = validation_accuracy(model, val_loader, nclasses, device, input_dim, error, loss, epoch, test_subj, xv, loss_list, val_loss_list, epoch_list, accuracy_list)\n",
    "\n",
    "            ### Early stopping\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "                current_patience = 0  # Reset patience counter\n",
    "            else:\n",
    "                current_patience += 1  # No improvement, increase patience counter\n",
    "            \n",
    "            if current_patience >= patience:\n",
    "                # Early stopping condition met\n",
    "                print(f'Early stopping at epoch {epoch} due to lack of improvement.')\n",
    "                break\n",
    "\n",
    "        # Restore the best model checkpoint\n",
    "        model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "    \n",
    "        # Cross validation accuracy\n",
    "        cross_accuracy(model, test_loader, avg_test_acc, test_acc_list, test_accuracies, nclasses, device, error_cpu, input_dim, features_test, targets_test, error, xv, test_subj)\n",
    "\n",
    "    avg_test_acc = np.mean(test_acc_list)\n",
    "    test_accuracies.append(avg_test_acc)\n",
    "  \n",
    "print(\"Test accuracies:\")\n",
    "print(test_accuracies)\n",
    "print(f\"Mean accuracy: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = './model_0_3.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
