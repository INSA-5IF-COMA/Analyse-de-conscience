{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sys\n",
    "import sklearn.metrics as metrics\n",
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\n",
    "from torchinfo import summary\n",
    "import parameters\n",
    "import random\n",
    "from data_formatting import split_sequence_overlap, split_sequence_nooverlap, split_sequence, split_train_test, normalize_data, set_targets\n",
    "parameters.initialize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(CNN, self).__init__()\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.kernel_size1 = 7\n",
    "        self.kernel_size2 = 7\n",
    "        self.fc_input_size = hidden_size*(seq_length-self.kernel_size1+1-self.kernel_size2+1)\n",
    "        self.conv1 = nn.Conv2d(1, hidden_size, (self.kernel_size1,1))   # output size : seq_length - 4\n",
    "        self.conv2 = nn.Conv2d(hidden_size, hidden_size, (self.kernel_size2,1))   # output size : seq_length - 8\n",
    "        self.fc = nn.Linear(self.fc_input_size, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = x.view(-1, self.fc_input_size) #reshaping the data for next dense layer\n",
    "        x = self.fc(x)\n",
    "        x[:,1] = self.sig(x[:,1])\n",
    "        return x\n",
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim, seq_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Define the architecture with layers based on the input arguments\n",
    "        self.conv1 = nn.Conv1d(seq_dim, 16, 5)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_input_size = 32 * (input_dim - 5 - 3 + 2)\n",
    "        self.fc = nn.Linear(self.fc_input_size, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# Classes we want to predict and binary outputs\n",
    "list_targets = [0, 3]\n",
    "list_labels = [0, 1]\n",
    "\n",
    "# number of subjects used for validation\n",
    "num_validation_subjects = 1\n",
    "\n",
    "learning_rate = 0.0007\n",
    "weight_decay = 10e-4\n",
    "epochs = 3\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 100\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1412\n",
      "Number of validation examples: 70\n",
      "Number of test examples: 672\n",
      "Epoch: 1, Training Loss: 0.5193742945622862\n",
      "Epoch: 2, Training Loss: 0.4254317009047176\n",
      "Epoch: 3, Training Loss: 0.36765916595298254\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1390\n",
      "Number of validation examples: 86\n",
      "Number of test examples: 672\n",
      "Epoch: 1, Training Loss: 0.48754825434465515\n",
      "Epoch: 2, Training Loss: 0.4011658827463786\n",
      "Epoch: 3, Training Loss: 0.3653666932007362\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1384\n",
      "Number of validation examples: 84\n",
      "Number of test examples: 672\n",
      "Epoch: 1, Training Loss: 0.5224646621051876\n",
      "Epoch: 2, Training Loss: 0.4232322470895175\n",
      "Epoch: 3, Training Loss: 0.37816572668908655\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1414\n",
      "Number of validation examples: 83\n",
      "Number of test examples: 702\n",
      "Epoch: 1, Training Loss: 0.515556047136864\n",
      "Epoch: 2, Training Loss: 0.4131877331921224\n",
      "Epoch: 3, Training Loss: 0.37939785102779944\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1402\n",
      "Number of validation examples: 84\n",
      "Number of test examples: 702\n",
      "Epoch: 1, Training Loss: 0.5120514160530134\n",
      "Epoch: 2, Training Loss: 0.41174243492158974\n",
      "Epoch: 3, Training Loss: 0.35919884727759793\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1388\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 702\n",
      "Epoch: 1, Training Loss: 0.5053701462416813\n",
      "Epoch: 2, Training Loss: 0.4168538482024752\n",
      "Epoch: 3, Training Loss: 0.38151696255837364\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1356\n",
      "Number of validation examples: 114\n",
      "Number of test examples: 684\n",
      "Epoch: 1, Training Loss: 0.5114293750594644\n",
      "Epoch: 2, Training Loss: 0.41471391565659466\n",
      "Epoch: 3, Training Loss: 0.37597481292836804\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1388\n",
      "Number of validation examples: 75\n",
      "Number of test examples: 684\n",
      "Epoch: 1, Training Loss: 0.5110199204806624\n",
      "Epoch: 2, Training Loss: 0.39709637596689423\n",
      "Epoch: 3, Training Loss: 0.3525497975020573\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1369\n",
      "Number of validation examples: 84\n",
      "Number of test examples: 684\n",
      "Epoch: 1, Training Loss: 0.5064116799554159\n",
      "Epoch: 2, Training Loss: 0.4172260834034099\n",
      "Epoch: 3, Training Loss: 0.3694774546595507\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1443\n",
      "Number of validation examples: 78\n",
      "Number of test examples: 501\n",
      "Epoch: 1, Training Loss: 0.5218262443175683\n",
      "Epoch: 2, Training Loss: 0.4081970757835514\n",
      "Epoch: 3, Training Loss: 0.3750629565872989\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1415\n",
      "Number of validation examples: 75\n",
      "Number of test examples: 501\n",
      "Epoch: 1, Training Loss: 0.5033363639638665\n",
      "Epoch: 2, Training Loss: 0.396963610742869\n",
      "Epoch: 3, Training Loss: 0.3656436452704869\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1432\n",
      "Number of validation examples: 70\n",
      "Number of test examples: 501\n",
      "Epoch: 1, Training Loss: 0.5197259356578191\n",
      "Epoch: 2, Training Loss: 0.42100992335213555\n",
      "Epoch: 3, Training Loss: 0.3669967267248366\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1381\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 500\n",
      "Epoch: 1, Training Loss: 0.5267863736070436\n",
      "Epoch: 2, Training Loss: 0.4145078474077685\n",
      "Epoch: 3, Training Loss: 0.3823224556172031\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1396\n",
      "Number of validation examples: 86\n",
      "Number of test examples: 500\n",
      "Epoch: 1, Training Loss: 0.4797328172082251\n",
      "Epoch: 2, Training Loss: 0.3919140852310441\n",
      "Epoch: 3, Training Loss: 0.3581473498859189\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1440\n",
      "Number of validation examples: 78\n",
      "Number of test examples: 500\n",
      "Epoch: 1, Training Loss: 0.5344782905446158\n",
      "Epoch: 2, Training Loss: 0.4099570526017083\n",
      "Epoch: 3, Training Loss: 0.3731544544299444\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1450\n",
      "Number of validation examples: 81\n",
      "Number of test examples: 415\n",
      "Epoch: 1, Training Loss: 0.5076459990097926\n",
      "Epoch: 2, Training Loss: 0.41490682042562044\n",
      "Epoch: 3, Training Loss: 0.3616485602253086\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1412\n",
      "Number of validation examples: 116\n",
      "Number of test examples: 415\n",
      "Epoch: 1, Training Loss: 0.5072392884934886\n",
      "Epoch: 2, Training Loss: 0.4076186418533325\n",
      "Epoch: 3, Training Loss: 0.3879537281025662\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1412\n",
      "Number of validation examples: 116\n",
      "Number of test examples: 415\n",
      "Epoch: 1, Training Loss: 0.5187575843896759\n",
      "Epoch: 2, Training Loss: 0.41484081142404106\n",
      "Epoch: 3, Training Loss: 0.3826830099137981\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1404\n",
      "Number of validation examples: 83\n",
      "Number of test examples: 487\n",
      "Epoch: 1, Training Loss: 0.5142597596753727\n",
      "Epoch: 2, Training Loss: 0.41088368235663936\n",
      "Epoch: 3, Training Loss: 0.371589025313204\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1408\n",
      "Number of validation examples: 97\n",
      "Number of test examples: 487\n",
      "Epoch: 1, Training Loss: 0.5162990486079996\n",
      "Epoch: 2, Training Loss: 0.43368719111789356\n",
      "Epoch: 3, Training Loss: 0.3753249597820369\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1408\n",
      "Number of validation examples: 97\n",
      "Number of test examples: 487\n",
      "Epoch: 1, Training Loss: 0.49902041764421895\n",
      "Epoch: 2, Training Loss: 0.40854626589200715\n",
      "Epoch: 3, Training Loss: 0.3685438141904094\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1393\n",
      "Number of validation examples: 84\n",
      "Number of test examples: 621\n",
      "Epoch: 1, Training Loss: 0.5142092227258466\n",
      "Epoch: 2, Training Loss: 0.43362845649773424\n",
      "Epoch: 3, Training Loss: 0.4026231413537806\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1420\n",
      "Number of validation examples: 81\n",
      "Number of test examples: 621\n",
      "Epoch: 1, Training Loss: 0.5292133243566148\n",
      "Epoch: 2, Training Loss: 0.4264501283008061\n",
      "Epoch: 3, Training Loss: 0.3750224756390861\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1390\n",
      "Number of validation examples: 84\n",
      "Number of test examples: 621\n",
      "Epoch: 1, Training Loss: 0.5110427466617233\n",
      "Epoch: 2, Training Loss: 0.4161502694946596\n",
      "Epoch: 3, Training Loss: 0.38173310784087783\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1478\n",
      "Number of validation examples: 70\n",
      "Number of test examples: 464\n",
      "Epoch: 1, Training Loss: 0.4898381954239261\n",
      "Epoch: 2, Training Loss: 0.4061903296619333\n",
      "Epoch: 3, Training Loss: 0.364090201995706\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1432\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 464\n",
      "Epoch: 1, Training Loss: 0.5230604386991925\n",
      "Epoch: 2, Training Loss: 0.4283478687206904\n",
      "Epoch: 3, Training Loss: 0.3862285070949131\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1424\n",
      "Number of validation examples: 114\n",
      "Number of test examples: 464\n",
      "Epoch: 1, Training Loss: 0.5319175033756857\n",
      "Epoch: 2, Training Loss: 0.40214870551998694\n",
      "Epoch: 3, Training Loss: 0.3594202908237329\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1381\n",
      "Number of validation examples: 75\n",
      "Number of test examples: 692\n",
      "Epoch: 1, Training Loss: 0.5191335821973866\n",
      "Epoch: 2, Training Loss: 0.40636135312332505\n",
      "Epoch: 3, Training Loss: 0.36860422670156107\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1364\n",
      "Number of validation examples: 114\n",
      "Number of test examples: 692\n",
      "Epoch: 1, Training Loss: 0.5119914419429247\n",
      "Epoch: 2, Training Loss: 0.41591856472714\n",
      "Epoch: 3, Training Loss: 0.3668682367302651\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1349\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 692\n",
      "Epoch: 1, Training Loss: 0.524992356931462\n",
      "Epoch: 2, Training Loss: 0.42614931043456583\n",
      "Epoch: 3, Training Loss: 0.37385171686901764\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1407\n",
      "Number of validation examples: 86\n",
      "Number of test examples: 507\n",
      "Epoch: 1, Training Loss: 0.5177662778984417\n",
      "Epoch: 2, Training Loss: 0.4339076304300265\n",
      "Epoch: 3, Training Loss: 0.3809653313999826\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1447\n",
      "Number of validation examples: 78\n",
      "Number of test examples: 507\n",
      "Epoch: 1, Training Loss: 0.5125022409381447\n",
      "Epoch: 2, Training Loss: 0.42083132430747316\n",
      "Epoch: 3, Training Loss: 0.37567126750946045\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1389\n",
      "Number of validation examples: 114\n",
      "Number of test examples: 507\n",
      "Epoch: 1, Training Loss: 0.5441383839338675\n",
      "Epoch: 2, Training Loss: 0.42883389982683906\n",
      "Epoch: 3, Training Loss: 0.38075838691886815\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1368\n",
      "Number of validation examples: 116\n",
      "Number of test examples: 512\n",
      "Epoch: 1, Training Loss: 0.4860912031212518\n",
      "Epoch: 2, Training Loss: 0.3965972682764364\n",
      "Epoch: 3, Training Loss: 0.3670053665721139\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1413\n",
      "Number of validation examples: 78\n",
      "Number of test examples: 512\n",
      "Epoch: 1, Training Loss: 0.5084079751807652\n",
      "Epoch: 2, Training Loss: 0.40876887286646985\n",
      "Epoch: 3, Training Loss: 0.38774133800120836\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1390\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 512\n",
      "Epoch: 1, Training Loss: 0.5040790561971993\n",
      "Epoch: 2, Training Loss: 0.4170151753672238\n",
      "Epoch: 3, Training Loss: 0.37111885760022306\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1405\n",
      "Number of validation examples: 117\n",
      "Number of test examples: 592\n",
      "Epoch: 1, Training Loss: 0.5268017212775621\n",
      "Epoch: 2, Training Loss: 0.41859860718250275\n",
      "Epoch: 3, Training Loss: 0.3833178874443878\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1407\n",
      "Number of validation examples: 84\n",
      "Number of test examples: 592\n",
      "Epoch: 1, Training Loss: 0.547665497796102\n",
      "Epoch: 2, Training Loss: 0.42374050143090164\n",
      "Epoch: 3, Training Loss: 0.3728009936484424\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1416\n",
      "Number of validation examples: 78\n",
      "Number of test examples: 592\n",
      "Epoch: 1, Training Loss: 0.5193804847390464\n",
      "Epoch: 2, Training Loss: 0.4235423508654819\n",
      "Epoch: 3, Training Loss: 0.36537358298730316\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1398\n",
      "Number of validation examples: 114\n",
      "Number of test examples: 450\n",
      "Epoch: 1, Training Loss: 0.529192540794611\n",
      "Epoch: 2, Training Loss: 0.42409802465276286\n",
      "Epoch: 3, Training Loss: 0.3603556254370646\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1390\n",
      "Number of validation examples: 115\n",
      "Number of test examples: 450\n",
      "Epoch: 1, Training Loss: 0.5128473677169317\n",
      "Epoch: 2, Training Loss: 0.41551594384785356\n",
      "Epoch: 3, Training Loss: 0.36651484925171424\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1421\n",
      "Number of validation examples: 75\n",
      "Number of test examples: 450\n",
      "Epoch: 1, Training Loss: 0.5072017650255997\n",
      "Epoch: 2, Training Loss: 0.41522944408856083\n",
      "Epoch: 3, Training Loss: 0.35874052663867395\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1394\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 456\n",
      "Epoch: 1, Training Loss: 0.5161152776669372\n",
      "Epoch: 2, Training Loss: 0.41482148319482803\n",
      "Epoch: 3, Training Loss: 0.36968209967017174\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1421\n",
      "Number of validation examples: 78\n",
      "Number of test examples: 456\n",
      "Epoch: 1, Training Loss: 0.5105343906397231\n",
      "Epoch: 2, Training Loss: 0.40636761838130736\n",
      "Epoch: 3, Training Loss: 0.36797958478498993\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1394\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 456\n",
      "Epoch: 1, Training Loss: 0.5283866568722508\n",
      "Epoch: 2, Training Loss: 0.42200256342237646\n",
      "Epoch: 3, Training Loss: 0.3749415146356279\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1390\n",
      "Number of validation examples: 104\n",
      "Number of test examples: 575\n",
      "Epoch: 1, Training Loss: 0.5384075343608856\n",
      "Epoch: 2, Training Loss: 0.4328656891981761\n",
      "Epoch: 3, Training Loss: 0.3791534633472048\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1417\n",
      "Number of validation examples: 75\n",
      "Number of test examples: 575\n",
      "Epoch: 1, Training Loss: 0.5113293063104822\n",
      "Epoch: 2, Training Loss: 0.4102508713690083\n",
      "Epoch: 3, Training Loss: 0.3656243052375451\n",
      "----Finished this cross validation pass----\n",
      "Generating train/val/test split...\n",
      "Generating sequences...\n",
      "Number of training examples: 1410\n",
      "Number of validation examples: 100\n",
      "Number of test examples: 575\n",
      "Epoch: 1, Training Loss: 0.5333995802348919\n",
      "Epoch: 2, Training Loss: 0.42722904715645177\n",
      "Epoch: 3, Training Loss: 0.3744205648309729\n",
      "----Finished this cross validation pass----\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "csvfile = \"../../data/video/All_Subs_Diff_Modules_nofilter_withoutAUc.csv\"\n",
    "train_df = pd.read_csv(csvfile,  delimiter=\",\")  # 101 features (only AU_r)\n",
    "\n",
    "# Select only the classes we want to predict\n",
    "train_df, nclasses, targets_numpy = set_targets(train_df, list_targets, list_labels)\n",
    "\n",
    "# Convert the subject names (strings) into numbers\n",
    "subjects = pd.factorize(train_df['Subject'])[0]\n",
    "\n",
    "# Normalise the features\n",
    "features_numpy = normalize_data(train_df, False)# parameters.normalise_individual_subjects\n",
    "input_dim = features_numpy.shape[1]\n",
    "print(f\"Number of features: {input_dim}\")\n",
    "\n",
    "del train_df\n",
    "\n",
    "test_accuracies = []\n",
    "calibrated_test_accuracies = []\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "all_outputs = np.empty((0, nclasses), dtype='float')\n",
    "\n",
    "# Get distinct subjects\n",
    "subj = np.unique(subjects)\n",
    "\n",
    "# Loop over all subjects\n",
    "for test_subj in subj:\n",
    "  xv_max_val = 0\n",
    "  avg_test_acc = 0\n",
    "  val_acc_val_loss_list = []\n",
    "  test_acc_list = []\n",
    "\n",
    "  # Cross validation\n",
    "  for xv in range(parameters.cross_validation_passes):\n",
    "\n",
    "    test_idx = np.array([test_subj])\n",
    "\n",
    "    # Take out test subject from trainval (Crooss validation)\n",
    "    trainval_idx = np.delete(subj, np.where(subj==test_subj))\n",
    "    val_idx = trainval_idx[random.sample(range(len(trainval_idx)), num_validation_subjects)]\n",
    "    val_idx = val_idx%len(subj)\n",
    "\n",
    "    # Remove test & validation subjects from trainval\n",
    "    train_idx = np.setxor1d(subj, test_idx)\n",
    "    train_idx = np.setxor1d(train_idx, val_idx)\n",
    "\n",
    "    print(\"Generating train/val/test split...\")\n",
    "    features_train, targets_train, features_val, targets_val, features_test, targets_test = split_train_test(targets_numpy, features_numpy, subjects, train_idx, val_idx, test_idx)\n",
    "\n",
    "    print(\"Generating sequences...\")\n",
    "    features_train, targets_train = split_sequence_overlap(features_train, targets_train, parameters.seq_dim, parameters.overlap_size)\n",
    "    features_val, targets_val = split_sequence_overlap(features_val, targets_val, parameters.seq_dim, parameters.overlap_size)\n",
    "    \n",
    "    # Overlap or no\n",
    "    if parameters.test_with_subsequences:\n",
    "      features_test, targets_test = split_sequence_overlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "    else:\n",
    "      features_test, targets_test = split_sequence_nooverlap(features_test, targets_test, parameters.test_seq_dim, parameters.test_overlap_size)\n",
    "\n",
    "    print(f\"Number of training examples: {len(targets_train)}\")\n",
    "    print(f\"Number of validation examples: {len(targets_val)}\")\n",
    "    print(f\"Number of test examples: {len(targets_test)}\")\n",
    "\n",
    "    # Create feature and targets tensor for train set. We need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "    featuresTrain = torch.from_numpy(features_train)\n",
    "    targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "    featuresVal = torch.from_numpy(features_val)\n",
    "    targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor)  # data type is long\n",
    "\n",
    "    # Pytorch train and validation sets\n",
    "    train = TensorDataset(featuresTrain, targetsTrain)\n",
    "    val = TensorDataset(featuresVal, targetsVal)\n",
    "    \n",
    "    # Data loader\n",
    "    train_loader = DataLoader(train, batch_size=parameters.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val, batch_size=parameters.batch_size, shuffle=False)\n",
    "\n",
    "    # Create feature and targets tensor for test set\n",
    "    if parameters.test_with_subsequences:\n",
    "      featuresTest = torch.from_numpy(features_test)\n",
    "      targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)  # data type is long\n",
    "      test = TensorDataset(featuresTest, targetsTest)\n",
    "      test_loader = DataLoader(test, batch_size=parameters.batch_size, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    model = CNN(input_dim, parameters.seq_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    cur_learning_rate = learning_rate\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    error_cpu = nn.CrossEntropyLoss().to('cpu')\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "      model.train()\n",
    "      running_loss = 0\n",
    "      for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = error(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "      print(f\"Epoch: {epoch+1}, Training Loss: {running_loss/len(train_loader)}\")\n",
    "    print(\"----Finished this cross validation pass----\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = './model_test.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([2, 1000, 100])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([16, 1000, 100])\n",
      "torch.Size([15, 1000, 100])\n",
      "Test accuracy for run 2: 0.7930434782608695\n",
      "Test accuracies:\n",
      "[0.7930434782608695]\n",
      "Mean accuracy: 0.7930434782608695\n"
     ]
    }
   ],
   "source": [
    "# Open the model file\n",
    "model = CNN(input_dim, parameters.seq_dim).to(device)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "prev_label = -1\n",
    "class_hist = np.zeros(nclasses, dtype='int')\n",
    "\n",
    "\n",
    "print(parameters.test_seq_dim)\n",
    "# Iterate through test dataset\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if parameters.test_with_subsequences:\n",
    "        for features, labels in test_loader:\n",
    "            features = Variable(features.view(-1, parameters.test_seq_dim, input_dim)).to(device)\n",
    "            labels = Variable(labels).to('cpu')\n",
    "\n",
    "            print(features.shape)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(features)\n",
    "\n",
    "            test_loss = error_cpu(outputs.to('cpu'), labels)\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            predicted = predicted.to('cpu')\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predicted.extend(list(predicted.detach().numpy()))\n",
    "            all_labels.extend(list(labels.detach().numpy()))\n",
    "            all_outputs = np.concatenate((all_outputs, outputs.data.to('cpu').reshape(-1, nclasses)))\n",
    "\n",
    "    \n",
    "    else:\n",
    "        count=0\n",
    "        for features in features_test:\n",
    "            features = torch.tensor(features)\n",
    "            features = torch.unsqueeze(features, 0).to(device)\n",
    "            labels = torch.unsqueeze(torch.tensor(targets_test[count]), 0)\n",
    "            #features = Variable(features.view(-1, seq_dim, input_dim)).to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(features)\n",
    "\n",
    "            test_loss = error(outputs.to('cpu'), labels)\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            predicted = predicted.to('cpu')\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            count += 1\n",
    "\n",
    "    al_np = np.array(all_labels)   \n",
    "    ao_np = np.array(all_outputs)  \n",
    "\n",
    "    accuracy = correct / float(total)\n",
    "\n",
    "    print(f\"Test accuracy for run {xv}: {accuracy}\")\n",
    "\n",
    "avg_test_acc += accuracy\n",
    "test_acc_list.append(accuracy)\n",
    "\n",
    "avg_test_acc = np.mean(test_acc_list)\n",
    "\n",
    "# avg_test_acc /= parameters.cross_validation_passes\n",
    "test_accuracies.append(avg_test_acc)\n",
    "print(\"Test accuracies:\")\n",
    "print(test_accuracies)\n",
    "print(f\"Mean accuracy: {np.mean(test_accuracies)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
